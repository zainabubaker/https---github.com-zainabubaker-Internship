How to Write Fast Numerical Code Spring 2016 Lecture : SIMD extensions , SSE , compiler vectorization Instructor : Markus Püschel TA : Gagandeep Singh , Daniele Spampinato , Alen Stojanov Flynn ’ s Taxonomy Single data Multiple data Single instruction Multiple instruction SISD Uniprocessor MISD SIMD Vector computer Short vector extensions MIMD Multiprocessors VLIW © Markus Püschel Computer Science 2 How to write fast numerical code Spring 2016 SIMD Extensions and SSE  Overview : SSE family  SSE intrinsics  Compiler vectorization  This lecture and material was created together with Franz Franchetti ( ECE , Carnegie Mellon ) SIMD Vector Extensions + x 4-way  What is it ?  Extension of the ISA  Data types and instructions for the parallel computation on short ( length 2 , 4 , 8 , … ) vectors of integers or floats  Names : MMX , SSE , SSE2 , …  Why do they exist ?  Useful : Many applications have the necessary fine-grain parallelism Then : speedup by a factor close to vector length  Doable : Relative easy to design ; chip designers have enough transistors to play with 3 4 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 MMX : Multimedia extension SSE : Streaming SIMD extension AVX : Advanced vector extensions register width 64 bit ( only int ) Intel x86 Processors © Markus Püschel Computer Science x86-16 x86-32 MMX SSE SSE2 SSE3 8086 286 386 486 Pentium Pentium MMX Pentium III Pentium 4 Pentium 4E Pentium 4F time 128 bit x86-64 / em64t SSE4 AVX AVX2 Core 2 Duo Penryn Core i7 ( Nehalem ) Sandy Bridge Haswell 256 bit SSE Family : Floating Point SSE4 SSSE3 SSE3 SSE2 : 2-way double SSE : 4-way single  Not drawn to scale  From SSE3 : Only additional instructions  Every Core 2 has SSE3 © Markus Püschel Computer Science 6 How to write fast numerical code Spring 2016 Overview Floating-Point Vector ISAs Within an extension family , newer generations add features to older ones Convergence : 3DNow ! Professional = 3DNow ! + SSE ; VMX = AltiVec ; Core 2  Has SSE3  16 SSE registers 128 bit = 2 doubles = 4 singles % xmm0 % xmm1 % xmm2 % xmm3 % xmm4 % xmm5 % xmm6 % xmm7 % xmm8 % xmm9 % xmm10 % xmm11 % xmm12 % xmm13 % xmm14 % xmm15 7 8 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 VendorNameº-wayPrecisionIntroducedwithIntelSSE4-waysinglePentiumIIISSE2+2-waydoublePentium4SSE3Pentium4 ( Prescott ) SSSE3CoreDuoSSE4Core2Extreme ( Penryn ) AVX8-waysingleCorei7 ( Sandybridge ) 4-waydoubleIntelIPF2-waysingleItaniumIntelLRB16-waysingleLarrabee8-waydoubleAMD3DNow ! 2-waysingleK6Enhanced3DNow ! K73DNow ! Professional+4-waysingleAthlonXPAMD64+2-waydoubleOpteronMotorolaAltiVec4-waysingleMPC7400G4IBMVMX4-waysinglePowerPC970G5SPU+2-waydoubleCellBEIBMDoubleFPU2-waydoublePowerPC440FP2 SSE3 Registers  Different data types and associated instructions 128 bit LSB  Integer vectors :  16-way byte  8-way 2 bytes  4-way 4 bytes  2-way 8 bytes  Floating point vectors :  4-way single ( since SSE )  2-way double ( since SSE2 )  Floating point scalars :  single ( since SSE )  double ( since SSE2 ) SSE3 Instructions : Examples  Single precision 4-way vector add : addps % xmm0 % xmm1 +  Single precision scalar add : addss % xmm0 % xmm1 + % xmm0 % xmm1 % xmm0 % xmm1 9 10 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE3 Instruction Names packed ( vector ) single slot ( scalar ) addps addss single precision addpd addsd double precision Compiler will use this for floating point • on x86-64 • with proper flags if SSE/SSE2 is available 11 x86-64 FP Code Example float ipf ( float x [ ] , float y [ ] , int n ) { int i ; float result = 0.0 ; for ( i = 0 ; i < n ; i++ ) result += x [ i ] * y [ i ] ; return result ; }  Inner product of two vectors  Single precision arithmetic  Compiled : not vectorized , uses SSE instructions ipf : xorps xorl jmp .L10 : % xmm1 , % xmm1 % ecx , % ecx .L8 % ecx movslq % ecx , % rax incl movss ( % rsi , % rax,4 ) , % xmm0 mulss ( % rdi , % rax,4 ) , % xmm0 addss % xmm0 , % xmm1 .L8 : cmpl % edx , % ecx .L10 jl movaps % xmm1 , % xmm0 ret © Markus Püschel Computer Science # result = 0.0 # i = 0 # goto middle # loop : # icpy = i # i++ # t = y [ icpy ] # t * = x [ icpy ] # result += t # middle : # i : n # if < goto loop # return result 12 How to write fast numerical code Spring 2016 From Core 2 Manual Latency , throughput SSE based FP x87 FP Summary  On Core 2 there are two different ( unvectorized ) floating points  x87 : obsolete , is default on x86-32  SSE based : uses only one slot , is default on x86-64  SIMD vector floating point instructions  4-way single precision : since SSE  2-way double precision : since SSE2  SSE vector add and mult are fully pipelined ( 1 per cycle ) : possible gain 4x and 2x , respectively  Starting with Sandybridge , AVX was introduced : 8-way single , 4-way double 13 14 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE : How to Take Advantage ? + instead of +  Necessary : fine grain parallelism  Options ( ordered by effort ) :  Use vectorized libraries ( easy , not always available )  Compiler vectorization ( this lecture )  Use intrinsics ( this lecture )  Write assembly  We will focus on floating point and single precision ( 4-way ) SIMD Extensions and SSE  Overview : SSE family  SSE intrinsics  Compiler vectorization References : Intel Intrinsics Guide ( contains latency and throughput information ! ) http : //software.intel.com/en-us/articles/intel-intrinsics-guide Intel icc compiler manual Visual Studio manual 15 16 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Family : Floating Point SSE4 SSSE3 SSE3 SSE2 : 2-way double SSE : 4-way single  Not drawn to scale  From SSE2 : Only additional instructions  Every Core 2 has SSE3 SSE Family Intrinsics  Assembly coded C functions  Expanded inline upon compilation : no overhead  Like writing assembly inside C  Floating point :  Intrinsics for math functions : log , sin , …  Intrinsics for SSE  Our introduction is based on icc  Most intrinsics work with gcc and Visual Studio ( VS )  Some language extensions are icc ( or even VS ) specific 17 18 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Header files  SSE : xmmintrin.h  SSE2 : emmintrin.h  SSE3 : pmmintrin.h  SSSE3 : tmmintrin.h  SSE4 : smmintrin.h and nmmintrin.h or ia32intrin.h Visual Conventions We Will Use  Memory increasing address memory LSB  Registers  Before ( and common ) R3 R2 R1 R0  Now we will use LSB R0 R1 R2 R3 19 20 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Intrinsics ( Focus Floating Point )  Data types __m128 f ; // = { float f0 , f1 , f2 , f3 } __m128d d ; // = { double d0 , d1 } __m128i i ; // 16 8-bit , 8 16-bit , 4 32-bit , or 2 64-bit ints ints ints ints or floats ints or doubles SSE Intrinsics ( Focus Floating Point )  Instructions  Naming convention : _mm_ < intrin_op > _ < suffix >  Example : // a is 16-byte aligned float a [ 4 ] = { 1.0 , 2.0 , 3.0 , 4.0 } ; __m128 t = _mm_load_ps ( a ) ; p : packed s : single precision LSB 1.0 2.0 3.0 4.0  Same result as __m128 t = _mm_set_ps ( 4.0 , 3.0 , 2.0 , 1.0 ) 21 22 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Intrinsics  Native instructions ( one-to-one with assembly ) _mm_load_ps ( ) _mm_add_ps ( ) _mm_mul_ps ( ) …  Multi instructions ( map to several assembly instructions ) _mm_set_ps ( ) _mm_set1_ps ( ) …  Macros and helpers _MM_TRANSPOSE4_PS ( ) _MM_SHUFFLE ( ) … What Are the Main Issues ?  Alignment is important ( 128 bit = 16 byte )  You need to code explicit loads and stores  Overhead through shuffles 23 24 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Intrinsics  Load and store  Constants  Arithmetic  Comparison  Conversion  Shuffles Loads and Stores Intrinsic Name Operation _mm_loadh_pi _mm_loadl_pi _mm_load_ss Load high Load low Corresponding SSE Instructions MOVHPS reg , mem MOVLPS reg , mem Load the low value and clear the three high values MOVSS _mm_load1_ps Load one value into all four words MOVSS + Shuffling _mm_load_ps Load four values , address aligned _mm_loadu_ps Load four values , address unaligned MOVAPS MOVUPS _mm_loadr_ps Load four values in reverse MOVAPS + Shuffling Intrinsic Name Operation Corresponding SSE Instruction Set the low value and clear the three high values Composite _mm_set_ss _mm_set1_ps _mm_set_ps _mm_setr_ps Set all four words with the same value Set four values , address aligned Set four values , in reverse order _mm_setzero_ps Clear all four values Composite Composite Composite Composite 25 26 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Loads and Stores p 1.0 2.0 3.0 4.0 memory LSB 1.0 2.0 3.0 4.0 a a = _mm_load_ps ( p ) ; // p 16-byte aligned a = _mm_loadu_ps ( p ) ; // p not aligned avoid ( can be expensive ) on recent Intel possibly no penalty → blackboard 27 How to Align  __m128 , __m128d , __m128i are 16-byte aligned  Arrays : __declspec ( align ( 16 ) ) float g [ 4 ] ;  Dynamic allocation  _mm_malloc ( ) and _mm_free ( )  Write your own malloc that returns 16-byte aligned addresses  Some malloc ’ s already guarantee 16-byte alignment © Markus Püschel Computer Science 28 How to write fast numerical code Spring 2016 Loads and Stores p 1.0 2.0 memory LSB 1.0 2.0 a kept LSB 1.0 2.0 a kept a = _mm_loadl_pi ( a , p ) ; // p 8-byte aligned a = _mm_loadh_pi ( a , p ) ; // p 8-byte aligned Loads and Stores p 1.0 LSB 1.0 0 0 0 a set to zero a = _mm_load_ss ( p ) ; // p any alignment memory 29 → blackboard 30 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Stores Analogous to Loads Intrinsic Name _mm_storeh_pi _mm_storel_pi Operation Store high Store low Corresponding SSE Instruction MOVHPS mem , reg MOVLPS mem , reg _mm_store_ss Store the low value MOVSS _mm_store1_ps Store the low value across all four words , address aligned Shuffling + MOVSS _mm_store_ps Store four values , address aligned MOVAPS _mm_storeu_ps Store four values , address unaligned MOVUPS _mm_storer_ps Store four values , in reverse order MOVAPS + Shuffling 31 Constants LSB 1.0 2.0 3.0 4.0 a a = _mm_set_ps ( 4.0 , 3.0 , 2.0 , 1.0 ) ; LSB 1.0 1.0 1.0 1.0 b b = _mm_set1_ps ( 1.0 ) ; LSB 1.0 0 0 0 c c = _mm_set_ss ( 1.0 ) ; LSB 0 0 0 0 d d = _mm_setzero_ps ( ) ; → blackboard 32 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Arithmetic SSE Intrinsic Name Operation _mm_add_ss _mm_add_ps Addition Addition _mm_sub_ss Subtraction _mm_sub_ps Subtraction _mm_mul_ss Multiplication _mm_mul_ps Multiplication _mm_div_ss _mm_div_ps Division Division _mm_sqrt_ss Squared Root _mm_sqrt_ps Squared Root _mm_rcp_ss Reciprocal _mm_rcp_ps Reciprocal SSE3 Corresponding SSE Instruction Intrinsic Name Operation Corresponding SSE3 Instruction _mm_addsub_ps Subtract and add ADDSUBPS _mm_hadd_ps Add _mm_hsub_ps Subtracts HADDPS HSUBPS SSE4 Intrinsic Operation Corresponding SSE4 Instruction _mm_dp_ps Single precision dot product DPPS ADDSS ADDPS SUBSS SUBPS MULSS MULPS DIVSS DIVPS SQRTSS SQRTPS RCPSS RCPPS _mm_rsqrt_ss Reciprocal Squared Root RSQRTSS _mm_rsqrt_ps Reciprocal Squared Root RSQRTPS _mm_min_ss Computes Minimum _mm_min_ps Computes Minimum _mm_max_ss Computes Maximum _mm_max_ps Computes Maximum MINSS MINPS MAXSS MAXPS 33 Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 1.5 3.5 5.5 7.5 c c = _mm_add_ps ( a , b ) ; analogous : c = _mm_sub_ps ( a , b ) ; c = _mm_mul_ps ( a , b ) ; → blackboard 34 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example void addindex ( float * x , int n ) { for ( int i = 0 ; i < n ; i++ ) x [ i ] = x [ i ] + i ; } # include < ia32intrin.h > // n a multiple of 4 , x is 16-byte aligned void addindex_vec ( float * x , int n ) { __m128 index , x_vec ; for ( int i = 0 ; i < n ; i+=4 ) { x_vec = _mm_load_ps ( x+i ) ; // load 4 floats index = _mm_set_ps ( i+3 , i+2 , i+1 , i ) ; // create vector with indexes x_vec = _mm_add_ps ( x_vec , index ) ; // add the two _mm_store_ps ( x+i , x_vec ) ; // store back } } Is this the best solution ? No ! _mm_set_ps may be too expensive Example void addindex ( float * x , int n ) { for ( int i = 0 ; i < n ; i++ ) x [ i ] = x [ i ] + i ; } # include < ia32intrin.h > // n a multiple of 4 , x is 16-byte aligned void addindex_vec ( float * x , int n ) { __m128 x_vec , init , incr ; = _mm_set_ps ( 3 , 2 , 1 , 0 ) ; ind incr = _mm_set1_ps ( 4 ) ; for ( int i = 0 ; i < n ; i+=4 ) { x_vec = _mm_load_ps ( x+i ) ; // load 4 floats x_vec = _mm_add_ps ( x_vec , ind ) ; ind = _mm_add_ps ( ind , incr ) ; // update ind _mm_store_ps ( x+i , x_vec ) ; // store back // add the two } } How does the code style differ from scalar code ? Intrinsics force scalar replacement ! 35 36 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 b LSB 1.5 2.0 3.0 4.0 c c = _mm_add_ss ( a , b ) ; Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b max max max max LSB 1.0 2.0 3.0 4.0 c c = _mm_max_ps ( a , b ) ; 37 38 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 0.5 3.5 0.5 7.5 c c = _mm_addsub_ps ( a , b ) ; Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 3.0 7.0 2.0 6.0 c c = _mm_hadd_ps ( a , b ) ; analogous : c = _mm_hsub_ps ( a , b ) ; 39 → blackboard 40 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example // n is even void lp ( float * x , float * y , int n ) { for ( int i = 0 ; i < n/2 ; i++ ) y [ i ] = ( x [ 2 * i ] + x [ 2 * i+1 ] ) /2 ; } # include < ia32intrin.h > // n a multiple of 8 , x , y are 16-byte aligned void lp_vec ( float * x , int n ) { __m128 half , v1 , v2 , avg ; half = _mm_set1_ps ( 0.5 ) ; // set vector to all 0.5 for ( int i = 0 ; i < n/8 ; i++ ) { v1 = _mm_load_ps ( x+i * 8 ) ; // load first 4 floats v2 = _mm_load_ps ( x+4+i * 8 ) ; // load next 4 floats avg = _mm_hadd_ps ( v1 , v2 ) ; // add pairs of floats avg = _mm_mul_ps ( avg , half ) ; _mm_store_ps ( y+i * 4 , avg ) ; // save result // multiply with 0.5 } } Arithmetic __m128 _mm_dp_ps ( __m128 a , __m128 b , const int mask ) ( SSE4 ) Computes the pointwise product of a and b and writes a selected sum of the resulting numbers into selected elements of c ; the others are set to zero . The selections are encoded in the mask . Example : mask = 117 = 01110101 LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b 0.5 3.0 7.5 14.0 01110101 Σ LSB 11.0 0 11.0 0 c 41 42 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Comparisons Intrinsic Name Operation _mm_cmpeq_ss _mm_cmpeq_ps _mm_cmplt_ss _mm_cmplt_ps _mm_cmple_ss _mm_cmple_ps _mm_cmpgt_ss _mm_cmpgt_ps _mm_cmpge_ss _mm_cmpge_ps _mm_cmpneq_ss _mm_cmpneq_ps _mm_cmpnlt_ss _mm_cmpnlt_ps _mm_cmpnle_ss _mm_cmpnle_ps _mm_cmpngt_ss _mm_cmpngt_ps _mm_cmpnge_ss _mm_cmpnge_ps Equal Equal Less Than Less Than Less Than or Equal Less Than or Equal Greater Than Greater Than Greater Than or Equal Greater Than or Equal Not Equal Not Equal Not Less Than Not Less Than Not Less Than or Equal Not Less Than or Equal Not Greater Than Not Greater Than Not Greater Than or Equal Not Greater Than or Equal Corresponding SSE Instruction CMPEQSS CMPEQPS CMPLTSS CMPLTPS CMPLESS CMPLEPS CMPLTSS CMPLTPS CMPLESS CMPLEPS CMPNEQSS CMPNEQPS CMPNLTSS CMPNLTPS CMPNLESS CMPNLEPS CMPNLTSS CMPNLTPS CMPNLESS CMPNLEPS Intrinsic Name _mm_cmpord_ss _mm_cmpord_ps _mm_cmpunord_ss _mm_cmpunord_ps _mm_comieq_ss _mm_comilt_ss _mm_comile_ss _mm_comigt_ss _mm_comige_ss _mm_comineq_ss _mm_ucomieq_ss _mm_ucomilt_ss _mm_ucomile_ss _mm_ucomigt_ss _mm_ucomige_ss _mm_ucomineq_ss Operation Corresponding SSE Instruction CMPORDSS Ordered CMPORDPS Ordered CMPUNORDSS Unordered CMPUNORDPS Unordered COMISS Equal COMISS Less Than COMISS Less Than or Equal COMISS Greater Than COMISS Greater Than or Equal COMISS Not Equal UCOMISS Equal UCOMISS Less Than UCOMISS Less Than or Equal Greater Than UCOMISS Greater Than or Equal UCOMISS UCOMISS Not Equal Comparisons LSB 1.0 2.0 3.0 4.0 a LSB 1.0 1.5 3.0 3.5 b = ? = ? = ? = ? LSB 0xffffffff 0x0 0xffffffff 0x0 c c = _mm_cmpeq_ps ( a , b ) ; analogous : c = _mm_cmple_ps ( a , b ) ; c = _mm_cmplt_ps ( a , b ) ; c = _mm_cmpge_ps ( a , b ) ; etc . Each field : 0xffffffff if true 0x0 if false Return type : __m128 43 44 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example void fcond ( float * x , size_t n ) { int i ; for ( i = 0 ; i < n ; i++ ) { if ( x [ i ] > 0.5 ) x [ i ] += 1. ; else x [ i ] -= 1. ; } } # include < xmmintrin.h > void fcond ( float * a , size_t n ) { int i ; __m128 vt , vmask , vp , vm , vr , ones , mones , thresholds ; ones = _mm_set1_ps ( 1 . ) ; mones = _mm_set1_ps ( -1 . ) ; thresholds = _mm_set1_ps ( 0.5 ) ; for ( i = 0 ; i < n ; i+=4 ) { = _mm_load_ps ( a+i ) ; vt vmask = _mm_cmpgt_ps ( vt , thresholds ) ; = _mm_and_ps ( vmask , ones ) ; vp = _mm_andnot_ps ( vmask , mones ) ; vm vr = _mm_add_ps ( vt , _mm_or_ps ( vp , vm ) ) ; _mm_store_ps ( a+i , vr ) ; } } 45 © Markus Püschel Computer Science Vectorization = Picture : www.druckundbestell.de © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Conversion Intrinsic Name Operation _mm_cvtss_si32 Convert to 32-bit integer _mm_cvtss_si64 * Convert to 64-bit integer Corresponding SSE Instruction CVTSS2SI CVTSS2SI _mm_cvtps_pi32 Convert to two 32-bit integers CVTPS2PI _mm_cvttss_si32 Convert to 32-bit integer _mm_cvttss_si64 * Convert to 64-bit integer CVTTSS2SI CVTTSS2SI _mm_cvttps_pi32 Convert to two 32-bit integers CVTTPS2PI _mm_cvtsi32_ss Convert from 32-bit integer _mm_cvtsi64_ss * Convert from 64-bit integer CVTSI2SS CVTSI2SS _mm_cvtpi32_ps Convert from two 32-bit integers CVTTPI2PS _mm_cvtpi16_ps Convert from four 16-bit integers composite _mm_cvtpu16_ps Convert from four 16-bit integers composite _mm_cvtpi8_ps Convert from four 8-bit integers composite _mm_cvtpu8_ps Convert from four 8-bit integers composite _mm_cvtpi32x2_ps Convert from four 32-bit integers composite _mm_cvtps_pi16 Convert to four 16-bit integers composite _mm_cvtps_pi8 Convert to four 8-bit integers composite _mm_cvtss_f32 Extract composite Conversion float _mm_cvtss_f32 ( __m128 a ) LSB 1.0 2.0 3.0 4.0 a 1.0 f float f ; f = _mm_cvtss_f32 ( a ) ; 47 48 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Cast floats ints __m128i _mm_castps_si128 ( __m128 a ) __m128 _mm_castsi128_ps ( __m128i a ) Reinterprets the four single precision floating point values in a as four 32-bit integers , and vice versa . No conversion is performed . Does not map to any assembly instructions . Makes integer shuffle instructions usable for floating point . → blackboard 49 Shuffles SSE Intrinsic Name Operation _mm_shuffle_ps Shuffle _mm_unpackhi_ps Unpack High _mm_unpacklo_ps Unpack Low _mm_move_ss Set low word , pass in three high values Corresponding SSE Instruction SHUFPS UNPCKHPS UNPCKLPS MOVSS _mm_movehl_ps Move High to Low MOVHLPS SSE3 Intrinsic Name Operation Corresponding SSE3 Instruction _mm_movehdup_ps Duplicates MOVSHDUP _mm_moveldup_ps Duplicates MOVSLDUP SSSE3 Intrinsic Name Operation Corresponding SSSE3 Instruction _mm_movelh_ps Move Low to High MOVLHPS _mm_shuffle_epi8 Shuffle _mm_movemask_ps Create four-bit mask MOVMSKPS _mm_alignr_epi8 Shift SSE4 Intrinsic Syntax Operation PSHUFB PALIGNR Corresponding SSE4 Instruction __m128 _mm_blend_ps ( __m128 v1 , __m128 v2 , const int mask ) Selects float single precision data from 2 BLENDPS __m128 _mm_blendv_ps ( __m128 v1 , __m128 v2 , __m128 v3 ) __m128 _mm_insert_ps ( __m128 dst , __m128 src , const int ndx ) sources using constant mask Selects float single precision data from 2 sources using variable mask Insert single precision float into packed single precision array element selected by index . BLENDVPS INSERTPS int _mm_extract_ps ( __m128 src , const int ndx ) Extract single precision float from packed single precision array selected by index . EXTRACTPS 50 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Shuffles LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 1.0 0.5 2.0 1.5 c c = _mm_unpacklo_ps ( a , b ) ; LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 3.0 2.5 4.0 3.5 c c = _mm_unpackhi_ps ( a , b ) ; → blackboard 51 Shuffles c = _mm_shuffle_ps ( a , b , _MM_SHUFFLE ( l , k , j , i ) ) ; helper macro to create mask LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB c0 c1 c2 c3 c any element of a any element of b c0 = ai c1 = aj c2 = bk c3 = bl i , j , k , l in { 0,1,2,3 } → blackboard 52 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example : Loading 4 Real Numbers from Arbitrary Memory Locations p0 p1 p2 p3 1.0 2.0 3.0 4.0 memory LSB 1.0 0 0 0 LSB 3.0 0 0 0 LSB 2.0 0 0 0 LSB 4.0 0 0 0 LSB 1.0 0 2.0 0 LSB 3.0 0 4.0 0 4x _mm_load_ss 2x _mm_shuffle_ps 1x _mm_shuffle_ps LSB 1.0 2.0 3.0 4.0 7 instructions , this is one good way of doing it 53 Code For Previous Slide # include < ia32intrin.h > __m128 LoadArbitrary ( float * p0 , float * p1 , float * p2 , float * p3 ) { __m128 a , b , c , d , e , f ; a = _mm_load_ss ( p0 ) ; b = _mm_load_ss ( p1 ) ; c = _mm_load_ss ( p2 ) ; d = _mm_load_ss ( p3 ) ; e = _mm_shuffle_ps ( a , b , _MM_SHUFFLE ( 1,0,2,0 ) ) ; //only zeros are important f = _mm_shuffle_ps ( c , d , _MM_SHUFFLE ( 1,0,2,0 ) ) ; //only zeros are important return _mm_shuffle_ps ( e , f , _MM_SHUFFLE ( 2,0,2,0 ) ) ; } © Markus Püschel Computer Science 54 How to write fast numerical code Spring 2016 Example : Loading 4 Real Numbers from Arbitrary Memory Locations ( cont ’ d )  Whenever possible avoid the previous situation  Restructure algorithm and use the aligned _mm_load_ps ( )  Other possibility ( but likely also yields 7 instructions ) __m128 vf ; vf = _mm_set_ps ( * p3 , * p2 , * p1 , * p0 ) ;  SSE4 : _mm_insert_epi32 together with _mm_castsi128_ps  Not clear whether better Example : Loading 4 Real Numbers from Arbitrary Memory Locations ( cont ’ d )  Do not do this ( why ? ) : __declspec ( align ( 16 ) ) float g [ 4 ] ; __m128 vf ; g [ 0 ] = * p0 ; g [ 1 ] = * p1 ; g [ 2 ] = * p2 ; g [ 3 ] = * p3 ; vf = _mm_load_ps ( g ) ; 55 56 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example : Storing 4 Real Numbers to Arbitrary Memory Locations LSB 1.0 2.0 3.0 4.0 LSB 4.0 0 0 0 LSB 3.0 0 0 0 LSB 2.0 0 0 0 3x _mm_shuffle_ps 4x _mm_store_ss 1.0 2.0 3.0 4.0 memory 7 instructions , shorter critical path Shuffle __m128i _mm_alignr_epi8 ( __m128i a , __m128i b , const int n ) Concatenate a and b and extract byte-aligned result shifted to the right by n bytes Example : View __m128i as 4 32-bit ints ; n = 12 LSB 1 2 3 4 b LSB 5 6 7 8 a n = 12 bytes LSB 4 5 6 7 c How to use this with floating point vectors ? Use with _mm_castsi128_ps ! 57 58 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example void shift ( float * x , float * y , int n ) { for ( int i = 0 ; i < n-1 ; i++ ) y [ i ] = x [ i+1 ] ; y [ n-1 ] = 0 ; } # include < ia32intrin.h > // n a multiple of 4 , x , y are 16-byte aligned void shift_vec ( float * x , float * y , int n ) { __m128 f ; __m128i i1 , i2 , i3 ; i1 = _mm_castps_si128 ( _mm_load_ps ( x ) ) ; // load first 4 floats and cast to int for ( int i = 0 ; i < n-8 ; i = i + 4 ) { i2 = _mm_castps_si128 ( _mm_load_ps ( x+4+i ) ) ; // load next 4 floats and cast to int f = _mm_castsi128_ps ( _mm_alignr_epi8 ( i2 , i1,4 ) ) ; // shift and extract and cast back _mm_store_ps ( y+i , f ) ; // store it i1 = i2 ; // make 2nd element 1st } // we are at the last 4 i2 = _mm_castps_si128 ( _mm_setzero_ps ( ) ) ; // set the second vector to 0 and cast to int f = _mm_castsi128_ps ( _mm_alignr_epi8 ( i2 , i1,4 ) ) ; // shift and extract and cast back _mm_store_ps ( y+n-4 , f ) ; // store it } Shuffle __m128i _mm_shuffle_epi8 ( __m128i a , __m128i mask ) Result is filled in each position by any element of a or with 0 , as specified by mask Example : View __m128i as 4 32-bit ints LSB 1 2 3 4 a LSB 4 1 0 2 c Use with _mm_castsi128_ps to do the same for floating point 59 60 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Shuffle __m128 _mm_blendv_ps ( __m128 a , __m128 b , __m128 mask ) ( SSE4 ) Result is filled in each position by an element of a or b in the same position as specified by mask Example : LSB 0x0 0xffffffff 0x0 0x0 mask LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 1.0 1.5 3.0 4.0 c see also _mm_blend_ps Example ( Continued From Before ) void fcond ( float * x , size_t n ) { int i ; for ( i = 0 ; i < n ; i++ ) { if ( x [ i ] > 0.5 ) x [ i ] += 1. ; else x [ i ] -= 1. ; } } # include < xmmintrin.h > void fcond ( float * a , size_t n ) { int i ; __m128 vt , vmask , vp , vm , vr , ones , mones , thresholds ; ones = _mm_set1_ps ( 1 . ) ; = _mm_set1_ps ( -1 . ) ; mones thresholds = _mm_set1_ps ( 0.5 ) ; for ( i = 0 ; i < n ; i+=4 ) { = _mm_load_ps ( a+i ) ; vt vmask = _mm_cmpgt_ps ( vt , thresholds ) ; vb vr = _mm_blendv_ps ( ones , mones , vmask ) ; = _mm_add_ps ( vt , vb ) ; } } 61 62 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Shuffle _MM_TRANSPOSE4_PS ( row0 , row1 , row2 , row3 ) Macro for 4 x 4 matrix transposition : The arguments row0 , … , row3 are __m128 values each containing a row of a 4 x 4 matrix . After execution , row0 , .. , row 3 contain the columns of that matrix . LSB 1.0 2.0 3.0 4.0 row0 LSB 1.0 5.0 9.0 13.0 row0 LSB 5.0 6.0 7.0 8.0 row1 LSB 2.0 6.0 10.0 14.0 row1 LSB 9.0 10.0 11.0 12.0 row2 LSB 3.0 7.0 11.0 15.0 row2 LSB 13.0 14.0 15.0 16.0 row3 LSB 4.0 8.0 12.0 16.0 row3 In SSE : 8 shuffles ( 4 _mm_unpacklo_ps , 4 _mm_unpackhi_ps ) Vectorization With Intrinsics : Key Points  Use aligned loads and stores  Minimize overhead ( shuffle instructions ) = maximize vectorization efficiency  Definition : Vectorization efficiency Op count of scalar ( unvectorized ) code Op count of vectorized code includes shuffles does not include loads/stores  Ideally : Efficiency = ν for ν-way vector instructions  assumes no vector instruction does more than ν scalar ops  assumes every vector instruction has the same cost ( not true : see hadd for example ) 63 64 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Vectorization Efficiency : Example 2  4 x 4 matrix-vector multiplication  Blackboard LSB LSB LSB LSB a b c d LSB LSB = x y SIMD Extensions and SSE  Overview : SSE family  SSE intrinsics  Compiler vectorization References : Intel icc manual ( look for auto vectorization ) 65 66 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Compiler Vectorization  Compiler flags  Aliasing  Proper code style  Alignment Compiler Flags ( icc 12.0 ) Linux * OS and Mac OS * X Windows * OS Description -vec -no-vec /Qvec /Qvec- Enables or disables vectorization and transformations enabled for vectorization . Vectorization is enabled by default . To disable , use -no-vec ( Linux * and MacOS * X ) or /Qvec- ( Windows * ) option . Supported on IA-32 and Intel® 64 architectures only . -vec-report /Qvec-report Controls the diagnostic messages from the vectorizer . See Vectorization Report . -simd -no-simd /Qsimd /Qsimd- Controls user-mandated ( SIMD ) vectorization . User-mandated ( SIMD ) vectorization is enabled by default . Use the -no-simd ( Linux * or MacOS * X ) or /Qsimd- ( Windows * ) option to disable SIMD transformations for vectorization . Architecture flags : Linux : -xHost ¾ -mHost Windows : /QxHost ¾ /Qarch : Host Host in { SSE2 , SSE3 , SSSE3 , SSE4.1 , SSE4.2 } Default : -mSSE2 , /Qarch : SSE2 67 68 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 How Do I Know the Compiler Vectorized ?  vec-report ( previous slide )  Look at assembly : mulps , addps , xxxps  Generate assembly with source code annotation :  Visual Studio + icc : /Fas  icc on Linux/Mac : -S 69 void myadd ( float * a , float * b , const int n ) { for ( int i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; } Example unvectorized : /Qvec- < more > ; ; ; a [ i ] = a [ i ] + b [ i ] ; movss addss movss < more > xmm0 , DWORD PTR [ rcx+rax * 4 ] xmm0 , DWORD PTR [ rdx+rax * 4 ] DWORD PTR [ rcx+rax * 4 ] , xmm0 vectorized : xmm0 , DWORD PTR [ rcx+r11 * 4 ] xmm0 , DWORD PTR [ rdx+r11 * 4 ] DWORD PTR [ rcx+r11 * 4 ] , xmm0 < more > ; ; ; a [ i ] = a [ i ] + b [ i ] ; movss addss movss … movups movups addps addps movaps movaps < more > xmm0 , XMMWORD PTR [ rdx+r10 * 4 ] xmm1 , XMMWORD PTR [ 16+rdx+r10 * 4 ] xmm0 , XMMWORD PTR [ rcx+r10 * 4 ] xmm1 , XMMWORD PTR [ 16+rcx+r10 * 4 ] XMMWORD PTR [ rcx+r10 * 4 ] , xmm0 XMMWORD PTR [ 16+rcx+r10 * 4 ] , xmm1 why this ? why everything twice ? why movups and movaps ? unaligned aligned 70 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Aliasing for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; Can not be vectorized in a straightforward way due to potential aliasing . However , in this case compiler can insert runtime check : if ( a + n < b || b + n < a ) / * vectorized loop * / ... else / * serial loop * / ... Removing Aliasing  Globally with compiler flag :  -fno-alias , /Oa  -fargument-noalias , /Qalias-args- ( function arguments only )  For one loop : pragma void add ( float * a , float * b , int n ) { # pragma ivdep for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; }  For specific arrays : restrict ( needs compiler flag –restrict , /Qrestrict ) void add ( float * restrict a , float * restrict b , int n ) { for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; } 71 72 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Proper Code Style  Use countable loops = number of iterations known at runtime  Number of iterations is a : constant loop invariant term linear function of outermost loop indices  Countable or not ? for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; void vsum ( float * a , float * b , float * c ) { int i = 0 ; while ( a [ i ] > 0.0 ) { a [ i ] = b [ i ] * c [ i ] ; i++ ; } } Proper Code Style  Use arrays , structs of arrays , not arrays of structs  Ideally : unit stride access in innermost loop void mmm1 ( float * a , float * b , float * c ) { int N = 100 ; int i , j , k ; for ( i = 0 ; i < N ; i++ ) for ( j = 0 ; j < N ; j++ ) for ( k = 0 ; k < N ; k++ ) c [ i ] [ j ] = c [ i ] [ j ] + a [ i ] [ k ] * b [ k ] [ j ] ; } void mmm2 ( float * a , float * b , float * c ) { int N = 100 ; int i , j , k ; for ( i = 0 ; i < N ; i++ ) for ( k = 0 ; k < N ; k++ ) for ( j = 0 ; j < N ; j++ ) c [ i ] [ j ] = c [ i ] [ j ] + a [ i ] [ k ] * b [ k ] [ j ] ; } 73 74 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Alignment float * x = ( float * ) malloc ( 1024 * sizeof ( float ) ) ; int i ; for ( i = 0 ; i < 1024 ; i++ ) x [ i ] = 1 ; Can not be vectorized in a straightforward way since x may not be aligned However , the compiler can peel the loop to extract aligned part : float * x = ( float * ) malloc ( 1024 * sizeof ( float ) ) ; int i ; peel = x & 0x0f ; / * x mod 16 * / if ( peel ! = 0 ) { peel = 16 - peel ; / * initial segment * / for ( i = 0 ; i < peel ; i++ ) x [ i ] = 1 ; } / * 16-byte aligned access * / for ( i = peel ; i < 1024 ; i++ ) x [ i ] = 1 ; Ensuring Alignment  Align arrays to 16-byte boundaries ( see earlier discussion )  If compiler can not analyze :  Use pragma for loops float * x = ( float * ) malloc ( 1024 * sizeof ( float ) ) ; int i ; # pragma vector aligned for ( i = 0 ; i < 1024 ; i++ ) x [ i ] = 1 ;  For specific arrays : __assume_aligned ( a , 16 ) ; 75 76 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 More Tips ( icc 14.0 ) https : //software.intel.com/en-us/node/512631  Use simple for loops . Avoid complex loop termination conditions – the upper iteration limit must be invariant within the loop . For the innermost loop in a nest of loops , you could set the upper limit iteration to be a function of the outer loop indices .  Write straight-line code . Avoid branches such as switch , goto , or return statements , most function calls , orif constructs that can not be treated as masked assignments .   Avoid dependencies between loop iterations or at the least , avoid read-after-write dependencies . Try to use array notations instead of the use of pointers . C programs in particular impose very few restrictions on the use of pointers ; aliased pointers may lead to unexpected dependencies . Without help , the compiler often can not tell whether it is safe to vectorize code containing pointers .  Wherever possible , use the loop index directly in array subscripts instead of incrementing a separate counter for use as an array address .  Access memory efficiently : Favor inner loops with unit stride .   Minimize indirect addressing .  Align your data to 16 byte boundaries ( for SSE instructions ) .   Choose a suitable data layout with care . Most multimedia extension instruction sets are rather sensitive to alignment . … 77 void myadd ( float * a , float * b , const int n ) { for ( int i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; } Yes : Through versioning © Markus Püschel Computer Science Assume : • No aliasing information • No alignment information Can compiler vectorize ? function runtime check a , b potentially aliased ? no yes runtime check a , b aligned ? unvectorized loop yes , yes yes , no no , yes no , no vectorized loop aligned loads vectorized loop aligned and unaligned loads or peeling and aligned loads vectorized loop unaligned loads or peeling and aligned loads © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Compiler Vectorization  Read manual 79 © Markus Püschel Computer Science How to write fast numerical code Spring 2016