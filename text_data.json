{
    "1-Pipeline_Hazards.txt": "Computer Architecture Pipeline : Hazards CSCE430/830 Portions of these slides are derived from : Dave Patterson © UCB Pipeline Hazards Pipeline Hazards • Where one instruction can not immediately follow another • Types of hazards – Structural hazards - attempt to use the same resource by two or more instructions – Control hazards - attempt to make branching decisions before branch condition is evaluated – Data hazards - attempt to use data before it is ready • Can always resolve hazards by waiting ( stalling the pipeline ) CSCE430/830 Pipeline Hazards Structural Hazards • Attempt to use the same resource by two or more instructions at the same time • Example : Single Memory for instructions and data – Accessed by IF stage – Accessed at same time by MEM stage • Solutions – Delay the second access by one clock cycle , OR – Provide separate memories for instructions & data » This is what the book does » This is called a “ Harvard Architecture ” » Real pipelined processors have separate caches CSCE430/830 Pipeline Hazards Pipelined Example - Executing Multiple Instructions • Consider the following instruction sequence : lw $ r2 , 12 ( $ r1 ) sw $ r3 , 20 ( $ r4 ) add $ r5 , $ r6 , $ r7 sub $ r8 , $ r9 , $ r10 CSCE430/830 Pipeline Hazards Alternative View - Multicycle Diagram CC 1 CC 2 CC 3 CC 4 CC 5 CC 6 CC 7 CC 8 lw $ r0 , 10 ( $ r1 ) IM REG ALU DM REG sw $ r3 , 20 ( $ r4 ) IM REG ALU DM REG add $ r5 , $ r6 , $ r7 IM REG ALU DM REG sub $ r8 , $ r9 , $ r10 IM REG ALU DM REG CSCE430/830 Pipeline Hazards Alternative View - Multicycle Diagram CC 1 CC 2 CC 3 CC 4 CC 5 CC 6 CC 7 CC 8 lw $ r0 , 10 ( $ r1 ) IM REG ALU DM REG Memory Conflict sw $ r3 , 20 ( $ r4 ) IM REG ALU DM REG add $ r5 , $ r6 , $ r7 IM REG ALU DM REG sub $ r8 , $ r9 , $ r10 IM REG ALU DM REG CSCE430/830 Pipeline Hazards One Memory Port Structural Hazards Time ( clock cycles ) Cycle 1 Cycle 2 Cycle 3 Cycle 4 Cycle 5 Cycle 6 Cycle 7 Load Ifetch Reg U L A DMem Reg Instr 1 Ifetch Reg U L A DMem Reg Instr 2 Stall Instr 3 Ifetch Reg U L A DMem Reg Bubble Bubble Bubble Bubble Bubble Ifetch Reg U L A DMem Reg I n s t r. O r d e r CSCE430/830 Pipeline Hazards Dealing with Structural Hazards low cost , simple Increases CPI Stall • • • use for rare case since stalling has performance effect Pipeline hardware resource • useful for multi-cycle resources • good performance • sometimes complex e.g. , RAM Replicate resource • good performance • • useful for cheap or divisible resources increases cost ( + maybe interconnect delay ) CSCE430/830 Pipeline Hazards Structural Hazards Avoidance • Structural hazards are reduced with these rules : – Each instruction uses a resource at most once – Always use the resource in the same pipeline stage – Use the resource for one cycle only • Many RISC ISAs are designed with this in mind • Sometimes very difficult to do this . – For example , memory of necessity is used in the IF and MEM stages . CSCE430/830 Pipeline Hazards Data Hazards • Data hazards occur when data is used before it is ready Time ( in clock cycles ) Value of register $ 2 : CC 1 10 CC 2 10 CC 3 10 CC 4 10 CC 5 10/– 20 CC 6 – 20 CC 7 – 20 CC 8 – 20 CC 9 – 20 Program execution order ( in instructions ) sub $ 2 , $ 1 , $ 3 IM Reg DM Reg and $ 12 , $ 2 , $ 5 IM Reg DM Reg or $ 13 , $ 6 , $ 2 IM Reg DM Reg add $ 14 , $ 2 , $ 2 IM Reg DM Reg sw $ 15 , 100 ( $ 2 ) IM Reg DM Reg The use of the result of the SUB instruction in the next three instructions causes a data hazard , since the register $ 2 is not written until after those instructions read it . CSCE430/830 Pipeline Hazards Data Hazards Execution Order is : InstrI InstrJ Read After Write ( RAW ) InstrJ tries to read operand before InstrI writes it I : add r1 , r2 , r3 J : sub r4 , r1 , r3 • Caused by a “ Dependence ” . This hazard results from an actual need for communication . CSCE430/830 Pipeline Hazards Execution Order is : InstrI InstrJ Write After Read ( WAR ) InstrJ tries to write operand before InstrI reads i – Gets wrong operand Data Hazards I : sub r4 , r1 , r3 J : add r1 , r2 , r3 K : mul r6 , r1 , r7 – Called an “ anti-dependence ” by compiler writers . This results from reuse of the name “ r1 ” . • Can ’ t happen in MIPS 5 stage pipeline because : – All instructions take 5 stages , and – Reads are always in stage 2 , and – Writes are always in stage 5 CSCE430/830 Pipeline Hazards Execution Order is : InstrI InstrJ Write After Write ( WAW ) InstrJ tries to write operand before InstrI writes it – Leaves wrong result ( InstrI not InstrJ ) Data Hazards I : sub r1 , r4 , r3 J : add r1 , r2 , r3 K : mul r6 , r1 , r7 • Called an “ output dependence ” by compiler writers This also results from the reuse of name “ r1 ” . • Can ’ t happen in MIPS 5 stage pipeline because : – All instructions take 5 stages , and – Writes are always in stage 5 • Will see WAR and WAW later in more complicated pipes CSCE430/830 Pipeline Hazards Data Hazard Detection in MIPS ( 1 ) Read after Write Time ( in clock cycles ) Value of register $ 2 : CC 1 10 CC 2 10 CC 3 10 CC 4 10 CC 5 10/– 20 CC 6 – 20 CC 7 – 20 CC 8 – 20 CC 9 – 20 Program execution order ( in instructions ) IF/ID ID/EX EX/MEM MEM/WB sub $ 2 , $ 1 , $ 3 IM Reg DM Reg and $ 12 , $ 2 , $ 5 IM Reg DM Reg or $ 13 , $ 6 , $ 2 IM Reg DM Reg add $ 14 , $ 2 , $ 2 IM Reg DM Reg sw $ 15 , 100 ( $ 2 ) IM Reg DM Reg 1a : EX/MEM.RegisterRd = ID/EX.RegisterRs 1b : EX/MEM.RegisterRd = ID/EX.RegisterRt 2a : MEM/WB.RegisterRd = ID/EX.RegisterRs 2b : MEM/WB.RegisterRd = ID/EX.RegisterRt EX hazard MEM hazard CSCE430/830 Pipeline Hazards Data Hazards • Solutions for Data Hazards – Stalling – Forwarding : » connect new value directly to next stage – Reordering CSCE430/830 Pipeline Hazards Data Hazard - Stalling 0 2 4 6 8 10 12 16 18 add $ s0 , $ t0 , $ t1 IF ID EX MEM W s0 $ s0 written here STALL STALL sub $ t2 , $ s0 , $ t3 BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE IF R s0 EX MEM WB $ s0 read here CSCE430/830 Pipeline Hazards Data Hazards - Stalling Simple Solution to RAW • Hardware detects RAW and stalls • Assumes register written then read each cycle + low cost to implement , simple -- reduces IPC ( increases CPI ) • Try to minimize stalls Minimizing RAW stalls • Bypass/forward/shortcircuit ( We will use the word “ forward ” ) • Use data before it is in the register + reduces/avoids stalls -- complex • Crucial for common RAW hazards CSCE430/830 Pipeline Hazards Data Hazards - Forwarding • Key idea : connect new value directly to next stage • Still read s0 , but ignore in favor of new result • • Problem : what about load instructions ? CSCE430/830 Pipeline Hazards Data Hazards - Forwarding • STALL still required for load - data avail . after MEM • MIPS architecture calls this delayed load , initial implementations required compiler to deal with this 0 2 4 6 8 10 12 16 18 lw $ s0,20 ( $ t1 ) IF ID ID EX MEM W s0 STALL BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE new value of s0 sub $ t2 , $ s0 , $ t3 IF R s0 EX MEM WB CSCE430/830 Pipeline Hazards Data Hazards LW R1 , 0 ( R2 ) IF SUB R4 , R1 , R5 AND R6 , R1 , R7 OR R8 , R1 , R9 This is another representation of the stall . ID IF EX MEM WB ID IF EX MEM WB ID IF EX ID MEM WB EX MEM WB LW R1 , 0 ( R2 ) IF SUB R4 , R1 , R5 AND R6 , R1 , R7 OR R8 , R1 , R9 ID IF EX ID IF MEM WB stall stall stall EX MEM WB ID IF EX ID MEM WB EX MEM WB CSCE430/830 Pipeline Hazards Forwarding Key idea : connect data internally before it 's stored Time ( in clock cycles ) Value of register $ 2 : CC 1 10 CC 2 10 CC 3 10 CC 4 10 CC 5 10/– 20 CC 6 – 20 CC 7 – 20 CC 8 – 20 CC 9 – 20 Program execution order ( in instructions ) IF/ID ID/EX EX/MEM MEM/WB sub $ 2 , $ 1 , $ 3 IM Reg DM Reg and $ 12 , $ 2 , $ 5 IM Reg DM Reg or $ 13 , $ 6 , $ 2 IM Reg DM Reg add $ 14 , $ 2 , $ 2 IM Reg DM Reg sw $ 15 , 100 ( $ 2 ) IM Reg DM Reg How would you design the forwarding ? CSCE430/830 Pipeline Hazards No Forwarding CSCE430/830 Pipeline Hazards Data Hazard Solution : Forwarding • Key idea : connect data internally before it 's stored Time ( in clock cycles ) CC 1 CC 2 CC 3 Value of register $ 2 : Value of EX/MEM : Value of MEM/WB : 10 X X 10 X X 10 X X CC 4 10 – 20 X CC 5 10/– 20 X – 20 CC 6 – 20 X X CC 7 – 20 X X CC 8 CC 9 – 20 X X – 20 X X Program execution order ( in instructions ) sub $ 2 , $ 1 , $ 3 IM Reg DM Reg and $ 12 , $ 2 , $ 5 IM Reg DM Reg or $ 13 , $ 6 , $ 2 IM Reg DM Reg add $ 14 , $ 2 , $ 2 IM Reg DM Reg sw $ 15 , 100 ( $ 2 ) IM Reg DM Reg Assumption : • The register file forwards values that are read and written during the same cycle . CSCE430/830 Pipeline Hazards Forwarding 00 01 10 00 01 10 CSCE430/830 Add hardware to feed back ALU and MEM results to both ALU inputs Pipeline Hazards Controlling Forwarding • Need to test when register numbers match in rs , rt , and rd fields stored in pipeline registers • `` EX '' hazard : – EX/MEM - test whether instruction writes register file and examine rd register – ID/EX - test whether instruction reads rs or rt register and matches rd register in EX/MEM • `` MEM '' hazard : – MEM/WB - test whether instruction writes register file and examine rd ( rt ) register – ID/EX - test whether instruction reads rs or rt register and matches rd ( rt ) register in EX/MEM CSCE430/830 Pipeline Hazards Forwarding Unit Detail - EX Hazard if ( EX/MEM.RegWrite ) and ( EX/MEM.RegisterRd ≠ 0 ) and ( EX/MEM.RegisterRd = ID/EX.RegisterRs ) ) ForwardA = 10 if ( EX/MEM.RegWrite ) and ( EX/MEM.RegisterRd ≠ 0 ) and ( EX/MEM.RegisterRd = ID/EX.RegisterRt ) ) ForwardB = 10 CSCE430/830 Pipeline Hazards Forwarding Unit Detail - MEM Hazard if ( MEM/WB.RegWrite ) and ( MEM/WB.RegisterRd ≠ 0 ) and ( MEM/WB.RegisterRd = ID/EX.RegisterRs ) ) ForwardA = 01 if ( MEM/WB.RegWrite ) and ( MEM/WB.RegisterRd ≠ 0 ) and ( MEM/WB.RegisterRd = ID/EX.RegisterRt ) ) ForwardB = 01 CSCE430/830 Pipeline Hazards Data Hazards and Stalls • So far , we ’ ve only addressed “ potential ” data hazards , where the forwarding unit was able to detect and resolve them without affecting the performance of the pipeline . • There are also “ unavoidable ” data hazards , which the forwarding unit can not resolve , and whose resolution does affect pipeline performance . • We thus add a ( unavoidable ) hazard detection unit , which detects them and introduces stalls to resolve them . CSCE430/830 Pipeline Hazards Data Hazards & Stalls • Identify the true data hazard in this sequence : LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 LW ADD 1 2 IF ID IF 3 EX 4 5 6 MEM WB ID EX MEM WB CSCE430/830 Pipeline Hazards Data Hazards & Stalls • Identify the true data hazard in this sequence : LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 LW ADD 1 2 IF ID IF 3 EX 4 5 6 MEM WB ID EX MEM WB • LW doesn ’ t write $ s0 to Reg File until the end of CC5 , but ADD reads $ s0 from Reg File in CC3 CSCE430/830 Pipeline Hazards Data Hazards & Stalls LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 LW ADD 1 2 IF ID IF 3 EX 4 5 6 MEM WB ID EX MEM WB • EX/MEM forwarding won ’ t work , because the data isn ’ t loaded from memory until CC4 ( so it ’ s not in EX/MEM register ) CSCE430/830 Pipeline Hazards Data Hazards & Stalls LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 LW ADD 1 2 IF ID IF 3 EX 4 5 6 MEM WB ID EX MEM WB • MEM/WB forwarding won ’ t work either , because ADD executes in CC4 CSCE430/830 Pipeline Hazards Data Hazards & Stalls : implementation LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 1 2 ID IF LW IF ADD 3 EX ID 4 5 6 MEM WB ID bubbl e EX MEM WB • We must handle this hazard by “ stalling ” the pipeline for 1 Clock Cycle ( bubble ) CSCE430/830 Pipeline Hazards Data Hazards & Stalls : implementation LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 1 2 ID IF LW IF ADD 3 EX ID 4 5 6 MEM WB ID bubbl e EX MEM WB • We can then use MEM/WB forwarding , but of course there is still a performance loss CSCE430/830 Pipeline Hazards Data Hazards & Stalls : implementation • Stall Implementation # 1 : Compiler detects hazard and inserts a NOP ( no reg changes ( SLL $ 0 , $ 0 , 0 ) ) LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value NOP ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 ; dummy instruction 1 2 IF ID 3 EX 4 5 6 MEM WB IF bubbl e ID bubbl e EX bubbl e MEM bubbl e WB bubbl e IF ID EX MEM WB LW NOP ADD • Problem : we have to rely on the compiler CSCE430/830 Pipeline Hazards Data Hazards & Stalls : implementation • Stall Implementation # 2 : Add a “ hazard detection unit ” to stall current instruction for 1 CC if : • ID-Stage Hazard Detection and Stall Condition : If ( ( ID/EX.MemRead = 1 ) & ( ( ID/EX.RegRT = IF/ID.RegRS ) || ; RS will read load dest ( RT ) ( ID/EX.RegRT = IF/ID.RegRT ) ) ) ; RT will read load dest ; only a LW reads mem LW $ s0 , 100 ( $ t0 ) ; $ s0 = memory value ADD $ t2 , $ s0 , $ t3 ; $ t2 = $ s0 + $ t3 LW IF ADD CSCE430/830 ID IF EX MEM WB ID EX MEM WB Pipeline Hazards Data Hazards & Stalls : implementation • The effect of this stall will be to repeat the ID Stage of the current instruction . Then we do the MEM/WB forwarding on the next Clock Cycle LW ADD IF ID EX MEM WB IF ID ID EX MEM WB • We do this by preserving the current values in IF/ID for use on the next Clock Cycle CSCE430/830 Pipeline Hazards Data Hazards : A Classic Example • Identify the data dependencies in the following code . Which of them can be resolved through forwarding ? SUB $ 2 , $ 1 , $ 3 OR $ 12 , $ 2 , $ 5 SW $ 13 , 100 ( $ 2 ) ADD $ 14 , $ 2 , $ 2 LW $ 15 , 100 ( $ 2 ) ADD $ 4 , $ 7 , $ 15 CSCE430/830 Pipeline Hazards Reordering example • LW $ 10 , 12 ( $ 2 ) • ADD $ 11 , $ 10 , $ 12 • AND $ 14 , $ 14 , $ 15 • Reorder • LW $ 10 , 12 ( $ 2 ) • AND $ 14 , $ 14 , $ 15 • ADD $ 11 , $ 10 , $ 12 CSCE430/830 Pipeline Hazards Code Scheduling to Avoid Stalls • Reorder code to avoid use of load result in the next instruction • C code for A = B + E ; C = B + F ; $ t1 , 0 ( $ t0 ) $ t2 , 4 ( $ t0 ) lw lw add $ t3 , $ t1 , $ t2 sw lw add $ t5 , $ t1 , $ t4 sw $ t3 , 12 ( $ t0 ) $ t4 , 8 ( $ t0 ) $ t5 , 16 ( $ t0 ) stall stall $ t1 , 0 ( $ t0 ) $ t2 , 4 ( $ t0 ) $ t4 , 8 ( $ t0 ) lw lw lw add $ t3 , $ t1 , $ t2 sw add $ t5 , $ t1 , $ t4 sw $ t3 , 12 ( $ t0 ) $ t5 , 16 ( $ t0 ) 13 cycles 11 cycles CSCE430/830 Pipeline Hazards Data Hazard Summary • Three types of data hazards – RAW ( MIPS ) – WAW ( not in MIPS ) – WAR ( not in MIPS ) • Solution to RAW in MIPS – Stall – Forwarding » Detection & Control • EX hazard • MEM hazard » A stall is needed if read a register after a load instruction that writes the same register . – Reordering CSCE430/830 Pipeline Hazards Control Hazards A control hazard is when we need to find the destination of a branch , and can ’ t fetch any new instructions until we know that destination . A branch is either – Taken : PC < = PC + 4 + Immediate – Not Taken : PC < = PC + 4 CSCE430/830 Pipeline Hazards Control Hazards Control Hazard on Branches Three Stage Stall 10 : beq r1 , r3,36 Ifetch Reg U L A DMem Reg 14 : and r2 , r3 , r5 Ifetch Reg U L A DMem Reg 18 : or r6 , r1 , r7 Ifetch Reg U L A DMem Reg 22 : add r8 , r1 , r9 36 : xor r10 , r1 , r11 Ifetch Reg U L A DMem Reg Ifetch Reg U L A DMem Reg The penalty when branch taken is 3 cycles ! CSCE430/830 Pipeline Hazards Branch Hazards • Just stalling for each branch is not practical • Common assumption : branch not taken • When assumption fails : flush three instructions Program execution order ( in instructions ) Time ( in clock cycles ) CC 1 CC 2 CC 3 CC 4 CC 5 CC 6 CC 7 CC 8 CC 9 40 beq $ 1 , $ 3 , 7 IM Reg DM Reg 44 and $ 12 , $ 2 , $ 5 IM Reg DM Reg 48 or $ 13 , $ 6 , $ 2 IM Reg DM Reg 52 add $ 14 , $ 2 , $ 2 IM Reg DM Reg 72 lw $ 4 , 50 ( $ 7 ) IM Reg DM Reg CSCE430/830 ( Fig . 6.37 ) Pipeline Hazards Basic Pipelined Processor = In our original Design , branches have a penalty of 3 cycles CSCE430/830 Pipeline Hazards Reducing Branch Delay Move following to ID stage a ) Branch-target address calculation b ) Branch condition decision = Reduced penalty ( 1 cycle ) when branch taken ! CSCE430/830 Pipeline Hazards Reducing Branch Delay • Key idea : move branch logic to ID stage of pipeline – New adder calculates branch target ( PC + 4 + extend ( IMM ) ) – New hardware tests rs == rt after register read • Reduced penalty ( 1 cycle ) when branch taken CSCE430/830 Pipeline Hazards Control Hazard Solutions • Stall ( software/hardware ) - software : insert NOP by compiler – Hardware : stop loading instructions until result is available • Predict ( Hardware ) – assume an outcome and continue fetching ( undo if prediction is wrong ) – loose cycles only on mis-prediction » static branch prediction : base guess on instruction type » dynamic branch prediction : base guess on execution history • Delayed branch ( software ) – specify in architecture that the instruction immediately following branch is always executed Compiler puts something useful ( or a no-op ) there . CSCE430/830 Pipeline Hazards Branch Behavior in Programs • Based on SPEC benchmarks on DLX – Branches occur with a frequency of 14 % to 16 % in integer programs and 3 % to 12 % in floating point programs . – About 75 % of the branches are forward branches – 60 % of forward branches are taken – 80 % of backward branches are taken – 67 % of all branches are taken • Why are branches ( especially backward branches ) more likely to be taken than not taken ? CSCE430/830 Pipeline Hazards Static Branch Prediction For every branch encountered during execution predict whether the branch will be taken or not taken . Predicting branch not taken : 1 . 2 . Speculatively fetch and execute in-line instructions following the branch If prediction incorrect flush pipeline of speculated instructions • Convert these instructions to NOPs by clearing pipeline registers • These have not updated memory or registers at time of flush Predicting branch taken : Speculatively fetch and execute instructions at the branch target address 1 . 2 . Useful only if target address known earlier than branch outcome • May require stall cycles till target address known • Flush pipeline if prediction is incorrect • Must ensure that flushed instructions do not update memory/register Predicting backward taken , forward not taken ( BTFN ) Predict backward ( loop ) branches as taken , others not-taken CSCE430/830 Pipeline Hazards Control Hazard - Stall 0 2 4 6 8 10 12 16 18 add $ r4 , $ r5 , $ r6 IF ID EX MEM WB beq $ r0 , $ r1 , tgt IF ID EX MEM WB STALL BUBBLE BUBBLE BUBBLE BUBBLE BUBBLE sw $ s4,200 ( $ t5 ) IF ID EX MEM WB beq writes PC here new PC used here CSCE430/830 Pipeline Hazards Control Hazard - Correct Prediction 0 2 4 6 8 10 12 16 18 add $ r4 , $ r5 , $ r6 IF ID EX MEM WB beq $ r0 , $ r1 , tgt IF ID EX MEM WB tgt : sw $ s4,200 ( $ t5 ) IF ID EX MEM WB Fetch assuming branch taken CSCE430/830 Pipeline Hazards Control Hazard - Incorrect Prediction 0 2 4 6 8 10 12 16 18 add $ r4 , $ r5 , $ r6 IF ID EX MEM WB beq $ r0 , $ r1 , tgt IF ID EX MEM WB tgt : sw $ s4,200 ( $ t5 ) ( incorrect - STALL ) IF BUBBLE BUBBLE BUBBLE BUBBLE or $ r8 , $ r8 , $ r9 IF ID EX MEM WB “ Squashed ” instruction CSCE430/830 Pipeline Hazards 1-Bit Branch Prediction • Branch History Table ( BHT ) : Lower bits of PC address index table of 1-bit values – Says whether or not the branch was taken last time – No address check ( saves HW , but may not be the right branch ) – If prediction is wrong , invert prediction bit 1 = branch was last taken 0 = branch was last not taken 1K-entry BHT 1 0 1 prediction bit a31a30…a11…a2a1a0 branch instruction 10-bit index CSCE430/830 Hypothesis : branch will do the same again . Pipeline Hazards Instruction memory 1-Bit Branch Prediction • Example : Consider a loop branch that is taken 9 times in a row and then not taken once . What is the prediction accuracy of the 1-bit predictor for this branch assuming only this branch ever changes its corresponding prediction bit ? – Answer : 80 % . Because there are two mispredictions – one on the first iteration and one on the last iteration . Is this good enough and Why ? CSCE430/830 Pipeline Hazards 2-Bit Branch Prediction ( Jim Smith , 1981 ) • Solution : a 2-bit scheme where prediction is changed only if mispredicted twice Red : not taken Green : taken T Predict Taken 11 T 01 Predict Not Taken NT T NT T 10 Predict Taken NT 00 NT Predict Not Taken CSCE430/830 Pipeline Hazards n-bit Saturating Counter – Values : 0 ~ 2n-1 – counter can hold values between 0 and 2n-1 – predict taken when value is greater than or equal to half of maximum value : – The counter is incremented on each taken branch – and decremented on each not taken branch • Studies have shown that the 2-bit predictors do almost as well , and thus most systems rely on 2-bit branch predictors . CSCE430/830 Pipeline Hazards 2-bit Predictor Statistics Prediction accuracy of 4K-entry 2-bit prediction buffer on SPEC89 benchmarks : accuracy is lower for integer programs ( gcc , espresso , eqntott , li ) than for FP CSCE430/830 Pipeline Hazards 2-bit Predictor Statistics Prediction accuracy of 4K-entry 2-bit prediction buffer vs. “ infinite ” 2-bit buffer : increasing buffer size from 4K does not significantly improve performance CSCE430/830 Pipeline Hazards Correlated Predictor The rationale : • having the prediction depend on the outcome of only 1 branch might produce bad predictions • some branch outcomes are correlated example : same condition variable if ( d==0 ) ... if ( d ! =0 ) example : related condition variable if ( d==0 ) b=1 ; if ( b==1 ) 6/16/20 CSCE430/830 Pipeline Hazards Correlated Predictor another example : related condition variables if ( x==2 ) x=0 ; if ( y==2 ) y=0 ; if ( x ! =y ) / * branch 1 * / / * branch 2 * / / * branch 3 * / do this ; else do that ; » if branches 1 & 2 are taken , branch 3 is not taken Þ use a history of the past m branches represents a path through the program ( but still n bits of prediction ) 6/16/20 CSCE430/830 Pipeline Hazards Correlated Predictor General idea of correlated branch prediction : • put the global branch history in a global history register » global history is a shift register : shift left in the new branch outcome • use its value to access a pattern history table ( PHT ) of 2-bit saturating counters 6/16/20 CSCE430/830 Pipeline Hazards Tournament Predictors • A local predictor might work well for some branches or programs , while a global predictor might work well for others • Provide one of each and maintain another predictor to identify which predictor is best for each branch Local Predictor Global Predictor Tournament Predictor M U X Branch PC CSCE430/830 Table of 2-bit saturating counters 63 Pipeline Hazards % of predictions from local predictor in Tournament Prediction Scheme 0 % 20 % 40 % 60 % 80 % 100 % nasa7 matrix300 tomcatv doduc spice fpppp gcc espresso eqntott li 98 % 100 % 94 % 90 % 55 % 76 % 72 % 63 % 69 % 37 % 64 CSCE430/830 Pipeline Hazards Accuracy of Branch Prediction tomcatv doduc fpppp li espresso gcc 99 % 99 % 100 % 84 % 95 % 97 % 86 % 82 % 88 % 77 % 98 % 98 % 86 % 82 % 96 % 70 % 88 % 94 % Profile-based 2-bit counter Tournament 0 % 20 % 40 % 60 % 80 % 100 % Branch prediction accuracy Profile : branch profile from last execution ( static in that the prediction is in encoded in the instruction , but derived from the real execution profile ) • A good dynamic predictor can outperform profile-driven static prediction by a large margin Pipeline Hazards 65 CSCE430/830 Tournament Predictor Combine branch predictors • local , per-branch prediction , accessed by the PC • correlated prediction based on the last m branches , assessed by the global history • indicator of which had been the best predictor for this branch » 2-bit counter : increase for one , decrease for the other • Compaq Alpha 21264 • ~5 % misprediction on SPEC95 • 2 % of die 6/16/20 CSCE430/830 Pipeline Hazards Branch Target Buffer ( BTB ) Cache that stores : the PCs of branches ( tag ) the predicted target address ( data ) branch prediction bits ( data ) Accessed by PC address in fetch stage if hit : address was for this branch instruction fetch the target instruction if prediction bits say taken No branch delay if : branch found in BTB prediction is correct ( assume BTB update is done in the next cycles ) 6/16/20 CSCE430/830 Pipeline Hazards Fetch Both Targets Fetch target & fall-through code • reduces the misprediction penalty • but requires lots of I-cache bandwidth » a dual-ported instruction cache » requires independent bank accessing » wide cache-to-pipeline buses 6/16/20 CSCE430/830 Pipeline Hazards Calculating the Cost of Branches Factors to consider : • branch frequency ( every 4-6 instructions ) • correct prediction rate » 1 bit : ~ 80 % to 85 % » 2 bit : ~ high 80s to 90 % » correlated branch prediction : ~ 95 % • misprediction penalty Alpha 21164 : 5 cycles ; 21264 : 7 cycles UltraSPARC 4 cycles Pentium Pro : at least 9 cycles , 15 on average • or misfetch penalty have the correct prediction but not know the target address yet ( may also apply to unconditional branches ) 6/16/20 CSCE430/830 Pipeline Hazards Summary - Control Hazard Solutions • Stall - stop fetching instr . until result is available – Significant performance penalty – Hardware required to stall • Predict - assume an outcome and continue fetching ( undo if prediction is wrong ) – Performance penalty only when guess wrong – Hardware required to `` squash '' instructions • Delayed branch - specify in architecture that following instruction is always executed – Compiler re-orders instructions into delay slot – Insert `` NOP '' ( no-op ) operations when ca n't use ( ~50 % ) – This is how original MIPS worked CSCE430/830 Pipeline Hazards",
    "10-memory (1).txt": "Memory Hierarchy and Cache Design 1 Why is memory important ? • Processor performance has increased at a much faster rate than memory performance , making main memory the bottleneck . CPU-DRAM Gap • 1980 : no cache in mproc ; 1995 2-level cache , 60 % trans . on Alpha 21164 mproc 2 How do architects address this gap ? • Programmers want unlimited amounts of memory with low latency • Fast memory technology is more expensive per bit than slower memory • Solution : organize memory system into a hierarchy • Entire addressable memory space available in largest , slowest memory • Incrementally smaller and faster memories , each containing a subset of the memory below it , proceed in steps up toward the processor • Temporal and spatial locality insures that nearly all references can be found in smaller memories • Gives the allusion of a large , fast memory being presented to the processor 3 Memory Hierarchy Secondary Storage Memory Hierarchy Disks DRAM L2 Cache L1 Cache Processor Registers 4 Memory Hierarchy 5 Generations of Microprocessors • Time of a full cache miss in instructions executed : 1st Alpha : 2nd Alpha : 3rd Alpha : 340 ns/5.0 ns = 68 clks x 2 or 266 ns/3.3 ns = 80 clks x 4 or 180 ns/1.7 ns =108 clks x 6 or 136 320 648 access time/cycle time X instructions per cycle . newer processors waste more instructions because of cache misses . 6 General Principles of Memory • Locality • Temporal Locality : referenced memory is likely to be referenced again soon ( e.g . code within a loop ) • Spatial Locality : memory close to referenced memory is likely to be referenced soon ( e.g. , data in a sequentially access array ) • Locality + smaller HW is faster = memory hierarchy • Levels : each smaller , faster , more expensive/byte than level below • Inclusive : data found in top also found in the bottom • Definitions • Upper : closer to processor • Block : minimum unit that present or not in upper level • Block address : location of block in memory • Hit time : time to access upper level , including hit determination 7 Cache : A definition • Webster ’ s Dictionary : • Cache ( kash ) , a safe place for hiding or storing things • In CS ( originally ) • The first level of memory hierarchy encounter after the CPU • In CS today ( typically ) • A term applied to any level of buffering employed to reuse commonly accessed items 8 Cache Measures • Hit rate : fraction found in that level • So high that usually talk about Miss rate • Miss rate fallacy : as MIPS to CPU performance , miss rate to average memory access time in memory • Avg . memory-access time = Hit rate x Hit access time + Miss rate x Miss penalty • Miss penalty : time to replace a block from lower level , including time to replace in CPU • access time : time to lower level = ( lower level latency ) • transfer time : time to transfer block = ( BW upper & lower , block size ) Speculative and multithreaded processors may execute other instructions during a miss ( reduce performance impact of misses ) 9 Cache • Two issues • How do we know if a data item is in the cache ? • If it is , how do we find it ? • Our first example • Block size is one word of data • ” Direct mapped '' For each item of data at the lower level , there is exactly one location in the cache where it might be . e.g. , lots of items at the lower level share locations in the upper level 10 Direct mapped cache • Mapping • Cache address is Memory address modulo the number of blocks in the cache • ( Block address ) modulo ( # Blocks in cache ) C ache 0 0 0 1 0 0 0 1 0 1 1 0 0 0 1 1 0 1 0 1 1 1 1 1 00 001 001 01 01 001 0 1101 10 001 10101 11 00 1 11 101 Mem ory 11 Block Size vs . Performance 12 Block Size vs. Cache Measures • Increasing Block Size generally increases Miss Penalty and decreases Miss Rate Miss Penalty X Miss Rate = Block Size Block Size Block Size Avg . memory-access time = Hit rate x Hit access time + Miss rate x Miss penalty Avg . Memory Access Time 13 Implications For CPU • Fast hit check since every memory access • Hit is the common case • Unpredictable memory access time • 10s of clock cycles : wait • 1000s of clock cycles : • Interrupt & switch & do something else • New style : multithreaded execution 14 Four Questions for Memory Hierarchy Designers • Q1 : Where can a block be placed in the upper level ? ( Block placement ) • Q2 : How is a block found if it is in the upper level ? ( Block identification ) • Q3 : Which block should be replaced on a miss ? ( Block replacement ) • Q4 : What happens on a write ? ( Write strategy ) 15 Q1 : Where can a block be placed in the upper level ? • Direct Mapped : Each block has only one place that it can appear in the cache . • Fully associative : Each block can be placed anywhere in the cache . • Set associative : Each block can be placed in a restricted set of places in the cache . • If there are n blocks in a set , the cache placement is called n-way set associative • What is the associativity of a direct mapped cache ? Associativity Examples ( Figure 5.2 , pg . 376 ) Fully associative : Block 12 can go anywhere Direct mapped : Block no . = ( Block address ) mod ( No . of blocks in cache ) Block 12 can go only into block 4 ( 12 mod 8 ) Set associative : Set no . = ( Block address ) mod ( No . of sets in cache ) Block 12 can go anywhere in set 0 ( 12 mod 4 ) Q1 : Where can a block be placed in the upper level ? Full Associative Direct Mapped Set Associative 0 12 Block 12 placed in 8 block cache 31 18 Direct Mapped 4KB or 1024 words 19 Set Associative 4-way 20 Fully Associative • Can you draw it ? • How many comparators will you need ? 21 Associativity Performance 22 Q2 : How Is a Block Found if it is in the Upper Level ? • The address can be divided into two main parts • Block offset : selects the data from the block offset size = log2 ( block size ) • Block address : tag + index • index : selects set in cache index size = log2 ( # blocks/associativity ) • tag : compared to tag in cache to determine hit tag size = addreess size - index size - offset size Tag Index Q2 : How Is a Block Found If It Is in the Upper Level ? • Tag on each block • No need to check index or block offset • Increasing associativity shrinks index , expands tag Block Address Block Address Tag Index Block offset 24 Address organization for Set Associative Cache n-bits of CPU address k-bits of Block Offset i-bits of Tag j-bits of Index n= i + j + k 25 Cache organization TAG BLOCK 1 TAG BLOCK N N-way set associative means there are N-blocks per Set SET 0 Index used to select Set SET 2j - 1 26 Cache organization TAG BLOCK 1 TAG BLOCK N SET 0 The Tag is associatively compared to all tags in a set . If there is a macth we have a cache hit . SET 2j - 1 There must also be a mechanism to in- dicate invalid block data . This is commonly done by attaching a valid bit to the Tag field ( not shown ) . 27 SET 0 SET 2j - 1 Cache organization TAG BLOCK 1 TAG BLOCK N K Each block is broken into 2 elements . The Block Offset is used to select the which element . The Tag and Index identify the block & the Block Offset identifies the element . 28 Q3 : Which Block Should be Replaced on a Miss ? • Easy for Direct Mapped • Set Associative or Fully Associative : • Random - easier to implement • Least Recently used - harder to implement - may approximate • Miss rates for caches with different size , associativity and replacemnt algorithm . 2-way 4-way 8-way Associativity : Size 16 KB 64 KB 256 KB Random LRU 5.18 % 5.69 % 1.88 % 2.01 % 1.15 % 1.17 % Random LRU LRU 4.67 % 5.29 % 1.54 % 1.66 % 1.13 % 1.13 % 4.39 % 1.39 % 1.12 % Random 4.96 % 1.53 % 1.12 % For caches with low miss rates , random is almost as good as LRU . Q4 : What Happens on a Write ? • Write through : The information is written to both the block in the cache and to the block in the lower-level memory . • Write back : The information is written only to the block in the cache . The modified cache block is written to main memory only when it is replaced . • is block clean or dirty ? ( add a dirty bit to each block ) • Pros and Cons of each : • Write through • read misses can not result in writes to memory , • easier to implement • Always combine with write buffers to avoid memory latency • Write back • Less memory traffic • Perform writes at the speed of the cache Write Buffer for Write Through Processor Cache DRAM Write Buffer • A Write Buffer is needed between the Cache and Memory • Processor : writes data into the cache and the write buffer • Memory controller : write contents of the buffer to memory • Write buffer is just a FIFO : • Typical number of entries : 4 • Works fine if : Store frequency ( w.r.t . time ) < < 1 / DRAM write cycle • Memory system designer ’ s nightmare : • Store frequency ( w.r.t . time ) - > 1 / DRAM write cycle • Write buffer saturation 31 Q4 : What Happens on a Write ? 32 Hits & Misses ( Read v.s . Write ) • Read hits • This is what we want ! • Read misses • Stall the CPU , fetch block from memory , deliver to cache , restart • Write hits • Can replace data in cache and memory ( write-through ) • Write the data only into the cache ( write-back the cache later ) • Write misses • See next slide 33 What happens on a Write Miss ? Write Allocate vs Non-Allocate • Write allocate : allocate new cache line in cache • Usually means that you have to do a “ read miss ” to fill in rest of the cache-line ! • Alternative : per/word valid bits • Write non-allocate ( or “ write-around ” ) : • Simply send write data through to underlying memory/cache - don ’ t allocate new cache line ! 34 Split vs. Unified Cache • Unified cache ( mixed cache ) : Data and instructions are stored together ( von Neuman architecture ) • Split cache : Data and instructions are stored separately ( Harvard architecture ) • Why do instructions caches have a lower miss ratio ? Size 1 KB 2 KB 4 KB 8 KB 16 KB 32 KB 64 KB 128 KB Instruction Cache 3.06 % 2.26 % 1.78 % 1.10 % 0.64 % 0.39 % 0.15 % 0.02 % Data Cache 24.61 % 20.57 % 15.94 % 10.19 % 6.47 % 4.82 % 3.77 % 2.88 % Unified Cache 13.34 % 9.78 % 7.24 % 4.57 % 2.87 % 1.99 % 1.35 % 0.95 % 35 Review : Improving Cache Performance 1 . Reduce the miss rate , 2 . Reduce the miss penalty , or 3 . Reduce the time to hit in the cache . 36 Reducing Misses • Classifying Misses : 3 Cs • Compulsory—The first access to a block is not in the cache , so the block must be brought into the cache . Also called cold start missesor first reference misses . ( Misses in even an Infinite Cache ) • Capacity—If the cache can not contain all the blocks needed during execution of a program , capacity misses will occur due to blocks being discarded and later retrieved . ( Misses in Fully Associative Size X Cache ) • Conflict—If block-placement strategy is set associative or direct mapped , conflict misses ( in addition to compulsory & capacity misses ) will occur because a block can be discarded and later retrieved if too many blocks map to its set . Also called collision missesor interference misses . ( Misses in N-way Associative , Size X Cache ) • More recent , 4th “ C ” : • Coherence- Misses caused by cache coherence ( later ) . 37 Types of misses • Compulsory • Very first access to a block ( cold-start miss ) • Capacity • Cache can not contain all blocks needed • Conflict • Too many blocks mapped onto the same set 38 How do you solve • Compulsory misses ? • Larger blocks with a side effect ! • Capacity misses ? • Not much options : enlarge the cache otherwise face “ thrashing ! ” , computer runs at a speed of the lower memory or slower ! • Conflict misses ? • Full associative cache with a cost of hardware and may slow the processor ! 39 3Cs Absolute Miss Rate ( SPEC92 ) 1-way 2-way 4-way Conflict 8-way Capacity 0.14 0.12 0.1 0.08 0.06 0.04 0.02 0 1 2 4 8 6 1 2 3 Compulsory vanishingly small Cache Size ( KB ) 4 6 8 2 1 Compulsory 40 2:1 Cache Rule miss rate 1-way associative cache size X = miss rate 2-way associative cache size X/2 Or an old rule of thumb : 2x size = > 25 % cut in miss rate 1-way Conflict 2-way 4-way 8-way Capacity 0.14 0.12 0.1 0.08 0.06 0.04 0.02 0 1 2 4 8 6 1 2 3 Cache Size ( KB ) 4 6 8 2 1 Compulsory 41 How Can Reduce Misses ? • 3 Cs : Compulsory , Capacity , Conflict • In all cases , assume total cache size not changed : • What happens if : 1 ) Change Block Size : Which of 3Cs is obviously affected ? 2 ) Change Associativity : Which of 3Cs is obviously affected ? 3 ) Change Compiler : Which of 3Cs is obviously affected ? 42 Basic cache optimizations : • Larger block size • Reduces compulsory misses • Increases capacity and conflict misses , increases miss penalty • Larger total cache capacity to reduce miss rate • Increases hit time , increases power consumption • Higher associativity • Reduces conflict misses • Increases hit time , increases power consumption • Higher number of cache levels • Reduces overall memory access time • Giving priority to read misses over writes • Reduces miss penalty 43 25 % 20 % 15 % 10 % 5 % 0 % Miss Rate Reduced compulsory misses Larger Block Size ( fixed size & assoc ) 1K 4K 16K 64K 256K 6 1 2 3 4 6 8 2 1 6 5 2 Block Size ( bytes ) Increased Conflict Misses 44 2 . Reduce Misses via Higher Associativity • 2:1 Cache Rule : • Miss Rate DM cache size N Miss Rate 2-way cache size N/2 • Beware : Execution time is only final measure ! • Will Clock Cycle time increase ? • Hill [ 1988 ] suggested hit time for 2-way vs. 1-way external cache +10 % , internal + 2 % 45 Example : Avg . Memory Access Time vs. Miss Rate • CCT = Clock Cycle Time • Example : Assume that CCT ( 2-way ) = 1.10 CCT ( 1-way ) CCT ( 4-way ) = 1.12 CCT ( 1-way ) CCT ( 8-way ) = 1.14 CCT ( 1-way ) 46 Example : Avg . Memory Access Time vs. Miss Rate ( cont . ) Cache Size ( KB ) 1 2 4 8 16 32 64 128 Associativity 2-way 2.15 1.86 1.67 1.48 1.32 1.24 1.20 1.17 1-way 2.33 1.98 1.72 1.46 1.29 1.20 1.14 1.10 4-way 2.07 1.76 1.61 1.47 1.32 1.25 1.21 1.18 8-way 2.01 1.68 1.53 1.43 1.32 1.27 1.23 1.20 AMAT for each cache size/organization ( Red means A.M.A.T . not improved by more associativity ) 47 Other Optimizations : Victim Cache • Add a small fully associative victim cache to place data discarded from regular cache • When data not found in cache , check victim cache • 4-entry victim cache removed 20 % to 95 % of conflicts for a 4 KB direct mapped data cache • Get access time of direct mapped with reduced miss rate 48 3 . Reducing Misses via a “ Victim Cache ” • How to combine fast hit time of direct mapped yet still avoid conflict misses ? • Add buffer to place data discarded from cache • Jouppi [ 1990 ] : 4-entry victim cache removed 20 % to 95 % of conflicts for a 4 KB direct mapped data cache • Used in Alpha , HP machines TAGS DATA Tag and Comparator One Cache line of Data Tag and Comparator One Cache line of Data Tag and Comparator One Cache line of Data Tag and Comparator One Cache line of Data To Next Lower Level In Hierarchy 49 4 . Reducing Misses via “ Pseudo-Associativity ” • How to combine fast hit time of Direct Mapped and have the lower conflict misses of 2-way associative cache ? • Two cahces H1 and H2 caches • Place Block In H1 if Miss check H2 if hit swap if miss bring from memory to H1 and send block in H1 to H2 . • Divide cache : on a miss , check other half of cache to see if the data is there , if so have a pseudo-hit ( slow hit ) Hit Time Pseudo Hit Time Miss Penalty Time • Drawback : Difficult to build a CPU pipeline if hit may take either 1 or 2 cycles • Better for caches not tied directly to processor ( L2 ) • Used in MIPS R1000 L2 cache , similar in UltraSPARC 50 5 . Reducing Misses by Hardware Prefetching of Instructions & Data • E.g. , Instruction Prefetching • Alpha 21064 fetches 2 blocks on a miss • Extra block placed in “ stream buffer ” • On miss check stream buffer • IBM POWER4 has 8 data prefetch streams • Works with data blocks too : • Jouppi [ 1990 ] 1 data stream buffer got 25 % misses from 4KB cache ; 4 streams got 43 % • Palacharla & Kessler [ 1994 ] for scientific programs for 8 streams got 50 % to 70 % of misses from 2 64KB , 4-way set associative caches • Prefetching relies on having extra memory bandwidth that can be used without penalty 51 6 . Reducing Misses by Software Prefetching Data • Compiler or hand inserted prefetch instruction • Data Prefetch • Load data into register ( HP PA-RISC loads ) • Cache Prefetch : load into cache ( MIPS IV , PowerPC , SPARC v. 9 ) • Nonfaulting prefetching instructions can not cause faults . They are a form of speculative execution . • Prefetching comes in two flavors : • Binding prefetch : Requests load directly into register . • Must be correct address and register ! • Non-Binding prefetch : Load into cache . • Can be incorrect . Frees HW/SW to guess ! Non-binding is more common . 52 Software pre-fetching Example for ( int i=0 ; i < 1024 ; i++ ) { A [ i ] = A [ i ] + 100 ; } • Each iteration , the ith element of the array is accessed . • We can prefetch the elements that are going to be accessed in future iterations • inserting a `` prefetch '' instruction as shown below : for ( int i=0 ; i < 1024 ; i=i+k ) { prefetch ( A [ i + k ] ) ; A [ i ] = A [ i ] + 100 ; A [ i+1 ] = A [ i+1 ] + 100 ; A [ i+2 ] = A [ i+2 ] + 100 ; A [ i+3 ] = A [ i+3 ] + 100 ; } 53 7 . Reducing Misses by Compiler Optimizations • Data • Merging Arrays : improve spatial locality by single array of compound elements vs. 2 arrays • Loop Interchange : change nesting of loops to access data in order stored in memory • Loop Fusion : Combine 2 independent loops that have same looping and some variables overlap • Blocking : Improve temporal locality by accessing “ blocks ” of data repeatedly vs. going down whole columns or rows 54 Merging Arrays Example val val [ 0 ] m m [ 0 ] / * Before : 2 sequential arrays * / int val [ SIZE ] ; int key [ SIZE ] ; for ( int i = 0 ; i < 11 ; i++ ) if ( key [ i ] % 5 & & val [ i ] > 1000 ) printf ( “ found key ” ) ; / * After : 1 array of structures * / struct merge { int val ; int key ; } ; struct merge m [ SIZE ] ; for ( int i = 0 ; i < 11 ; i++ ) if ( m [ i ] .key % 5 & & m [ i ] .val > 1000 ) printf ( “ found key ” ) ; val [ 10 ] key key [ 0 ] key [ 10 ] Reducing conflicts between val & key ; improve spatial locality 55 m [ 10 ] Loop Interchange Example j / * Before * / for ( k = 0 ; k < 100 ; k = k+1 ) for ( j = 0 ; j < 100 ; j = j+1 ) for ( i = 0 ; i < 5000 ; i = i+1 ) x [ i ] [ j ] = 2 * x [ i ] [ j ] ; / * After * / for ( k = 0 ; k < 100 ; k = k+1 ) for ( i = 0 ; i < 5000 ; i = i+1 ) for ( j = 0 ; j < 100 ; j = j+1 ) x [ i ] [ j ] = 2 * x [ i ] [ j ] ; i ··· · · · Sequential accesses instead of striding through memory every 100 words ; improved spatial locality ··· ··· ··· memory addresses 56 Loop Fusion Example / * Before * / for ( i = 0 ; i < N ; i = i+1 ) for ( j = 0 ; j < N ; j = j+1 ) a [ i ] [ j ] = 1/b [ i ] [ j ] * c [ i ] [ j ] ; for ( i = 0 ; i < N ; i = i+1 ) for ( j = 0 ; j < N ; j = j+1 ) d [ i ] [ j ] = a [ i ] [ j ] + c [ i ] [ j ] ; / * After * / for ( i = 0 ; i < N ; i = i+1 ) for ( j = 0 ; j < N ; j = j+1 ) { a [ i ] [ j ] = 1/b [ i ] [ j ] * c [ i ] [ j ] ; d [ i ] [ j ] = a [ i ] [ j ] + c [ i ] [ j ] ; } 2 misses per access to a & c vs. one miss per access ; improve spatial locality 57 Blocking . Problem : When accessing multiple multi-dimensional arrays ( e.g. , for matrix multiplication ) , capacity misses occur if not all of the data can fit into the cache . . Solution : Divide the matrix into smaller submatrices ( or blocks ) that can fit within the cache . The size of the block chosen depends on the size of the cache . Blocking can only be used for certain types of algorithms 58 Matrix Multiplication for ( int i = 0 ; i < N ; i++ ) for ( int j = 0 ; j < N ; j++ ) for ( int k = 0 ; k < N ; k++ ) C [ i ] [ j ] = C [ i ] [ j ] + A [ i ] [ k ] * B [ k ] [ j ] ; 59 Blocked Matrix Multiplication 60 Blocked Matrix Multiplication 61 Blocked vs . Conventional 4096x4096 Array Block size : 32x32 VS. 62 Summary of Compiler Optimizations to Reduce Cache Misses ( by hand ) vpenta ( nasa7 ) gmty ( nasa7 ) tomcatv btrix ( nasa7 ) mxm ( nasa7 ) spice cholesky ( nasa7 ) compress 1 1.5 2 2.5 3 Performance Improvement merged arrays loop interchange loop fusion blocking 63 Summary : Miss Rate Reduction CPUtime  IC  CPI Execution   Clock cycle time      Miss rate  Miss penalty Memory accesses Instruction • 3 Cs : Compulsory , Capacity , Conflict 1 . Reduce Misses via Larger Block Size 2 . Reduce Misses via Higher Associativity 3 . Reducing Misses via Victim Cache 4 . Reducing Misses via Pseudo-Associativity 5 . Reducing Misses by HW Prefetching Instr , Data 6 . Reducing Misses by SW Prefetching Data 7 . Reducing Misses by Compiler Optimizations • Prefetching comes in two flavors : • Binding prefetch : Requests load directly into register . • Must be correct address and register ! • Non-Binding prefetch : Load into cache . • Can be incorrect . Frees HW/SW to guess ! 64 Review : Improving Cache Performance 1 . Reduce the miss rate , 2 . Reduce the miss penalty , or 3 . Reduce the time to hit in the cache . 65 1 . Reducing Miss Penalty : Read Priority over Write on Miss CPU in out Write Buffer write buffer DRAM ( or lower mem ) 66 1 . Reducing Miss Penalty : Read Priority over Write on Miss • Write-through with write buffers causes RAW conflicts with main memory reads on cache misses • If simply wait for write buffer to empty , might increase read miss penalty ( old MIPS 1000 by 50 % ) • Check write buffer contents before read ; if no conflicts , let the memory access continue . • Write-back also want buffer to hold misplaced blocks • Read miss replacing dirty block • Normal : Write dirty block to memory , and then do the read • Instead copy the dirty block to a write buffer , then do the read , and then do the write • CPU stall less since restarts as soon as do read 67 2 . Reduce Miss Penalty : Early Restart and Critical Word First • Don ’ t wait for full block to be loaded before restarting CPU • Early restart—As soon as the requested word of the block arrives , send it to the CPU and let the CPU continue execution • Critical Word First—Request the missed word first from memory and send it to the CPU as soon as it arrives ; let the CPU continue execution while filling the rest of the words in the block . Generally useful only in large blocks , • In Spatial locality we want the words in order , so not clear if benefit critical word first . It improves performance if we want none sequential access of words in a block . block 68 3.Reducing Miss Penalty : Multi-level Caches • Add a second level cache : • Often primary cache is on the same chip as the processor • Use SRAMs to add another cache above primary memory ( DRAM ) • Miss penalty goes down if data is in 2nd level cache • Using multilevel caches : • Try and optimize the hit time on the 1st level cache • Try and optimize the miss rate on the 2nd level cache 69 Multilevel Caches • Primary cache attached to CPU • Small , but fast • Level-2 cache services misses from primary cache • Larger , slower , but still faster than main memory • Main memory services L-2 cache misses • Some high-end systems include L-3 cache 70 Cache Optimization Summary Technique Larger Block Size Higher Associativity Victim Caches Pseudo-Associative Caches HW Prefetching of Instr/Data Compiler Controlled Prefetching Compiler Reduce Misses Priority to Read Misses Early Restart & Critical Word 1st Second Level Caches e t a r s s m i y t l a n e p s s m i – – + + + + + + + MR MP HT Complexity 0 1 2 2 2 3 0 1 3 2 + + + 71 Cache Coherence 72 Single Bus ( Shared Address UMA ) Multi ’ s Proc1 Proc2 Proc3 Proc4 Caches Caches Caches Caches Single Bus Memory I/O • Caches are used to reduce latency and to lower bus traffic • Write-back caches used to keep bus traffic at a minimum • Must provide hardware to ensure that caches and memory are consistent ( cache coherency ) • Must provide a hardware mechanism to support process synchronization 73 Multiprocessor Cache Coherency • Cache coherency protocols • Directory-based ” The state of a block of memory is kept in one location ( centralized ) ( centralized ) • Bus snooping – cache controllers monitor shared bus traffic with duplicate address tag hardware ( so they don ’ t interfere with processor ’ s access to the cache ) Proc1 Proc2 ProcN Snoop DCache Snoop DCache Snoop DCache Single Bus Memory I/O 74 Bus Snooping Protocols • Multiple copies are not a problem when reading • Processor must have exclusive access to write a word • if two processors try to write to the same shared data word in the same clock cycle ? • The bus arbiter decides which processor gets the bus first . • Then the second processor will get exclusive access . • Thus , bus arbitration forces sequential behavior . • This sequential consistency is the most conservative of the memory consistency models . • All other processors sharing that data must be informed of writes 75 Handling Writes Ensuring that all other processors sharing data are informed of writes can be handled two ways : 1 . Write-update ( write-broadcast ) – writing processor broadcasts new data over the bus , all copies are updated • All writes go to the bus  higher bus traffic • Since new values appear in caches sooner , can reduce latency 2 . Write-invalidate – writing processor issues invalidation signal on bus , cache snoops check to see if they have a copy of the data , if so they invalidate their cache block containing the word ( this allows multiple readers but only one writer ) • Uses the bus only on the first write  lower bus traffic , so better use of bus bandwidth 76 A Write-Invalidate CC Protocol read ( miss ) Invalid Shared ( clean ) read ( hit or miss ) ) s s m i ( e t i r w Modified ( dirty ) read ( hit ) or write ( hit or miss ) write-back caching protocol in black 77 A Write-Invalidate CC Protocol read ( miss ) receives invalidate ( write by another processor to this block ) Shared ( clean ) read ( hit or miss ) Invalid ) s s m i ( e t i r w e t a d i l a v n i d n e s r o s s e c o r p r e h o n a t k c o b l i s h t o t y b ) s s m i ( e t i r w Modified ( dirty ) read ( hit ) or write ( hit ) write-back caching protocol in black signals from the processor coherence additions in red signals from the bus coherence additions in blue 78 Write-Invalidate CC Examples • I = invalid ( many ) , S = shared ( many ) , M = modified ( only one ) Proc 1 Proc 2 Proc 1 Proc 2 A S A I A S A I Main Mem A Main Mem A Proc 1 Proc 2 Proc 1 Proc 2 A M A I A M A I Main Mem A Main Mem A 79 Write-Invalidate CC Examples • I = invalid ( many ) , S = shared ( many ) , M = modified ( only one ) 3. snoop sees read request for Proc 1 A & lets MM supply A A S 1. read miss for A Proc 2 4. gets A from MM & changes its state A I to S Proc 1 4. change A state to I A S 1. write miss for A Proc 2 2. writes A & changes its state A I to M 2. read request for A Main Mem A 3 . P2 sends invalidate for A Main Mem A 3. snoop sees read request for A , writes- Proc 1 back A to MM changes it state to S A M 1. read miss for A Proc 2 4. gets A from MM & changes its state A I to S Proc 1 4. change A state to I A M 1. write miss for A Proc 2 2. writes A & changes its state A I to M 2. read request for A 3 . P2 sends invalidate for A Main Mem A Main Mem A Note : Assume cache block is one word only and we are using write-allocate cache policy . 80 SMP Data Miss Rates • Shared data has lower spatial and temporal locality • Share data misses often dominate cache behavior even though they may only be 10 % to 40 % of the data accesses Capacity miss rate Coherence miss rate 64KB 2-way set associative data cache with 32B blocks Hennessy & Patterson , Computer Architecture : A Quantitative Approach Capacity miss rate Coherence miss rate 8 6 4 2 0 18 16 14 12 10 8 6 4 2 0 1 2 8 16 4 FFT 1 2 4 Ocean 8 16 81 Block Size Effects • Writes to one word in a multi-word block mean • either the full block is invalidated ( write-invalidate ) • or the full block is exchanged between processors ( write- update ) • Alternatively , could broadcast onlythe written word • Multi-word blocks can also result in false sharing : when two processors are writing to two different variables in the same cache block • With write-invalidate false sharing increases cache miss rates Proc1 Proc2 A B 4 word cache block  Compilers can help reduce false sharing by allocating highly correlated data to the same cache block 82 Other Coherence Protocols • There are many variations on cache coherence protocols • Another write-invalidate protocol used in the Pentium 4 ( and many other micro ’ s ) is MESI with four states : • Modified – ( same ) only modified cache copy is up-to-date ; memory copy and all other cache copies are out-of-date • Exclusive – only one copy of the shared data is allowed to be cached ; memory has an up-to-date copy • Since there is only one copy of the block , write hits don ’ t need to send invalidate signal • Shared – multiple copies of the shared data may be cached ( i.e. , data permitted to be cached with more than one processor ) ; memory has an up-to-date copy • Invalid – same 83",
    "2- problem solving & searching.txt": "PROBLEM SOLVING & SEARCH STRATEGY Part 1 Dr. Emad Natsheh Problem solving Problem Description • Components ✓State space ✓Initial state ✓Goal state ✓Actions ( operators ) ✓Path cost States • A problem is defined by its elements and their relations • A state is a representation of those elements in a given moment . • Two special states are defined : • Initial state ( starting point ) • Goal state State Modification : Successor Function • A successor function is needed to move between different states . • A successor function is a description of possible actions a set of operators . It is a transformation function on a state representation , which move it into another state . • The successor function defines a relation of accessibility among states . State space • The state space is the set of all states reachable from the initial state • Its form a graph ( or tree ) in which the nodes are states and the arcs between nodes are actions . • A path in the state space is a sequence of states connected by a sequence of actions . • The solution of the problem is part of the map formed by the state space . Tree vs Graph Problem Solution • A solution in the state space is a path from the initial state to a goal state • Path/solution cost : function that assigns a numeric cost to each path , the cost of applying the operators to the states • Solution quality is measured by the path cost function , and an optimal solution has the lowest path cost among all solutions . Example 8-puzzle Example : Travelling Problem Representation Example Water Jug Problem Problem Description Operations ( Actions ) # 1 2 3 4 5 6 7 8 Actions Fill X from Pump Fill Y from Pump Empty X into Ground Empty Y into Ground Get water from Y into X until X is full Get water from X into Y until Y is full Get all water from Y into X Get all water from X into Y Rules Rules # 1 2 3 4 5 6 7 8 Another Solution to the Water Jug Problem Algorithm for Problem Solving Initialize the search tree using the initial state of the problem 1 . 2 . Choose a terminal node for expansion according to certain search strategy ❑If no terminal node is available for expansion return failure ❑If the chosen node contains a goal return the node 3 . Expand the chosen node ( according to the rules ) and add the resulting node to the search tree 4 . Go to step 2 Missionaries & Cannibals Problem Problem Description • State ( # of missionaries Left , # of cannibals Left , # of missionaries Right , # of cannibals Right , side_of_the_boat ) • Initial State = > State ( 3 , 3 , 0 , 0 , 0 ) • Final State = > State ( 0 , 0 , 3 , 3 , 1 ) . • Actions • Carry ( 2 , 0 ) . • Carry ( 1 , 0 ) . • Carry ( 1 , 1 ) . • Carry ( 0 , 1 ) . • Carry ( 0 , 2 ) . Where Carry ( M , C ) means the boat will carry M missionaries and C cannibals on one trip . Rules Rules # 1 One missionaries can move only when _________ in one side And _________ in the other 2 Two missionaries can move only when ________in one side And _________ in the other 3 One cannibals can move only when ___________ in one side And _________ in the other 4 Two cannibals can move only when ___________in one side And ________ in the other 5 One missionary and one cannibal can move only when ________ in one side And ________ in the other Vacuum Cleaner • World state space • State • Actions • Goal • Path costs : PROBLEM SOLVING & SEARCH STRATEGY Part 2 Dr. Emad Natsheh Traveling Salesman Problem Traveling Salesman Problem Traveling Salesman Problem Search Technique Search Search Technique Breadth First Search Breadth First Search •Implementation : FIFO queue •Strategy : expand a shallowest node first Breadth First Search ( Example ) Breadth First Search ( Example ) BFS Analysis • Complete ? • Optimal ? Time vs Space Complexity • Time Complexity : • It is the amount of time need to generate the nodes • Space Complexity : • It is the amount of space or memory required for getting a solution • Big O notation • Is a mathematical notation that describes the limiting behavior of a function • Used in Computer Science to describe the performance or complexity of an algorithm Branching Factor • The branching factor of a node in a tree is the number of children it has . BFS Time and Space Complexity BFS Time and Space Complexity 1 + 𝑏 + 𝑏2 + 𝑏3 + ⋯ + 𝑏𝑑 = 𝑂 ( 𝑏𝑑 ) BFS Analysis • Time Complexity → • Space Complexity → O ( 𝑏𝑑 ) • Where b is branching factor and d is depth of solution 1 + 𝑏 + 𝑏2 + 𝑏3 + ⋯ + 𝑏𝑑 = 𝑂 ( 𝑏𝑑 ) BFS Analysis Depth First Search Depth First Search • Implementation : LIFO stack , queue • Strategy : find the deepest solution Depth First Search ( Example- Stack ) Depth First Search ( Example- Queue ) Depth First Search ( Example ) DFS Analysis • Complete ? • Optimal ? DFS Time and Space Complexity ( Stack ) DFS Time and Space Complexity ( Queue ) DFS Analysis • Time Complexity → O ( 𝑏𝑚 ) • Stack • Space Complexity → O ( m ) • Queue • Space Complexity → O ( bm ) • Where b is branching factor and m is maximum depth Quiz : DFS vs BFS • When will BFS outperform DFS ? • When will DFS outperform BFS ? Iterative Deepening Depth First Search Iterative Deepening Depth First Search • Its depth-limited version of depth-first search is run repeatedly with increasing depth limits until the goal is found . • Find the shallowest solution IDDFS ( Example depth=0 ) IDDFS ( Example depth=1 ) IDDFS ( Example depth=2 ) IDDFS Pseudocode IDDFS Analysis • Complete ? • Optimal ? IDDFS Time Complexity 𝑑 + 1 + 𝑑 𝑏 + 𝑑 − 1 𝑏2 + ⋯ + 3𝑏𝑑−2 + 2𝑏𝑑−1 + 𝑏𝑑 𝑑 ( 𝑑 + 1 − 𝑖 ) 𝑏𝑖 = ෍ 𝑖=0 IDDFS Space Complexity IDDFS Analysis • Time Complexity → O ( 𝑏𝑑 ) • Stack • Space Complexity → O ( d ) • Queue • Space Complexity → O ( bd ) • Where b is branching factor and d is depth of solution Uniform Cost Search UCS ( Branch and Bound Search ) • Implementation : priority queue ( sort by cost function g ( n ) ) • g ( n ) is cost from root node to current node n • Uniform cost search vs Dijkstra ! ! ! ! UCS ( Example Table ) Visited Nodes ( Close ) Priority Queue ( Open ) - A UCS ( Example Tree ) Class Exercise Class Exercise ( Solution Table ) Visited Nodes ( Close ) Priority Queue ( Open ) - S Class Exercise ( Solution Tree ) UCS Pseudocode UCS Analysis • Complete ? • Optimal ? UCS Analysis • Time Complexity • O ( 𝑏𝑑 ) • O ( 𝑏 Τ𝐶∗ ɛ ) • Space Complexity • O ( 𝑏𝑑 ) • O ( 𝑏 Τ𝐶∗ ɛ ) UCS and 8 puzzle PROBLEM SOLVING & SEARCH STRATEGY Part 3 Dr. Emad Natsheh Informed ( Heuristic ) Search Technique Informed search • Heuristic • Best First Search ( Greedy search ) • A * Recap : Search • Search problem • State • Action or cost • Successor function • Start goal and end goal • Represent problem as tree/graph • Search algorithm • Choose node for expanding • Blind search • Inform search Informed Search Heuristic Function h ( n ) • Heuristic h ( n ) is a function that estimates how close a state is to a goal • Designed for a particular search problem • We assume that h ( n ) is non-negative , and that h ( n ) =0 if n is a goal node . Heuristic Function ( Example - Travel Planning ) Heuristic Function ( Example- 8Puzzle ) Heuristic Function ( Example- 8Puzzle ) Best First Search ( Greedy search ) Best First Search • Implementation : priority queue • Very similar to UCS but sort the queue regarding to the h ( n ) • Strategy : expand the node that you think is closest to the goal BFS Pseudocode Best First Search ( Example ) Best First Search ( Example ) cont . Path find cost =450 Optimal path cost = 418 Best First Search Analysis • Complete ? BFS Pseudocode 2 Best First Search Analysis • Optimal ? • A Common case • Best first takes you straight to the ( wrong ) goal Best First Search Analysis • Time Complexity → O ( 𝑏𝑑 ) • Space Complexity → O ( 𝑏𝑑 ) • Where b is branching factor and d is depth of solution • But a good heuristic can give dramatic improvement How can we fix the greedy problem ? A * Search A * was created as part of the Shakey project IEEE Milestones Award A * • Optimize form Best first search • Implementation : priority queue ( cost + heuristic ) • F ( n ) =g ( n ) +h ( n ) A * A * Pseudocode A * ( Example1-Table ) Close Open S A * ( Example1-Tree ) A * ( Example2-Table ) Close Open A A * ( Example2-Tree ) A * ( Path Finding Example ) A * ( 8 puzzle Example ) Manhattan Distance 𝑥1 − 𝑥2 + |𝑦1 − 𝑦2| Maze World A * ( Maze Example ) Is A * Optimal ? • What went wrong ? Admissible Heuristic Admissible Heuristic ( Example ) H ( n ) < = distance to goal ( n ) H ( n ) distance to goal ( n ) State ( n ) S A B C D G Admissibility Consistency of Heuristic ( Monotonicity ) • Main idea : estimated heuristic costs < = actual costs • Admissibility : heuristic cost < =actual cost to goal • H ( A ) < = actual cost from A to G • Consistency : heuristic “ arc ’ ’ cost < = actual cost for each arc • H ( A ) -H ( C ) < = cost ( A to C ) • Consequences of consistency • The f value along a path never decreases Monotonic Heuristic ( Example ) If it ’ s monotonic then it ’ s admissible H ( n ) < = h ( n ’ ) +c ( n-n ’ ) H ( n ) H ( n ’ ) C ( n-n ’ ) H ( n ’ ) +c ( n-n ’ ) n-n ’ S-A S-G A-B A-C B-D C-D C-G D-G Optimality • Tree Search • A * is optimal if heuristic is admissible • Graph Search • A * is optimal if heuristic is consistent • Consistency implies admissibility Hill Climbing on a surface of states Hill Climbing ( Local Search ) • It is an iterative algorithm that starts with an arbitrary solution to a problem , then attempts to find a better solution by incrementally changing a single element of the solution . If the change produces a better solution , an incremental change is made to the new solution , repeating until no further improvements can be found . • In many optimization problems , the path to the goal I irrelevant ; the goal state itself is the solution • In such cases , we can use local search algorithms • Keep single “ current ” state , try to improve it N Queen Problem • The N Queen is the problem of placing N chess queens on an N×N chessboard so that no two queens attack each other • Example 4 Queen Hill Climbing Pseudocode Hill Climbing Example Drawbacks of hill climbing Example 1 Example 2 Example 3 Example 4 Hill Climbing Analysis • Complete ? • Optimal ? • Time Complexity • Space Complexity Simulated Annealing Anneal • To subject ( glass or metal ) to a process of heating and slow cooling in order to toughen and reduce brittleness . Pseudocode of Simulated Annealing Simulated annealing algorithm https : //toddwschneider.com/posts/traveling-salesman-with- simulated-annealing-r-and-shiny/ Beam Search • Beam search is a heuristic search algorithm that explores a graph by expanding the most promising node in a limited set . • Beam search is an optimization of breadth-first search that reduces its memory requirements . • A beam search is most often used to maintain tractability in large systems with insufficient amount of memory to store the entire search tree . For example , it has been used in many machine translation systems . Machine Translation ( Seq to Seq ) • • Input the encoded input sentence to the decoder ; the decoder will then apply softmax function to all the 10,000 words in the vocabulary . From 10,000 possibilities , we will select only the top 3 words with the highest probability . Machine Translation ( Seq to Seq ) Beam Search Beam Search Example Beam Search Example Pseudocode of Beam Search Beam Search Analysis • Complete ? • Optimal ? • Time Complexity • Space Complexity Class Exercise 1 Class Exercise 1 Class Exercise 2 Class Exercise 3 • Assume you have the following Maze environment , and you want to help the slug to reach here food as soon as possible . Which among the following algorithm is the best to use : Breadth-First Search , A-star , or Greedy search . Explain your result by showing the sequence of tested node ( In- order ) ? • The slug can only move up , down , left , or right . Any of these actions can only be performed on condition that the resulting state remains within the maze and that the resulting state is not a black cell . Also , actions that bring you back to a previous state are not allowed . Note : Assume that ties are broken alphabetically ( alphabetical order of the labels in the cells ) .",
    "2-floating point arithmetic.txt": "Floating Point Arithmetic Lec 14 Systems Architecture 1 Introduction • Objective : To provide hardware support for floating point arithmetic . To understand how to represent floating point numbers in the computer and how to perform arithmetic with them . Also to learn how to use floating point arithmetic in MIPS . • Approximate arithmetic – Finite Range – Limited Precision • Topics – IEEE format for single and double precision floating point numbers – Floating point addition and multiplication – Support for floating point computation in MIPS Lec 14 Systems Architecture 2 Floating Point • An IEEE floating point representation consists of – A Sign Bit ( no surprise ) – An Exponent ( “ times 2 to the what ? ” ) – Mantissa ( “ Significand ” ) , which is assumed to be 1.xxxxx ( thus , one bit of the mantissa is implied as 1 ) – This is called a normalized representation • So a mantissa = 0 really is interpreted to be 1.0 , and a mantissa of all 1111 is interpreted to be 1.1111 • Special cases are used to represent 0 , infinity and NaN . Lec 14 Systems Architecture 3 Floating Point Standard • Defined by IEEE Std 754-1985 • Developed in response to divergence of representations – Portability issues for scientific code • Now almost universally adopted • Two representations – Single precision ( 32-bit ) – Double precision ( 64-bit ) Lec 14 Systems Architecture 4 IEEE Floating-Point Format single : 8 bits double : 11 bits single : 23 bits double : 52 bits S Exponent Fraction/Mantissa ( x  1 ) S ( 1  Fraction )  2 ( Exponent  Bias ) • S : sign bit ( 0  non-negative , 1  negative ) • Normalize significand : 1.0 ≤ |significand| < 2.0 – Always has a leading pre-binary-point 1 bit , so no need to represent it explicitly ( hidden bit ) – Significand is Fraction with the “ 1. ” restored • Exponent : excess representation : actual exponent + Bias – Ensures exponent is unsigned – Single : Bias = 127 ; Double : Bias = 1023 Lec 14 Systems Architecture 5 Representation of Floating Point Numbers • IEEE 754 single precision 31 30 23 22 0 Sign Biased exponent Normalized Mantissa ( implicit 24th bit = 1 ) ( -1 ) s  F  2E-127 Exponent Mantissa Object Represented 0 1-254 255 255 0 anything 0 non-zero 0 FP number infinity NaN Lec 14 Systems Architecture 6 Basic Technique • Represent the decimal in the form +/- 1.xxxb x 2y • And “ fill in the fields ” – Remember biased exponent and implicit “ 1. ” mantissa ! • Examples : – 0.0 : 0 00000000 00000000000000000000000 – 1.0 ( 1.0 x 2^0 ) : 0 01111111 00000000000000000000000 – 0.5 ( 0.1 binary = 1.0 x 2^-1 ) : 0 01111110 00000000000000000000000 – 0.75 ( 0.11 binary = 1.1 x 2^-1 ) : 0 01111110 10000000000000000000000 – 3.0 ( 11 binary = 1.1 * 2^1 ) : 0 10000000 10000000000000000000000 – -0.375 ( -0.011 binary = -1.1 * 2^-2 ) : 1 01111101 10000000000000000000000 – 1 10000011 01000000000000000000000 = - 1.01 * 2^4 = -20.0 Lec 14 Systems Architecture http : //www.math-cs.gordon.edu/courses/cs311/lectures-2003/binary.html Copyright ©2003 - Russell C. Bjork 7 Floating-Point Example • What number is represented by the single-precision float 11000000101000…00 – S = 1 – Fraction = 01000…002 – Fxponent = 100000012 = 129 • x = ( –1 ) 1 × ( 1 + 012 ) × 2 ( 129 – 127 ) = ( –1 ) × 1.25 × 22 = –5.0 Lec 14 Systems Architecture 8 Floating-Point Example • Represent –0.75 – –0.75 = ( –1 ) 1 × 1.12 × 2–1 – S = 1 – Fraction = 1000…002 – Exponent = –1 + Bias • Single : –1 + 127 = 126 = 011111102 • Double : –1 + 1023 = 1022 = 011111111102 • Single : 1011111101000…00 • Double : 1011111111101000…00 Lec 14 Systems Architecture 9 Infinities and NaNs • Exponent = 111 ... 1 , Fraction = 000 ... 0 – ±Infinity – Can be used in subsequent calculations , avoiding need for overflow check • Exponent = 111 ... 1 , Fraction ≠ 000 ... 0 – Not-a-Number ( NaN ) – Indicates illegal or undefined result • e.g. , 0.0 / 0.0 – Can be used in subsequent calculations Lec 14 Systems Architecture 10 Single-Precision Range • Exponents 00000000 and 11111111 reserved • Smallest value – Exponent : 00000001  actual exponent = 1 – 127 = –126 – Fraction : 000…00  significand = 1.0 – ±1.0 × 2–126 ≈ ±1.2 × 10–38 • Largest value – exponent : 11111110  actual exponent = 254 – 127 = +127 – Fraction : 111…11  significand ≈ 2.0 – ±2.0 × 2+127 ≈ ±3.4 × 10+38 Lec 14 Systems Architecture 11 Double-Precision Range • Exponents 0000…00 and 1111…11 reserved • Smallest value – Exponent : 00000000001  actual exponent = 1 – 1023 = –1022 – Fraction : 000…00  significand = 1.0 – ±1.0 × 2–1022 ≈ ±2.2 × 10–308 • Largest value – Exponent : 11111111110  actual exponent = 2046 – 1023 = +1023 – Fraction : 111…11  significand ≈ 2.0 – ±2.0 × 2+1023 ≈ ±1.8 × 10+308 Lec 14 Systems Architecture 12 Representation of Floating Point Numbers 64 63 53 52 0 Sign Biased exponent Normalized Mantissa ( implicit 53rd bit ) Exponent Mantissa Object Represented 0 1-2046 2047 2047 0 anything 0 non-zero 0 FP number pm infinity NaN ( -1 ) s  F  2E-1023 Lec 14 Systems Architecture 13 Floating-Point Precision • Relative precision – all fraction bits are significant – Single : approx 2–23 • Equivalent to 23 × log102 ≈ 23 × 0.3 ≈ 6 decimal digits of precision – Double : approx 2–52 • Equivalent to 52 × log102 ≈ 52 × 0.3 ≈ 16 decimal digits of precision Lec 14 Systems Architecture 14 Floating Point Addition Lec 14 Systems Architecture Floating point addition Sign Exponent Fraction Sign Exponent Fraction • Small ALU Exponent difference 0 1 0 1 0 1 Control Shift right Big ALU 0 1 0 1 Increment or decrement Shift left or right Rounding hardware Sign Exponent Fraction Sta r t 1 . C o m p a re th e ex po n e n ts of th e tw o n u m b e rs . S h ift th e sm a lle r n u m b er to th e rig h t u n til its ex po n en t w o uld m a tc h th e la rg e r ex p o n e nt 2 . A d d th e s ig n ifica n d s 3 . N o rm a lize th e su m , e ith e r sh ifting rig ht a n d in cre m e n ting th e ex p o n e nt or s h iftin g le ft a n d d e cre m e n tin g th e ex p o n en t O ve rflow o r u n d e rflow ? Ye s N o E xc e p tio n 4 . R o u n d the s ig n ific a n d to th e a pp ro pr ia te n u m b er o f b its N o Still n o r m a lize d ? Ye s D o n e Lec 14 Systems Architecture 16 Floating-Point Addition • Consider a 4-digit decimal example – 9.999 × 101 + 1.610 × 10–1 • 1 . Align decimal points – Shift number with smaller exponent – 9.999 × 101 + 0.016 × 101 • 2 . Add significands – 9.999 × 101 + 0.016 × 101 = 10.015 × 101 • 3 . Normalize result & check for over/underflow – 1.0015 × 102 • 4 . Round and renormalize if necessary – 1.002 × 102 Lec 14 Systems Architecture 17 Floating-Point Addition • Now consider a 4-digit binary example – 1.0002 × 2–1 + –1.1102 × 2–2 ( 0.5 + –0.4375 ) • 1 . Align binary points – Shift number with smaller exponent – 1.0002 × 2–1 + –0.1112 × 2–1 • 2 . Add significands – 1.0002 × 2–1 + –0.1112 × 2–1 = 0.0012 × 2–1 • 3 . Normalize result & check for over/underflow – 1.0002 × 2–4 , with no over/underflow • 4 . Round and renormalize if necessary – 1.0002 × 2–4 ( no change ) = 0.0625 Lec 14 Systems Architecture 18 FP Adder Hardware • Much more complex than integer adder • Doing it in one clock cycle would take too long – Much longer than integer operations – Slower clock would penalize all instructions • FP adder usually takes several cycles – Can be pipelined Lec 14 Systems Architecture 19 FP Adder Hardware Step 1 Step 2 Step 3 Step 4 Lec 14 Systems Architecture 20 Floating Point Multiplication Lec 14 Systems Architecture Floating Point Multiplication Algorithm Lec 14 Systems Architecture 22 Floating-Point Multiplication • Consider a 4-digit decimal example – 1.110 × 1010 × 9.200 × 10–5 • 1 . Add exponents – For biased exponents , subtract bias from sum – New exponent = 10 + –5 = 5 • 2 . Multiply significands – 1.110 × 9.200 = 10.212  10.212 × 105 • 3 . Normalize result & check for over/underflow – 1.0212 × 106 • 4 . Round and renormalize if necessary – 1.021 × 106 • 5 . Determine sign of result from signs of operands – +1.021 × 106 Lec 14 Systems Architecture 23 Floating-Point Multiplication • Now consider a 4-digit binary example – 1.0002 × 2–1 × –1.1102 × 2–2 ( 0.5 × –0.4375 ) • 1 . Add exponents – Unbiased : –1 + –2 = –3 – Biased : ( –1 + 127 ) + ( –2 + 127 ) = –3 + 254 – 127 = –3 + 127 • 2 . Multiply significands – 1.0002 × 1.1102 = 1.1102  1.1102 × 2–3 • 3 . Normalize result & check for over/underflow – 1.1102 × 2–3 ( no change ) with no over/underflow • 4 . Round and renormalize if necessary – 1.1102 × 2–3 ( no change ) • 5 . Determine sign : +ve × –ve  –ve – –1.1102 × 2–3 = –0.21875 Lec 14 Systems Architecture 24 FP Arithmetic Hardware • FP multiplier is of similar complexity to FP adder – But uses a multiplier for significands instead of an adder • FP arithmetic hardware usually does – Addition , subtraction , multiplication , division , reciprocal , square-root – FP  integer conversion • Operations usually takes several cycles – Can be pipelined Lec 14 Systems Architecture 25 Advantages of IEEE 754 Standard Used predominantly by the industry Encoding of exponent and fraction simplifies comparison Integer comparator used to compare magnitude of FP numbers Includes special exceptional values : NaN and ±∞ Special rules are used such as : 0/0 is NaN , sqrt ( –1 ) is NaN , 1/0 is ∞ , and 1/∞ is 0 Computation may continue in the face of exceptional conditions FP Instructions in MIPS • Floating point operations are slower than integer operations • Data is rarely converted from integers to float within the same procedure • • 1980 ’ s solution – place FP processing unit in a separate chip Today ’ s solution – imbed FP processing unit in processor chip • Co-processor 1 features : – Contains 32 single precision floating point registers : $ f0 , $ f1 , … $ f31 – These registers can also act as 16 double precision registers : $ f0/ $ f1 , $ f2/ $ f3 , … , $ f30/ $ f31 ( only the first one is specified in the instructions ) – Uses special floating point instructions , which are similar ( in format ) to integer instructions but have .s or .d attached to signify that they work on fp numbers – Several special instructions to move between “ regular ” registers and the co- processor registers Lec 14 Systems Architecture 27 MIPS Floating Point Coprocessor Called Coprocessor 1 or the Floating Point Unit ( FPU ) 32 separate floating point registers : $ f0 , $ f1 , … , $ f31 FP registers are 32 bits for single precision numbers Even-odd register pair form a double precision register Use the even number for double precision registers $ f0 , $ f2 , $ f4 , … , $ f30 are used for double precision Separate FP instructions for single/double precision Single precision : add.s , sub.s , mul.s , div.s Double precision : add.d , sub.d , mul.d , div.d ( .s extension ) ( .d extension ) FP instructions are more complex than the integer ones Take more cycles to execute The MIPS Processor . . . 4 bytes per word Memory Up to 232 bytes = 230 words EIU 32 General Purpose Registers Arithmetic & Logic Unit ALU $ 0 $ 1 $ 2 $ 31 Execution & Integer Unit ( Main proc ) Integer mul/div Hi Lo Integer Multiplier/Divider FPU FP Arith TMU . . . F0 F1 F2 F31 Floating Point Unit ( Coproc 1 ) Trap & Memory Unit ( Coproc 0 ) BadVaddr Status Cause EPC 32 Floating-Point Registers Floating-Point Arithmetic Unit Coprocessor Instruction Set • Load word to coprocessor • Store word from coprocessor • Move to coprocessor • Move from coprocessor • Move control to coprocessor • Move control from coprocessor • Coprocessor operation • Branch on coprocessor true • Branch on coprocessor false FP Arithmetic Instructions Instruction add.s fd , fs , ft add.d fd , fs , ft sub.s fd , fs , ft sub.d fd , fs , ft mul.s fd , fs , ft mul.d fd , fs , ft fd , fs , ft div.s div.d fd , fs , ft sqrt.s fd , fs sqrt.d fd , fs abs.s fd , fs abs.d fd , fs neg.s fd , fs neg.d fd , fs Meaning ( fd ) = ( fs ) + ( ft ) ( fd ) = ( fs ) + ( ft ) ( fd ) = ( fs ) – ( ft ) ( fd ) = ( fs ) – ( ft ) ( fd ) = ( fs ) × ( ft ) ( fd ) = ( fs ) × ( ft ) ( fd ) = ( fs ) / ( ft ) ( fd ) = ( fs ) / ( ft ) ( fd ) = sqrt ( fs ) ( fd ) = sqrt ( fs ) ( fd ) = abs ( fs ) ( fd ) = abs ( fs ) ( fd ) = – ( fs ) ( fd ) = – ( fs ) Format ft5 ft5 ft5 ft5 ft5 ft5 ft5 ft5 0 0 0 0 0 0 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fs5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 fd5 0 1 0 1 0 1 0 1 0 1 0 1 0 1 0 0 1 1 2 2 3 3 4 4 5 5 7 7 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 FP Load/Store Instructions  Separate floating point load/store instructions  lwc1 : load word coprocessor 1  ldc1 : load double coprocessor 1  swc1 : store word coprocessor 1  sdc1 : store double coprocessor 1 General purpose register is used as the base register Instruction lwc1 $ f2 , 40 ( $ t0 ) ldc1 $ f2 , 40 ( $ t0 ) swc1 $ f2 , 40 ( $ t0 ) sdc1 $ f2 , 40 ( $ t0 ) Meaning ( $ f2 ) = Mem [ ( $ t0 ) +40 ] ( $ f2 ) = Mem [ ( $ t0 ) +40 ] Mem [ ( $ t0 ) +40 ] = ( $ f2 ) Mem [ ( $ t0 ) +40 ] = ( $ f2 ) Format $ f2 $ f2 $ f2 $ f2 $ t0 $ t0 $ t0 $ t0 im16 = 40 im16 = 40 im16 = 40 im16 = 40 0x31 0x35 0x39 0x3d  Better names can be used for the above instructions  l.s = lwc1 ( load FP single ) , l.d = ldc1 ( load FP double )  s.s = swc1 ( store FP single ) , s.d = sdc1 ( store FP double ) FP Data Movement Instructions  Moving data between general purpose and FP registers  mfc1 : move from coprocessor 1 ( to general purpose register )  mtc1 : move to coprocessor 1 ( from general purpose register )  Moving data between FP registers  mov.s : move single precision float  mov.d : move double precision float = even/odd pair of registers Instruction mfc1 $ t0 , $ f2 Meaning ( $ t0 ) = ( $ f2 ) mtc1 $ t0 , $ f2 ( $ f2 ) = ( $ t0 ) mov.s $ f4 , $ f2 ( $ f4 ) = ( $ f2 ) mov.d $ f4 , $ f2 ( $ f4 ) = ( $ f2 ) 0x11 0x11 0x11 0x11 0 4 0 1 Format $ t0 $ f2 $ t0 0 0 $ f2 $ f2 $ f2 0 0 $ f4 $ f4 0 0 6 6 FP Convert Instructions  Convert instruction : cvt.x.y  Convert to destination format x from source format y  Supported formats  Single precision float = .s ( single precision float in FP register )  Double precision float = .d ( double float in even-odd FP register )  Signed integer word = .w ( signed integer in FP register ) Instruction cvt.s.w fd , fs cvt.s.d fd , fs cvt.d.w fd , fs cvt.d.s fd , fs cvt.w.s fd , fs cvt.w.d fd , fs Meaning to single from integer to single from double to double from integer to double from single to integer from single to integer from double 0x11 0x11 0x11 0x11 0x11 0x11 0 1 0 1 0 1 Format fs5 0 fs5 0 fs5 0 fs5 0 fs5 0 fs5 0 fd5 fd5 fd5 fd5 fd5 fd5 0x20 0x20 0x21 0x21 0x24 0x24 FP Compare and Branch Instructions  FP unit ( co-processor 1 ) has a condition flag  Set to 0 ( false ) or 1 ( true ) by any comparison instruction  Three comparisons : equal , less than , less than or equal  Two branch instructions based on the condition flag Instruction c.eq.s fs , ft c.eq.d fs , ft fs , ft c.lt.s fs , ft c.lt.d fs , ft c.le.s c.le.d fs , ft bc1f bc1t Label Label Meaning cflag = ( ( fs ) == ( ft ) ) cflag = ( ( fs ) == ( ft ) ) cflag = ( ( fs ) < = ( ft ) ) cflag = ( ( fs ) < = ( ft ) ) cflag = ( ( fs ) < = ( ft ) ) cflag = ( ( fs ) < = ( ft ) ) branch if ( cflag == 0 ) branch if ( cflag == 1 ) 0x11 0x11 0x11 0x11 0x11 0x11 0x11 0x11 Format ft5 fs5 ft5 fs5 ft5 fs5 ft5 fs5 ft5 fs5 ft5 fs5 0 1 0 1 0 1 0 1 8 8 0x32 0x32 0x3c 0x3c 0x3e 0x3e 0 0 0 0 0 0 im16 im16 FP Data Directives .FLOAT Directive Stores the listed values as single-precision floating point .DOUBLE Directive Stores the listed values as double-precision floating point Examples var1 : .FLOAT 12.3 , -0.1 var2 : .DOUBLE 1.5e-10 pi : .DOUBLE 3.1415926535897924 Syscall Services Service $ v0 Arguments / Result Print Integer Print Float Print Double Print String Read Integer Read Float Read Double Read String 1 2 3 4 5 6 7 8 Exit Program Print Char Read Char 10 11 12 $ a0 = integer value to print $ f12 = float value to print $ f12 = double value to print $ a0 = address of null-terminated string $ v0 = integer read $ f0 = float read $ f0 = double read $ a0 = address of input buffer $ a1 = maximum number of characters to read $ a0 = character to print $ a0 = character read Supported by MARS FP Example : °F to °C • C code : float f2c ( float fahr ) { return ( ( 5.0/9.0 ) * ( fahr - 32.0 ) ) ; } – fahr in $ f12 , result in $ f0 , literals in global memory space • Compiled MIPS code : f2c : lwc1 $ f16 , const5 ( $ gp ) lwc2 $ f18 , const9 ( $ gp ) div.s $ f16 , $ f16 , $ f18 lwc1 $ f18 , const32 ( $ gp ) sub.s $ f18 , $ f12 , $ f18 mul.s $ f0 , $ f16 , $ f18 jr $ ra Lec 14 Systems Architecture 38",
    "3- adversarial search.txt": "Adversarial Search Dr. Emad Natsheh Space of Search Strategies Adversarial Search Types of Games • Many different kinds of games • Axes • Deterministic or stochastic ? • One two or more player ? • Zero sum ? • Perfect information ( you can see the state ) Deterministic and Perfect Information Games • Perfect Information Games • States • Actions • Successor function • Terminal test • Deterministic • Non-Deterministic : You can look at Expectimax search , and Markov Decision Processes Zero Sum Games Deterministic Single-Player Deterministic Two-Player Game Theory ( Strategy ) Mini-Max Algorithm Game Tree Mini-Max Algorithm • Deterministic , zero-sum , perfect information , two player • Tic-Tac-Toe , chess • One player maximizes result • The other minimizes result How Mini-Max work ? Example Evaluation Function Depth Matters ▪ Evaluation functions are always imperfect ▪ The deeper in the tree the evaluation function is buried , the less the quality of the evaluation function matters Evaluation Function ( Tic-Tac-Toe ) Mini-Max Pseudocode Example Example 2 Example 2 Game NIM Game NIM Mini-Max Analysis • Time Complexity • Space Complexity Mini-Max Analysis • Can we do betters ? How ? Alpha-Beta Pruning Alpha-Beta Pruning Alpha-Beta Pruning Pseudocode α=-inf Β=+inf V= α= Β= V= α= Β= V= α= Β= V= α= Β= V= α= Β= V= α= Β= V= α= Β= V= α= Β= V= Alpha-Beta Analysis Multi-Agent Utilities Multi-Agent Utilities • What if the game has multiple player ? • Generalization of minimax : • Evaluation function given by vector • All players are Max MINIMAXWITHOUT abababab-PRUNINGMiniMax & Constraint Processing : MiniMaxAlgorithm MiniMaxwithout ab-pruningMaxMin435214235473214053027453136MaxMin3 MiniMaxwithout ab-pruningMaxMin435214235473214053027453136MaxMin31 MiniMaxwithout ab-pruningMaxMin435214235473214053027453136MaxMin312472030231 MiniMaxwithout ab-pruningMaxMin435214235473214053027453136MaxMin3124720302313 MiniMaxwithout ab-pruningMaxMin435214235473214053027453136MaxMin31247203023132 MiniMaxwithout ab-pruningMaxMin435214235473214053027453136MaxMin312472030231327033 MiniMaxwithout ab-pruningMaxMin02435214235473214053027453136MaxMin312472030231327033 MiniMaxwithout ab-pruningMaxMin022435214235473214053027453136MaxMin312472030231327033 MINIMAXWITH abababab-PRUNINGMiniMax & Constraint Processing : MiniMaxAlgorithm MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin MiniMaxwith ab-pruningMaxMin•aaaa-nodes : TemporaryvaluesatMIN-nodes435214235473214053027453136MaxMin≤4 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin≤4 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin≤3 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin≤3 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin=3 MiniMaxwith ab-pruningMaxMin•bbbb-nodes : TemporaryvaluesatMAX-nodes435214235473214053027453136MaxMin=3≥3 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin=3≥3 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin=3≥3≤2 MiniMaxwith ab-pruningMaxMin•Prune : Parentbbbb-node≥Childaaaa-node435214235473214053027453136MaxMin=3≥3≤2 MiniMaxwith ab-pruningMaxMin435214235473214053027453136MaxMin=3=3=2 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2≤4 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2≤4 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2≤2 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2≤2 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2=2 MiniMaxwith ab-pruningMaxMin≤3435214235473214053027453136MaxMin=3=3=2=2=2 MiniMaxwith ab-pruningMaxMin≤2435214235473214053027453136MaxMin=3=3=2=2=2 MiniMaxwith ab-pruningMaxMin≤2435214235473214053027453136MaxMin=3=3=2=2=2 MiniMaxwith ab-pruningMaxMin≤2435214235473214053027453136MaxMin=3=3=2=2=2≤5 MiniMaxwith ab-pruningMaxMin≤2435214235473214053027453136MaxMin=3=3=2=2=2≤5 MiniMaxwith ab-pruningMaxMin≤2435214235473214053027453136MaxMin=3=3=2=2=2=4 MiniMaxwith ab-pruningMaxMin≤2435214235473214053027453136MaxMin=3=3=2=2=2=4≥4 MiniMaxwith ab-pruningMaxMin≤2•Prune : Parentaaaa-node≤Childbbbb-node435214235473214053027453136MaxMin=3=3=2=2=2=4≥4 MiniMaxwith ab-pruningMaxMin=2435214235473214053027453136MaxMin=3=3=2=2=2=4=4 MiniMaxwith ab-pruningMaxMin=2≥2435214235473214053027453136MaxMin=3=3=2=2=2=4=4 MiniMaxwith ab-pruningMaxMin=2≥2435214235473214053027453136MaxMin=3=3=2=2=2=4=4 MiniMaxwith ab-pruningMaxMin=2≥2435214235473214053027453136MaxMin=3=3=2=2=2=4=4≤1 MiniMaxwith ab-pruningMaxMin=2≥2• “ Deep ” cut-off : Ancestorbbbb-node≥aaaa-node435214235473214053027453136MaxMin=3=3=2=2=2=4=4≤1 MiniMaxwith ab-pruningMaxMin=2≥2435214235473214053027453136MaxMin=3=3=2=2=2=4=4=1=1 MiniMaxwith ab-pruningMaxMin=2≥2≤1435214235473214053027453136MaxMin=3=3=2=2=2=4=4=1=1 MiniMaxwith ab-pruningMaxMin=2≥2≤1•Prune : Parentbbbb-node≥Childaaaa-node435214235473214053027453136MaxMin=3=3=2=2=2=4=4=1=1 MiniMaxwith ab-pruningMaxMin=2=2=1•17staticevaluationssaved435214235473214053027453136MaxMin=3=3=2=2=2=4=4=1=1 PROBLEM 2MiniMax & Constraint Processing : MiniMaxAlgorithm Problem 2•Canthenodesbeorderedinsuchawaythatab-pruningcancutoffmorebranches ? Max435214235473214053027453136MinMaxMin OPTIMIZING abababab-PRUNINGMiniMax & Constraint Processing : MiniMaxAlgorithm Optimizing ab-Pruning•Bestcase : Eachlayerbestnodeleft-to-rightMaxMin022435214235473214053027453136MaxMin312472030231327033 Optimizing ab-Pruning•Bestcase : Eachlayerbestnodeleft-to-rightMaxMin435214235473214053027453136MaxMin312472030231327033 Optimizing ab-Pruning•Bestcase : Eachlayerbestnodeleft-to-rightMaxMin435214235473214053027453136MaxMin312472030231 Optimizing ab-Pruning•Bestcase : Eachlayerbestnodeleft-to-rightMaxMin345122344572301435024713536MaxMin MINIMAXWITH abababab-PRUNINGMiniMax & Constraint Processing : MiniMaxAlgorithm Minimaxwith ab-PruningMaxMin345122344572301435024713536MaxMin Minimaxwith ab-PruningMaxMin345122344572301435024713536MaxMin≤2 Minimaxwith ab-PruningMaxMin345122344572301435024713536MaxMin≤2 Minimaxwith ab-PruningMaxMin345122344572301435024713536MaxMin≤2 Minimaxwith ab-PruningMaxMin345122344572301435024713536MaxMin=2 Minimaxwith ab-PruningMaxMin345122344572301435024713536MaxMin=2=2 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2≤3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2≤3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2≤3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3≥3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3≥3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3=3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3=3 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3=3=7 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3=3=7≥7 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3=3=7≥7 Minimaxwith ab-PruningMaxMin≤2345122344572301435024713536MaxMin=2=2=3=3=7=7 Minimaxwith ab-PruningMaxMin=2345122344572301435024713536MaxMin=2=2=3=3=7=7 Minimaxwith ab-PruningMaxMin=2≥2345122344572301435024713536MaxMin=2=2=3=3=7=7 Minimaxwith ab-PruningMaxMin=2≥2345122344572301435024713536MaxMin=2=2=3=3=7=7 Minimaxwith ab-PruningMaxMin=2≥2345122344572301435024713536MaxMin=2=2=3=3=7=7≤0 Minimaxwith ab-PruningMaxMin=2≥2345122344572301435024713536MaxMin=2=2=3=3=7=7≤0 Minimaxwith ab-PruningMaxMin=2≥2345122344572301435024713536MaxMin=2=2=3=3=7=7=0 Minimaxwith ab-PruningMaxMin=2≥2345122344572301435024713536MaxMin=2=2=3=3=7=7=0=0 Minimaxwith ab-PruningMaxMin=2≥2≤0345122344572301435024713536MaxMin=2=2=3=3=7=7=0=0 Minimaxwith ab-PruningMaxMin=2≥2≤0345122344572301435024713536MaxMin=2=2=3=3=7=7=0=0 Minimaxwith ab-PruningMaxMin=2≥2=0•19staticevaluationssaved345122344572301435024713536MaxMin=2=2=3=3=7=7=0=0 Exercises : Artificial IntelligenceMiniMax & Constraint Processing : MiniMaxAlgorithm for 3 Players PROBLEMMiniMax & Constraint Processing : MiniMaxAlgorithm for 3 Players Problem•ComeupwithaMiniMaxalgorithmfor3playersandapplyonthefigurebelow .. . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 5. . .. . .. . .. . .. . .. . . MINIMAXFOR 3 PLAYERSMiniMax & Constraint Processing : MiniMaxAlgorithm MiniMaxFor 3 Players•AllplayersareMax•Evaluationfunctiongivenbyvector . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 5. . .. . .. . .. . .. . .. . . MiniMaxFor 3 Players•Eachlayerassignedto1player•Turn : every3layers . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 5. . .. . .. . .. . .. . .. . .Player 3Player 2Player 1 MiniMaxFor 3 Players•Maxthirdplayer : thirdpositionofvector . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 5. . .. . .. . .. . .. . .. . .Player 3 MiniMaxFor 3 Players•MaxThirdPlayer ( [ 1,2,3 ] , [ 4,2,1 ] ) = [ 1,2,3 ] •MaxThirdPlayer ( [ 6,1,2 ] , [ 7,4 , -1 ] ) = [ 6,1,2 ] •MaxThirdPlayer ( [ 5 , -1 , -1 ] , [ -1,5,2 ] ) = [ -1,5,2 ] •MaxThirdPlayer ( [ 7,7 , -1 ] , [ 5,4,5 ] ) = [ 5,4,5 ] . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 2 36 1 2. . .. . .-1 5 25 4 5Player 3 MiniMaxFor 3 Players•Secondplayer ’ smove . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 2 36 1 2. . .. . .-1 5 25 4 5Player 3Player 2 MiniMaxFor 3 Players•Maxsecondplayer : secondpositionofvector . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 236 12. . .. . .-1 525 45Player 3Player 2 MiniMaxFor 3 Players•MaxSecondPlayer ( [ 1,2,3 ] , [ 6,1,2 ] ) = [ 1,2,3 ] •MaxSecondPlayer ( [ -1,5,2 ] , [ 5,4,5 ] ) = [ -1,5,2 ] . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 236 121 2 3-1 5 2-1 525 45Player 3Player 2 MiniMaxFor 3 Players•Firstplayer ’ smove . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 2 36 1 21 2 3-1 5 2-1 5 25 4 5Player 3Player 2Player 1 MiniMaxFor 3 Players•Maxfirstplayer : firstpositionofvector . . .1 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 2 36 1 212 3-15 2-1 5 25 4 5Player 3Player 2Player 1 MiniMaxFor 3 Players•MaxFirstPlayer ( [ 1,2,3 ] , [ -1,5,4 ] ) = [ 1,2,3 ] 1 2 31 2 34 2 16 1 27 4 -15 -1 -1-1 5 27 7 -15 4 51 2 36 1 212 3-15 2-1 5 25 4 5Player 3Player 2Player 1",
    "4-_Perceptron.txt": "Machine Learning ( Artificial Neural Network ) Dr. Emad Natsheh Types of Machine Learning PERCEPTRON Biological Neuron vs Perceptron What is Perceptron • It 's a single node neural network that can take different inputs but produce only one output • Perceptron is usually used to classify the data into two parts . Therefore , it is also known as a Linear Binary Classifier . How does the neuron determine its output ? 1 . Computes the weighted sum input 2 . Apply the value to the activation function ( step , sign , sigmoid , linear ) How does the neuron determine its output ? Activation Functions Example How does a perceptron learn ❖This is done by making small adjustments in the weights to reduce the difference between the actual and desired outputs of the perceptron Perceptron learn Perceptron learn Perceptron learn Perceptron Example – AND Perceptron Example – AND • Epoch 1 – Iteration 1 ( input X1=0 ; X2=0 ; Yd=0 ) : • ( 0 * 0.3 + 0 * -0.1 ) -0.2 = -0.2 • Ya =step ( -0.2 ) =0 • Error=Yd-Ya= 0 • ∆w1=0 ; ∆w2=0 ; – Iteration 2 ( input X1=0 ; X2=1 ; Yd=0 ) : • ( 0 * 0.3 + 1 * -0.1 ) -0.2 = -0.3 • Ya =step ( -0.3 ) =0 • Error=Yd-Ya= 0 • ∆w1=0 ; ∆w2=0 ; Perceptron Example – AND – Iteration 3 ( input X1=1 ; X2=0 ; Yd=0 ) • ( 1 * 0.3 + 0 * -0.1 ) -0.2 = +0.1 • Ya =step ( +0.1 ) =1 • Error=Yd-Ya= -1 • ∆w1= 0.1 * 1 * -1= -0.1 • W1 ( new ) =w1 ( old ) + ∆w1 =0.3-0.1 =0.2 • ∆w2 =0 Perceptron Example – AND Perceptron Example – AND Summary • Single perceptron can be trained to recognize any linear separable function • Perceptron is able to represent a function only if there is some line that separates all the black dots from all the white dots Decision line w1 x1 + w2 x2 = q Drawing Line Y= 2x-2 𝟏 Y= - 𝟐 x+1 Drawing Line ( AND example ) 0.1X1 + 0.1X2-0.2=0 X2=-X1 + 2 Summary Summary Summary • A Neural Network Playground - TensorFlow Next Topic • Feed-forward neural network",
    "8-Multicore (1).txt": "Multi-core Processors Multi-core Processors Processor development till 2004 Out-of-order Instruction scheduling 2 Historical Perspective o 80 ’ s till 2004 the exponential increase in the number of transistors predicted by Moore ’ s Law ( 2x /18 mons . ) was used : n Implement sophisticated O.O.O & Superscalar designs n Design Large Caches o Increasing operating frequency Although successful for several years , this approach has eventually hit the Power , Memory and ILP walls Solution : Chip Multiprocessors ( CMP ) Use the transistors to increase the number of cores on a chip New challenge : Concurrency 3 The Switch to Multi-core The number of transistors is still increasing but more aggressive wider-issue , higher-clocked superscalars are not produced anymore , Why ? ? Transistor Influenza Virus Feature Size Billions Transis 2004 2006 2008 2010 2012 2014 2016 2018 90nm 65nm 45nm 32nm 22nm 16nm 11nm 8nm 2 4 8 16 32 64 128 256 * * o Complexity of the designs : power , leakage , heat , design difficulty , deep pipelines o Power/Heat ( Power Wall ) : heat , bills cooling , packaging , hot-spot , deep pipelines , can not increase clock frequencies o Lack of ILP ( ILP Wall ) : ILP rarely exceeds 7 , with average 5 o Marginal gain of incremental logic : N : transistors Perf = O ( sqrt ( N ) ) Power O ( N ) * * Source : Intel 4 1000 e c n a m r o f r e P 100 10 1 The Memory Wall “ Moore ’ s Law ” CPU µProc 60 % /yr . ( 2X/1.5yr ) Processor-Memory Performance Gap : ( grows 50 % / year ) 0 8 9 1 1 8 9 1 2 8 9 1 3 8 9 1 4 8 9 1 5 8 9 1 6 8 9 1 7 8 9 1 8 8 9 1 9 8 9 1 0 9 9 1 1 9 9 1 2 9 9 1 3 9 9 1 4 9 9 1 5 9 9 1 6 9 9 1 7 9 9 1 8 9 9 1 9 9 9 1 0 0 0 2 DRAM DRAM 9 % /yr . ( 2X/10 yrs ) 5 The Multi-core/Concurrency Era ( Why Multi-core ? ) o The solution for the previous problems is : n Use the silicon estate to put more processors on the same die n More area/power efficient n Scale the processor without complex designs n Shift the focus to extracting Thread Level Parallelism ( TLP ) Currently “ throughput programming ” Per ~ Area Per ~ √Area Power Perf . Power Perf . Power Perf . 6 Single-core computer 7 Single-core CPU chip the single core 8 Multi-core architectures Replicate multiple processor cores on a single die . Core 1 Core 2 Core 3 Core 4 Multi-core CPU chip 9 Multi-core processor Multi-core CPU chip • The cores fit on a single processor socket • Also called CMP ( Chip Multi-Processor ) c o r e 1 c o r e 2 c o r e 3 c o r e 4 11 The cores run in parallel thread 1 thread 2 thread 3 thread 4 c o r e 1 c o r e 2 c o r e 3 c o r e 4 12 Within each core , threads are time-sliced ( just like on a uniprocessor ) several threads several threads several threads several threads c o r e 1 c o r e 2 c o r e 3 c o r e 4 13 Interaction with the Operating System • OS perceives each core as a separate processor • OS scheduler maps threads/processes to different cores • Most major OS support multi-core today : Windows , Linux , Mac OS X , … 14 Instruction-level parallelism ( ILP ) • Parallelism at the machine-instruction level • The processor can re-order , pipeline instructions , split them into microinstructions , do aggressive branch prediction , etc . • Instruction-level parallelism enabled rapid increases in processor speeds over the last 15 years 15 Thread-level parallelism ( TLP ) • This is parallelism on a more coarser scale • Server can serve each client in a separate thread ( Web server , database server ) • A computer game can do AI , graphics , and a physics-related computation in three separate threads • Single-core superscalar processors can not fully exploit TLP • Multi-core architectures are the next step in processor evolution : explicitly exploiting TLP 16 Data Level Parallelism ( DLP ) • Also called SIMD or Vectorization • More on this later 17 What applications benefit from multi-core ? • Database servers • Web servers ( Web commerce ) • Multimedia applications • Scientific applications , CAD/CAM • In general , applications with Thread-level parallelism ( as opposed to instruction-level parallelism ) are better supported Each can run on its own core 18 More examples • Editing a photo while recording a TV show through a digital video recorder • Downloading software while running an anti-virus program • “ Anything that can be threaded today will map efficiently to multi-core ” • BUT : some applications difficult to parallelize 19 Multi-core design issues & Challenges o Programming multi-cores ( Concurrency ) – is Difficult and is the biggest challenge now n Parallel Lang./Extensions n H.W support n ILP was implicit v.s . TLP and DLP explicit n Parallelizing Compilers o On-chip Memory ( Memory Wall ) & Interconnection Network : n How to Scale up to tens/hundreds of cores : need on chip memory n Cache design/Shared vs. private Caches/Coherency ( space vs latency ) n Interconnect choices significantly affects overall performance n Bus/Point-to-Point/Cross-bar/Ring/Mesh/Omega ( cost vs latency ) o What is the best building blocks ? n Simple/complex/SMT/in-order/out-of-order cores ? n Homogeneous or heterogeneous ? o Best Balance between Cores/Caches/Interconnect ? 20 Heterogeneous Multicores 21 Heterogeneous vs. Homogeneous Homogeneous Multi-core Heterogeneous Multi-core Big Core ( Complex , out-of-order , superscalar , branch prediction , etc . ) Small Core ( Simple , focus on ALU . ) 22 Heterogeneous Multicores o Offers advantages compared to homogeneous multicores in : n Power/Area : code requiring complex out-of-order execution with branch-predication/speculation runs on the complex cores ( fast power inefficient cores ) . Less control-flow code requiring ALU and data parallel ( ex . SIMD/Vector ) ( multiple threads running on many cores ) n Mitigating Amdahl ’ s Law : execute serial portions on the fast and complex core and parallel portions on the smaller cores . n Different types of applications run simultaneously on these cores . 23 Amdahl ’ s Law The performance of a parallel program is limited by the serial ( non-parallelizable ) part of the program 24 Non-Parallelizable Parallelizable 8s 8s Single Core Non-Parallelizable Parallelizable 8s 8s Total Time : 16s 25 Non-Parallelizable Parallelizable 8s 8s Non-Parallelizable Parallelizable 8s 4s 4s Multi-Core ( 2 cores ) Total Time : 12s 26 Non-Parallelizable Parallelizable 8s 8s Non-Parallelizable Parallelizable 8s 2s 2s 2s 2s Multi-Core ( 4 cores ) Total Time : 10s 27 Non-Parallelizable Parallelizable 8s 8s Non-Parallelizable Parallelizable 8s 0s 0s … 0s Multi-Core ( ∞ cores ) Total Time : 8s 28 Thread Level Parallelism ( TLP ) 30 SIMD Vectorization DLP 42 Motivation • Intel analyzed multimedia applications and found they share the following characteristics : – Small native data types ( 8-bit pixel , 16-bit audio ) – Recurring operations ( same instruction on many pieces of large data sets ) . – Inherent parallelism • This gave birth to Vector/SIMD support at the level of instructions in mainstream-processors . Scalar vs. SIMD • Scalar processing —traditional mode —one operation produces one result • SIMD vector units — Same operation on multiple data —one operation produces multiple results X + Y X x3 x2 x1 x0 + Y y3 y2 y1 y0 X + Y X + Y x3+y3 x2+y2 x1+y1 x0+y0 Slide Credit : Alex Klimovitski & Dean Macri , Intel Corporation 9 SIMD • SIMD ( single instruction multiple data ) architecture performs the same operation on multiple data elements in parallel • PADDW MM0 , MM1 Flynn Taxonomy SIMD Architecture Support • MMX ( Multimedia Extension ) was introduced in 1996 - PI / PII . • 64-bit vectors / Only integer operations • SSE ( Streaming SIMD Extension ) - Pentium III . • 128-bit vectors ( only floating-point ) • SSE2 - P4 . ( floating-point , double & Integer ) • SSE3 - P4/HT • 13 more instructions . • AVX ( Advanced Vector Extensions ) – 2011 • 256-bit vectors • SIMD extensions for other architectures : • 3DNow ! / Altivec / VIS / VMX The SSE family of Vector extensions – Include over 400 instructions – Available in most modern processors – Uses 16 dedicated registers of length 128 bits – Programming with AVX is similar , vector length and instruction names differ SSE SSSE4.2 SSSE3 MMX SSE SSE3 SSSE4.1 SSE2 AVX 1997 1999 2001 2011 3 MMX data types Application : frame difference A B |A-B| Application : frame difference A-B B-A ( A-B ) or ( B-A ) Loading from array to register Scalar Vector/SIMD 53 Application : frame difference MOVQ MOVQ MOVQ PSUBSB PSUBSB POR mm1 , A //move 8 pixels of image A mm2 , B //move 8 pixels of image B mm3 , mm1 // mm3=A mm1 , mm2 // mm1=A-B mm2 , mm3 // mm2=B-A mm1 , mm2 // mm1=|A-B| Performance boost ( data from 1996 ) Benchmark kernels : FFT , FIR , vector dot- product , IDCT , motion compensation . 65 % performance gain Lower the cost of multimedia programs by removing the need of specialized DSP chips 94 Issues with MMX q Only supported integer operations q MMX and FPU can not be used at the same time . § Used the same set of registers § Big overhead to switch . q This proved to be a bad decision later . q It is why Intel introduced SSE later as a separate unit . SSE • Adds eight 128-bit registers • Allows SIMD operations on packed single- precision floating-point numbers • Later added support for double-precision FP • Most SSE instructions require 16-aligned addresses • Instructions that explicitly prefetch data , control data cacheability and ordering of store SSE programming environment XMM0 | XMM7 MM0 | MM7 EAX , EBX , ECX , EDX EBP , ESI , EDI , ESP SSE packed FP operation • ADDPS/SUBPS : packed single-precision FP SSE scalar FP operation • ADDSS/SUBSS : scalar single-precision FP SSE features • Add data types and instructions for them Programming environment unchanged How to use assembly in projects qWrite the whole project in assembly § Difficult/rare qLink with high-level languages § Develop most of the program in HLL § Use assembly for performance critical parts qInline assembly § Inline Assembly code directly into a HLL program . § Compilers such as Visual C++ have compiler- specific directives to identify inline ASM code . qIntrinsics Intrinsics q A function known by the compiler that directly maps to a sequence of assembly instructions . q The compiler manages : § Register names § Register allocations § Memory locations of data q More efficient than called functions § No calling linkage is required . _mm_ < opcode > _ < suffix > ps : packed single-precision ss : scalar single-precision Intrinsics # include < xmmintrin.h > m128 a , b , c ; c = _mm_add_ps ( a , b ) ; float a [ 4 ] , b [ 4 ] , c [ 4 ] ; for ( int i = 0 ; i < 4 ; ++ i ) c [ i ] = a [ i ] + b [ i ] ; // a = b * c + d / e ; m128 a = _mm_add_ps ( _mm_mul_ps ( b , c ) , _mm_div_ps ( d , e ) ) ; More Examples 68 VMX Example ( PowerPC ) E.g . 1 : Use in variable initialization statement ( Vector literal is bolded ) __vector signed int va = ( __vector signed int ) { -2 , -1 , 1 , 2 } ; va = vec_add ( va , ( ( __vector signed int ) { 1 , 2 , 3 , 4 } ) ) ; E.g . 2 : Accessing vector as a scalar - the third element of a vector ( Pointer cast is bolded ) __vector signed int va = ( __vector signed int ) { 1 , 2 , 3 , 4 } ; int * a = ( int * ) & va ; printf ( “ a [ 2 ] = % d ” , a [ 2 ] ) ; E.g . 3 : Accessing a scalar array as a vectors ( Pointer cast is bolded ) int a [ 8 ] __attribute__ ( ( aligned ( 16 ) ) ) = { 1 , 2 , 3 , 4 , 5 , 6 , 7 , 8 } ; __vector signed int * va = ( __vector signed int * ) a ; // va [ 0 ] = { 1 , 2 , 3 , 4 } , va [ 1 ] = { 5 , 6 , 7 , 8 } vb = vec_add ( va [ 0 ] , va [ 1 ] ) ; VMX Example ( PowerPC ) # include < stdio.h > # include < altivec.h > // declares input/output scalar varialbes int a [ 4 ] __attribute__ ( ( aligned ( 16 ) ) ) = { 1 , 3 , 5 , 7 } ; int b [ 4 ] __attribute__ ( ( aligned ( 16 ) ) ) = { 2 , 4 , 6 , 8 } ; int c [ 4 ] __attribute__ ( ( aligned ( 16 ) ) ) ; int main ( int argc , char * * argv ) { // declares vector variables which points to scalar arrays __vector signed int * va = ( __vector signed int * ) a ; __vector signed int * vb = ( __vector signed int * ) b ; __vector signed int * vc = ( __vector signed int * ) c ; // adds four signed integers at once * vc = vec_add ( * va , * vb ) ; // 1 + 2 , 3 + 4 , 5 + 6 , 7 + 8 // output results printf ( `` c [ 0 ] = % d , c [ 1 ] = % d , c [ 2 ] = % d , c [ 3 ] = % d\\n '' , c [ 0 ] , c [ 1 ] , c [ 2 ] , c [ 3 ] ) ; return 0 ; } float Scalar ( float * s1 , float * s2 ) { SSE Example ( intel ) int i ; float prod ; for ( i=0 ; i < size ; i++ ) { prod += s1 [ i ] * s2 [ i ] ; } return prod ; } float ScalarSSE ( float * s1 , float * s2 ) { Z [ 0 ] = s1 [ 0 ] * s2 [ 0 ] + s1 [ 4 ] * s2 [ 4 ] + s1 [ 8 ] * s2 [ 8 ] +… Z [ 1 ] = s1 [ 1 ] * s2 [ 1 ] + s1 [ 5 ] * s2 [ 5 ] + s1 [ 9 ] * s2 [ 9 ] +… Z [ 2 ] = s1 [ 2 ] * s2 [ 2 ] + s1 [ 6 ] * s2 [ 6 ] + s1 [ 10 ] * s2 [ 10 ] +… Z [ 3 ] = s1 [ 3 ] * s2 [ 3 ] + s1 [ 7 ] * s2 [ 7 ] + s1 [ 11 ] * s2 [ 11 ] +… float prod ; int i ; __m128 X , Y , Z ; for ( i=0 ; i < size ; i+=4 ) { X = _mm_load_ps ( & s1 [ i ] ) ; Y = _mm_load_ps ( & s2 [ i ] ) ; X = _mm_mul_ps ( X , Y ) ; Z = _mm_add_ps ( X , Z ) ; } for ( i=0 ; i < 4 ; i++ ) { prod += Z [ i ] ; } return prod ; } Other SIMD architectures • Graphics Processing Unit ( GPU ) References • Intel MMX for Multimedia PCs , CACM , Jan. 1997 • Chapter 11 The MMX Instruction Set , The Art of Assembly • Chap . 9 , 10 , 11 of IA-32 Intel Architecture Software Developer ’ s Manual : Volume 1 : Basic Architecture • http : //www.csie.ntu.edu.tw/~r89004/hive/sse/page_1.html",
    "8-SIMD-additional.txt": "How to Write Fast Numerical Code Spring 2016 Lecture : SIMD extensions , SSE , compiler vectorization Instructor : Markus Püschel TA : Gagandeep Singh , Daniele Spampinato , Alen Stojanov Flynn ’ s Taxonomy Single data Multiple data Single instruction Multiple instruction SISD Uniprocessor MISD SIMD Vector computer Short vector extensions MIMD Multiprocessors VLIW © Markus Püschel Computer Science 2 How to write fast numerical code Spring 2016 SIMD Extensions and SSE  Overview : SSE family  SSE intrinsics  Compiler vectorization  This lecture and material was created together with Franz Franchetti ( ECE , Carnegie Mellon ) SIMD Vector Extensions + x 4-way  What is it ?  Extension of the ISA  Data types and instructions for the parallel computation on short ( length 2 , 4 , 8 , … ) vectors of integers or floats  Names : MMX , SSE , SSE2 , …  Why do they exist ?  Useful : Many applications have the necessary fine-grain parallelism Then : speedup by a factor close to vector length  Doable : Relative easy to design ; chip designers have enough transistors to play with 3 4 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 MMX : Multimedia extension SSE : Streaming SIMD extension AVX : Advanced vector extensions register width 64 bit ( only int ) Intel x86 Processors © Markus Püschel Computer Science x86-16 x86-32 MMX SSE SSE2 SSE3 8086 286 386 486 Pentium Pentium MMX Pentium III Pentium 4 Pentium 4E Pentium 4F time 128 bit x86-64 / em64t SSE4 AVX AVX2 Core 2 Duo Penryn Core i7 ( Nehalem ) Sandy Bridge Haswell 256 bit SSE Family : Floating Point SSE4 SSSE3 SSE3 SSE2 : 2-way double SSE : 4-way single  Not drawn to scale  From SSE3 : Only additional instructions  Every Core 2 has SSE3 © Markus Püschel Computer Science 6 How to write fast numerical code Spring 2016 Overview Floating-Point Vector ISAs Within an extension family , newer generations add features to older ones Convergence : 3DNow ! Professional = 3DNow ! + SSE ; VMX = AltiVec ; Core 2  Has SSE3  16 SSE registers 128 bit = 2 doubles = 4 singles % xmm0 % xmm1 % xmm2 % xmm3 % xmm4 % xmm5 % xmm6 % xmm7 % xmm8 % xmm9 % xmm10 % xmm11 % xmm12 % xmm13 % xmm14 % xmm15 7 8 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 VendorNameº-wayPrecisionIntroducedwithIntelSSE4-waysinglePentiumIIISSE2+2-waydoublePentium4SSE3Pentium4 ( Prescott ) SSSE3CoreDuoSSE4Core2Extreme ( Penryn ) AVX8-waysingleCorei7 ( Sandybridge ) 4-waydoubleIntelIPF2-waysingleItaniumIntelLRB16-waysingleLarrabee8-waydoubleAMD3DNow ! 2-waysingleK6Enhanced3DNow ! K73DNow ! Professional+4-waysingleAthlonXPAMD64+2-waydoubleOpteronMotorolaAltiVec4-waysingleMPC7400G4IBMVMX4-waysinglePowerPC970G5SPU+2-waydoubleCellBEIBMDoubleFPU2-waydoublePowerPC440FP2 SSE3 Registers  Different data types and associated instructions 128 bit LSB  Integer vectors :  16-way byte  8-way 2 bytes  4-way 4 bytes  2-way 8 bytes  Floating point vectors :  4-way single ( since SSE )  2-way double ( since SSE2 )  Floating point scalars :  single ( since SSE )  double ( since SSE2 ) SSE3 Instructions : Examples  Single precision 4-way vector add : addps % xmm0 % xmm1 +  Single precision scalar add : addss % xmm0 % xmm1 + % xmm0 % xmm1 % xmm0 % xmm1 9 10 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE3 Instruction Names packed ( vector ) single slot ( scalar ) addps addss single precision addpd addsd double precision Compiler will use this for floating point • on x86-64 • with proper flags if SSE/SSE2 is available 11 x86-64 FP Code Example float ipf ( float x [ ] , float y [ ] , int n ) { int i ; float result = 0.0 ; for ( i = 0 ; i < n ; i++ ) result += x [ i ] * y [ i ] ; return result ; }  Inner product of two vectors  Single precision arithmetic  Compiled : not vectorized , uses SSE instructions ipf : xorps xorl jmp .L10 : % xmm1 , % xmm1 % ecx , % ecx .L8 % ecx movslq % ecx , % rax incl movss ( % rsi , % rax,4 ) , % xmm0 mulss ( % rdi , % rax,4 ) , % xmm0 addss % xmm0 , % xmm1 .L8 : cmpl % edx , % ecx .L10 jl movaps % xmm1 , % xmm0 ret © Markus Püschel Computer Science # result = 0.0 # i = 0 # goto middle # loop : # icpy = i # i++ # t = y [ icpy ] # t * = x [ icpy ] # result += t # middle : # i : n # if < goto loop # return result 12 How to write fast numerical code Spring 2016 From Core 2 Manual Latency , throughput SSE based FP x87 FP Summary  On Core 2 there are two different ( unvectorized ) floating points  x87 : obsolete , is default on x86-32  SSE based : uses only one slot , is default on x86-64  SIMD vector floating point instructions  4-way single precision : since SSE  2-way double precision : since SSE2  SSE vector add and mult are fully pipelined ( 1 per cycle ) : possible gain 4x and 2x , respectively  Starting with Sandybridge , AVX was introduced : 8-way single , 4-way double 13 14 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE : How to Take Advantage ? + instead of +  Necessary : fine grain parallelism  Options ( ordered by effort ) :  Use vectorized libraries ( easy , not always available )  Compiler vectorization ( this lecture )  Use intrinsics ( this lecture )  Write assembly  We will focus on floating point and single precision ( 4-way ) SIMD Extensions and SSE  Overview : SSE family  SSE intrinsics  Compiler vectorization References : Intel Intrinsics Guide ( contains latency and throughput information ! ) http : //software.intel.com/en-us/articles/intel-intrinsics-guide Intel icc compiler manual Visual Studio manual 15 16 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Family : Floating Point SSE4 SSSE3 SSE3 SSE2 : 2-way double SSE : 4-way single  Not drawn to scale  From SSE2 : Only additional instructions  Every Core 2 has SSE3 SSE Family Intrinsics  Assembly coded C functions  Expanded inline upon compilation : no overhead  Like writing assembly inside C  Floating point :  Intrinsics for math functions : log , sin , …  Intrinsics for SSE  Our introduction is based on icc  Most intrinsics work with gcc and Visual Studio ( VS )  Some language extensions are icc ( or even VS ) specific 17 18 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Header files  SSE : xmmintrin.h  SSE2 : emmintrin.h  SSE3 : pmmintrin.h  SSSE3 : tmmintrin.h  SSE4 : smmintrin.h and nmmintrin.h or ia32intrin.h Visual Conventions We Will Use  Memory increasing address memory LSB  Registers  Before ( and common ) R3 R2 R1 R0  Now we will use LSB R0 R1 R2 R3 19 20 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Intrinsics ( Focus Floating Point )  Data types __m128 f ; // = { float f0 , f1 , f2 , f3 } __m128d d ; // = { double d0 , d1 } __m128i i ; // 16 8-bit , 8 16-bit , 4 32-bit , or 2 64-bit ints ints ints ints or floats ints or doubles SSE Intrinsics ( Focus Floating Point )  Instructions  Naming convention : _mm_ < intrin_op > _ < suffix >  Example : // a is 16-byte aligned float a [ 4 ] = { 1.0 , 2.0 , 3.0 , 4.0 } ; __m128 t = _mm_load_ps ( a ) ; p : packed s : single precision LSB 1.0 2.0 3.0 4.0  Same result as __m128 t = _mm_set_ps ( 4.0 , 3.0 , 2.0 , 1.0 ) 21 22 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Intrinsics  Native instructions ( one-to-one with assembly ) _mm_load_ps ( ) _mm_add_ps ( ) _mm_mul_ps ( ) …  Multi instructions ( map to several assembly instructions ) _mm_set_ps ( ) _mm_set1_ps ( ) …  Macros and helpers _MM_TRANSPOSE4_PS ( ) _MM_SHUFFLE ( ) … What Are the Main Issues ?  Alignment is important ( 128 bit = 16 byte )  You need to code explicit loads and stores  Overhead through shuffles 23 24 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 SSE Intrinsics  Load and store  Constants  Arithmetic  Comparison  Conversion  Shuffles Loads and Stores Intrinsic Name Operation _mm_loadh_pi _mm_loadl_pi _mm_load_ss Load high Load low Corresponding SSE Instructions MOVHPS reg , mem MOVLPS reg , mem Load the low value and clear the three high values MOVSS _mm_load1_ps Load one value into all four words MOVSS + Shuffling _mm_load_ps Load four values , address aligned _mm_loadu_ps Load four values , address unaligned MOVAPS MOVUPS _mm_loadr_ps Load four values in reverse MOVAPS + Shuffling Intrinsic Name Operation Corresponding SSE Instruction Set the low value and clear the three high values Composite _mm_set_ss _mm_set1_ps _mm_set_ps _mm_setr_ps Set all four words with the same value Set four values , address aligned Set four values , in reverse order _mm_setzero_ps Clear all four values Composite Composite Composite Composite 25 26 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Loads and Stores p 1.0 2.0 3.0 4.0 memory LSB 1.0 2.0 3.0 4.0 a a = _mm_load_ps ( p ) ; // p 16-byte aligned a = _mm_loadu_ps ( p ) ; // p not aligned avoid ( can be expensive ) on recent Intel possibly no penalty → blackboard 27 How to Align  __m128 , __m128d , __m128i are 16-byte aligned  Arrays : __declspec ( align ( 16 ) ) float g [ 4 ] ;  Dynamic allocation  _mm_malloc ( ) and _mm_free ( )  Write your own malloc that returns 16-byte aligned addresses  Some malloc ’ s already guarantee 16-byte alignment © Markus Püschel Computer Science 28 How to write fast numerical code Spring 2016 Loads and Stores p 1.0 2.0 memory LSB 1.0 2.0 a kept LSB 1.0 2.0 a kept a = _mm_loadl_pi ( a , p ) ; // p 8-byte aligned a = _mm_loadh_pi ( a , p ) ; // p 8-byte aligned Loads and Stores p 1.0 LSB 1.0 0 0 0 a set to zero a = _mm_load_ss ( p ) ; // p any alignment memory 29 → blackboard 30 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Stores Analogous to Loads Intrinsic Name _mm_storeh_pi _mm_storel_pi Operation Store high Store low Corresponding SSE Instruction MOVHPS mem , reg MOVLPS mem , reg _mm_store_ss Store the low value MOVSS _mm_store1_ps Store the low value across all four words , address aligned Shuffling + MOVSS _mm_store_ps Store four values , address aligned MOVAPS _mm_storeu_ps Store four values , address unaligned MOVUPS _mm_storer_ps Store four values , in reverse order MOVAPS + Shuffling 31 Constants LSB 1.0 2.0 3.0 4.0 a a = _mm_set_ps ( 4.0 , 3.0 , 2.0 , 1.0 ) ; LSB 1.0 1.0 1.0 1.0 b b = _mm_set1_ps ( 1.0 ) ; LSB 1.0 0 0 0 c c = _mm_set_ss ( 1.0 ) ; LSB 0 0 0 0 d d = _mm_setzero_ps ( ) ; → blackboard 32 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Arithmetic SSE Intrinsic Name Operation _mm_add_ss _mm_add_ps Addition Addition _mm_sub_ss Subtraction _mm_sub_ps Subtraction _mm_mul_ss Multiplication _mm_mul_ps Multiplication _mm_div_ss _mm_div_ps Division Division _mm_sqrt_ss Squared Root _mm_sqrt_ps Squared Root _mm_rcp_ss Reciprocal _mm_rcp_ps Reciprocal SSE3 Corresponding SSE Instruction Intrinsic Name Operation Corresponding SSE3 Instruction _mm_addsub_ps Subtract and add ADDSUBPS _mm_hadd_ps Add _mm_hsub_ps Subtracts HADDPS HSUBPS SSE4 Intrinsic Operation Corresponding SSE4 Instruction _mm_dp_ps Single precision dot product DPPS ADDSS ADDPS SUBSS SUBPS MULSS MULPS DIVSS DIVPS SQRTSS SQRTPS RCPSS RCPPS _mm_rsqrt_ss Reciprocal Squared Root RSQRTSS _mm_rsqrt_ps Reciprocal Squared Root RSQRTPS _mm_min_ss Computes Minimum _mm_min_ps Computes Minimum _mm_max_ss Computes Maximum _mm_max_ps Computes Maximum MINSS MINPS MAXSS MAXPS 33 Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 1.5 3.5 5.5 7.5 c c = _mm_add_ps ( a , b ) ; analogous : c = _mm_sub_ps ( a , b ) ; c = _mm_mul_ps ( a , b ) ; → blackboard 34 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example void addindex ( float * x , int n ) { for ( int i = 0 ; i < n ; i++ ) x [ i ] = x [ i ] + i ; } # include < ia32intrin.h > // n a multiple of 4 , x is 16-byte aligned void addindex_vec ( float * x , int n ) { __m128 index , x_vec ; for ( int i = 0 ; i < n ; i+=4 ) { x_vec = _mm_load_ps ( x+i ) ; // load 4 floats index = _mm_set_ps ( i+3 , i+2 , i+1 , i ) ; // create vector with indexes x_vec = _mm_add_ps ( x_vec , index ) ; // add the two _mm_store_ps ( x+i , x_vec ) ; // store back } } Is this the best solution ? No ! _mm_set_ps may be too expensive Example void addindex ( float * x , int n ) { for ( int i = 0 ; i < n ; i++ ) x [ i ] = x [ i ] + i ; } # include < ia32intrin.h > // n a multiple of 4 , x is 16-byte aligned void addindex_vec ( float * x , int n ) { __m128 x_vec , init , incr ; = _mm_set_ps ( 3 , 2 , 1 , 0 ) ; ind incr = _mm_set1_ps ( 4 ) ; for ( int i = 0 ; i < n ; i+=4 ) { x_vec = _mm_load_ps ( x+i ) ; // load 4 floats x_vec = _mm_add_ps ( x_vec , ind ) ; ind = _mm_add_ps ( ind , incr ) ; // update ind _mm_store_ps ( x+i , x_vec ) ; // store back // add the two } } How does the code style differ from scalar code ? Intrinsics force scalar replacement ! 35 36 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 b LSB 1.5 2.0 3.0 4.0 c c = _mm_add_ss ( a , b ) ; Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b max max max max LSB 1.0 2.0 3.0 4.0 c c = _mm_max_ps ( a , b ) ; 37 38 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 0.5 3.5 0.5 7.5 c c = _mm_addsub_ps ( a , b ) ; Arithmetic LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 3.0 7.0 2.0 6.0 c c = _mm_hadd_ps ( a , b ) ; analogous : c = _mm_hsub_ps ( a , b ) ; 39 → blackboard 40 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example // n is even void lp ( float * x , float * y , int n ) { for ( int i = 0 ; i < n/2 ; i++ ) y [ i ] = ( x [ 2 * i ] + x [ 2 * i+1 ] ) /2 ; } # include < ia32intrin.h > // n a multiple of 8 , x , y are 16-byte aligned void lp_vec ( float * x , int n ) { __m128 half , v1 , v2 , avg ; half = _mm_set1_ps ( 0.5 ) ; // set vector to all 0.5 for ( int i = 0 ; i < n/8 ; i++ ) { v1 = _mm_load_ps ( x+i * 8 ) ; // load first 4 floats v2 = _mm_load_ps ( x+4+i * 8 ) ; // load next 4 floats avg = _mm_hadd_ps ( v1 , v2 ) ; // add pairs of floats avg = _mm_mul_ps ( avg , half ) ; _mm_store_ps ( y+i * 4 , avg ) ; // save result // multiply with 0.5 } } Arithmetic __m128 _mm_dp_ps ( __m128 a , __m128 b , const int mask ) ( SSE4 ) Computes the pointwise product of a and b and writes a selected sum of the resulting numbers into selected elements of c ; the others are set to zero . The selections are encoded in the mask . Example : mask = 117 = 01110101 LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b 0.5 3.0 7.5 14.0 01110101 Σ LSB 11.0 0 11.0 0 c 41 42 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Comparisons Intrinsic Name Operation _mm_cmpeq_ss _mm_cmpeq_ps _mm_cmplt_ss _mm_cmplt_ps _mm_cmple_ss _mm_cmple_ps _mm_cmpgt_ss _mm_cmpgt_ps _mm_cmpge_ss _mm_cmpge_ps _mm_cmpneq_ss _mm_cmpneq_ps _mm_cmpnlt_ss _mm_cmpnlt_ps _mm_cmpnle_ss _mm_cmpnle_ps _mm_cmpngt_ss _mm_cmpngt_ps _mm_cmpnge_ss _mm_cmpnge_ps Equal Equal Less Than Less Than Less Than or Equal Less Than or Equal Greater Than Greater Than Greater Than or Equal Greater Than or Equal Not Equal Not Equal Not Less Than Not Less Than Not Less Than or Equal Not Less Than or Equal Not Greater Than Not Greater Than Not Greater Than or Equal Not Greater Than or Equal Corresponding SSE Instruction CMPEQSS CMPEQPS CMPLTSS CMPLTPS CMPLESS CMPLEPS CMPLTSS CMPLTPS CMPLESS CMPLEPS CMPNEQSS CMPNEQPS CMPNLTSS CMPNLTPS CMPNLESS CMPNLEPS CMPNLTSS CMPNLTPS CMPNLESS CMPNLEPS Intrinsic Name _mm_cmpord_ss _mm_cmpord_ps _mm_cmpunord_ss _mm_cmpunord_ps _mm_comieq_ss _mm_comilt_ss _mm_comile_ss _mm_comigt_ss _mm_comige_ss _mm_comineq_ss _mm_ucomieq_ss _mm_ucomilt_ss _mm_ucomile_ss _mm_ucomigt_ss _mm_ucomige_ss _mm_ucomineq_ss Operation Corresponding SSE Instruction CMPORDSS Ordered CMPORDPS Ordered CMPUNORDSS Unordered CMPUNORDPS Unordered COMISS Equal COMISS Less Than COMISS Less Than or Equal COMISS Greater Than COMISS Greater Than or Equal COMISS Not Equal UCOMISS Equal UCOMISS Less Than UCOMISS Less Than or Equal Greater Than UCOMISS Greater Than or Equal UCOMISS UCOMISS Not Equal Comparisons LSB 1.0 2.0 3.0 4.0 a LSB 1.0 1.5 3.0 3.5 b = ? = ? = ? = ? LSB 0xffffffff 0x0 0xffffffff 0x0 c c = _mm_cmpeq_ps ( a , b ) ; analogous : c = _mm_cmple_ps ( a , b ) ; c = _mm_cmplt_ps ( a , b ) ; c = _mm_cmpge_ps ( a , b ) ; etc . Each field : 0xffffffff if true 0x0 if false Return type : __m128 43 44 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example void fcond ( float * x , size_t n ) { int i ; for ( i = 0 ; i < n ; i++ ) { if ( x [ i ] > 0.5 ) x [ i ] += 1. ; else x [ i ] -= 1. ; } } # include < xmmintrin.h > void fcond ( float * a , size_t n ) { int i ; __m128 vt , vmask , vp , vm , vr , ones , mones , thresholds ; ones = _mm_set1_ps ( 1 . ) ; mones = _mm_set1_ps ( -1 . ) ; thresholds = _mm_set1_ps ( 0.5 ) ; for ( i = 0 ; i < n ; i+=4 ) { = _mm_load_ps ( a+i ) ; vt vmask = _mm_cmpgt_ps ( vt , thresholds ) ; = _mm_and_ps ( vmask , ones ) ; vp = _mm_andnot_ps ( vmask , mones ) ; vm vr = _mm_add_ps ( vt , _mm_or_ps ( vp , vm ) ) ; _mm_store_ps ( a+i , vr ) ; } } 45 © Markus Püschel Computer Science Vectorization = Picture : www.druckundbestell.de © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Conversion Intrinsic Name Operation _mm_cvtss_si32 Convert to 32-bit integer _mm_cvtss_si64 * Convert to 64-bit integer Corresponding SSE Instruction CVTSS2SI CVTSS2SI _mm_cvtps_pi32 Convert to two 32-bit integers CVTPS2PI _mm_cvttss_si32 Convert to 32-bit integer _mm_cvttss_si64 * Convert to 64-bit integer CVTTSS2SI CVTTSS2SI _mm_cvttps_pi32 Convert to two 32-bit integers CVTTPS2PI _mm_cvtsi32_ss Convert from 32-bit integer _mm_cvtsi64_ss * Convert from 64-bit integer CVTSI2SS CVTSI2SS _mm_cvtpi32_ps Convert from two 32-bit integers CVTTPI2PS _mm_cvtpi16_ps Convert from four 16-bit integers composite _mm_cvtpu16_ps Convert from four 16-bit integers composite _mm_cvtpi8_ps Convert from four 8-bit integers composite _mm_cvtpu8_ps Convert from four 8-bit integers composite _mm_cvtpi32x2_ps Convert from four 32-bit integers composite _mm_cvtps_pi16 Convert to four 16-bit integers composite _mm_cvtps_pi8 Convert to four 8-bit integers composite _mm_cvtss_f32 Extract composite Conversion float _mm_cvtss_f32 ( __m128 a ) LSB 1.0 2.0 3.0 4.0 a 1.0 f float f ; f = _mm_cvtss_f32 ( a ) ; 47 48 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Cast floats ints __m128i _mm_castps_si128 ( __m128 a ) __m128 _mm_castsi128_ps ( __m128i a ) Reinterprets the four single precision floating point values in a as four 32-bit integers , and vice versa . No conversion is performed . Does not map to any assembly instructions . Makes integer shuffle instructions usable for floating point . → blackboard 49 Shuffles SSE Intrinsic Name Operation _mm_shuffle_ps Shuffle _mm_unpackhi_ps Unpack High _mm_unpacklo_ps Unpack Low _mm_move_ss Set low word , pass in three high values Corresponding SSE Instruction SHUFPS UNPCKHPS UNPCKLPS MOVSS _mm_movehl_ps Move High to Low MOVHLPS SSE3 Intrinsic Name Operation Corresponding SSE3 Instruction _mm_movehdup_ps Duplicates MOVSHDUP _mm_moveldup_ps Duplicates MOVSLDUP SSSE3 Intrinsic Name Operation Corresponding SSSE3 Instruction _mm_movelh_ps Move Low to High MOVLHPS _mm_shuffle_epi8 Shuffle _mm_movemask_ps Create four-bit mask MOVMSKPS _mm_alignr_epi8 Shift SSE4 Intrinsic Syntax Operation PSHUFB PALIGNR Corresponding SSE4 Instruction __m128 _mm_blend_ps ( __m128 v1 , __m128 v2 , const int mask ) Selects float single precision data from 2 BLENDPS __m128 _mm_blendv_ps ( __m128 v1 , __m128 v2 , __m128 v3 ) __m128 _mm_insert_ps ( __m128 dst , __m128 src , const int ndx ) sources using constant mask Selects float single precision data from 2 sources using variable mask Insert single precision float into packed single precision array element selected by index . BLENDVPS INSERTPS int _mm_extract_ps ( __m128 src , const int ndx ) Extract single precision float from packed single precision array selected by index . EXTRACTPS 50 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Shuffles LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 1.0 0.5 2.0 1.5 c c = _mm_unpacklo_ps ( a , b ) ; LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 3.0 2.5 4.0 3.5 c c = _mm_unpackhi_ps ( a , b ) ; → blackboard 51 Shuffles c = _mm_shuffle_ps ( a , b , _MM_SHUFFLE ( l , k , j , i ) ) ; helper macro to create mask LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB c0 c1 c2 c3 c any element of a any element of b c0 = ai c1 = aj c2 = bk c3 = bl i , j , k , l in { 0,1,2,3 } → blackboard 52 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example : Loading 4 Real Numbers from Arbitrary Memory Locations p0 p1 p2 p3 1.0 2.0 3.0 4.0 memory LSB 1.0 0 0 0 LSB 3.0 0 0 0 LSB 2.0 0 0 0 LSB 4.0 0 0 0 LSB 1.0 0 2.0 0 LSB 3.0 0 4.0 0 4x _mm_load_ss 2x _mm_shuffle_ps 1x _mm_shuffle_ps LSB 1.0 2.0 3.0 4.0 7 instructions , this is one good way of doing it 53 Code For Previous Slide # include < ia32intrin.h > __m128 LoadArbitrary ( float * p0 , float * p1 , float * p2 , float * p3 ) { __m128 a , b , c , d , e , f ; a = _mm_load_ss ( p0 ) ; b = _mm_load_ss ( p1 ) ; c = _mm_load_ss ( p2 ) ; d = _mm_load_ss ( p3 ) ; e = _mm_shuffle_ps ( a , b , _MM_SHUFFLE ( 1,0,2,0 ) ) ; //only zeros are important f = _mm_shuffle_ps ( c , d , _MM_SHUFFLE ( 1,0,2,0 ) ) ; //only zeros are important return _mm_shuffle_ps ( e , f , _MM_SHUFFLE ( 2,0,2,0 ) ) ; } © Markus Püschel Computer Science 54 How to write fast numerical code Spring 2016 Example : Loading 4 Real Numbers from Arbitrary Memory Locations ( cont ’ d )  Whenever possible avoid the previous situation  Restructure algorithm and use the aligned _mm_load_ps ( )  Other possibility ( but likely also yields 7 instructions ) __m128 vf ; vf = _mm_set_ps ( * p3 , * p2 , * p1 , * p0 ) ;  SSE4 : _mm_insert_epi32 together with _mm_castsi128_ps  Not clear whether better Example : Loading 4 Real Numbers from Arbitrary Memory Locations ( cont ’ d )  Do not do this ( why ? ) : __declspec ( align ( 16 ) ) float g [ 4 ] ; __m128 vf ; g [ 0 ] = * p0 ; g [ 1 ] = * p1 ; g [ 2 ] = * p2 ; g [ 3 ] = * p3 ; vf = _mm_load_ps ( g ) ; 55 56 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example : Storing 4 Real Numbers to Arbitrary Memory Locations LSB 1.0 2.0 3.0 4.0 LSB 4.0 0 0 0 LSB 3.0 0 0 0 LSB 2.0 0 0 0 3x _mm_shuffle_ps 4x _mm_store_ss 1.0 2.0 3.0 4.0 memory 7 instructions , shorter critical path Shuffle __m128i _mm_alignr_epi8 ( __m128i a , __m128i b , const int n ) Concatenate a and b and extract byte-aligned result shifted to the right by n bytes Example : View __m128i as 4 32-bit ints ; n = 12 LSB 1 2 3 4 b LSB 5 6 7 8 a n = 12 bytes LSB 4 5 6 7 c How to use this with floating point vectors ? Use with _mm_castsi128_ps ! 57 58 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Example void shift ( float * x , float * y , int n ) { for ( int i = 0 ; i < n-1 ; i++ ) y [ i ] = x [ i+1 ] ; y [ n-1 ] = 0 ; } # include < ia32intrin.h > // n a multiple of 4 , x , y are 16-byte aligned void shift_vec ( float * x , float * y , int n ) { __m128 f ; __m128i i1 , i2 , i3 ; i1 = _mm_castps_si128 ( _mm_load_ps ( x ) ) ; // load first 4 floats and cast to int for ( int i = 0 ; i < n-8 ; i = i + 4 ) { i2 = _mm_castps_si128 ( _mm_load_ps ( x+4+i ) ) ; // load next 4 floats and cast to int f = _mm_castsi128_ps ( _mm_alignr_epi8 ( i2 , i1,4 ) ) ; // shift and extract and cast back _mm_store_ps ( y+i , f ) ; // store it i1 = i2 ; // make 2nd element 1st } // we are at the last 4 i2 = _mm_castps_si128 ( _mm_setzero_ps ( ) ) ; // set the second vector to 0 and cast to int f = _mm_castsi128_ps ( _mm_alignr_epi8 ( i2 , i1,4 ) ) ; // shift and extract and cast back _mm_store_ps ( y+n-4 , f ) ; // store it } Shuffle __m128i _mm_shuffle_epi8 ( __m128i a , __m128i mask ) Result is filled in each position by any element of a or with 0 , as specified by mask Example : View __m128i as 4 32-bit ints LSB 1 2 3 4 a LSB 4 1 0 2 c Use with _mm_castsi128_ps to do the same for floating point 59 60 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Shuffle __m128 _mm_blendv_ps ( __m128 a , __m128 b , __m128 mask ) ( SSE4 ) Result is filled in each position by an element of a or b in the same position as specified by mask Example : LSB 0x0 0xffffffff 0x0 0x0 mask LSB 1.0 2.0 3.0 4.0 a LSB 0.5 1.5 2.5 3.5 b LSB 1.0 1.5 3.0 4.0 c see also _mm_blend_ps Example ( Continued From Before ) void fcond ( float * x , size_t n ) { int i ; for ( i = 0 ; i < n ; i++ ) { if ( x [ i ] > 0.5 ) x [ i ] += 1. ; else x [ i ] -= 1. ; } } # include < xmmintrin.h > void fcond ( float * a , size_t n ) { int i ; __m128 vt , vmask , vp , vm , vr , ones , mones , thresholds ; ones = _mm_set1_ps ( 1 . ) ; = _mm_set1_ps ( -1 . ) ; mones thresholds = _mm_set1_ps ( 0.5 ) ; for ( i = 0 ; i < n ; i+=4 ) { = _mm_load_ps ( a+i ) ; vt vmask = _mm_cmpgt_ps ( vt , thresholds ) ; vb vr = _mm_blendv_ps ( ones , mones , vmask ) ; = _mm_add_ps ( vt , vb ) ; } } 61 62 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Shuffle _MM_TRANSPOSE4_PS ( row0 , row1 , row2 , row3 ) Macro for 4 x 4 matrix transposition : The arguments row0 , … , row3 are __m128 values each containing a row of a 4 x 4 matrix . After execution , row0 , .. , row 3 contain the columns of that matrix . LSB 1.0 2.0 3.0 4.0 row0 LSB 1.0 5.0 9.0 13.0 row0 LSB 5.0 6.0 7.0 8.0 row1 LSB 2.0 6.0 10.0 14.0 row1 LSB 9.0 10.0 11.0 12.0 row2 LSB 3.0 7.0 11.0 15.0 row2 LSB 13.0 14.0 15.0 16.0 row3 LSB 4.0 8.0 12.0 16.0 row3 In SSE : 8 shuffles ( 4 _mm_unpacklo_ps , 4 _mm_unpackhi_ps ) Vectorization With Intrinsics : Key Points  Use aligned loads and stores  Minimize overhead ( shuffle instructions ) = maximize vectorization efficiency  Definition : Vectorization efficiency Op count of scalar ( unvectorized ) code Op count of vectorized code includes shuffles does not include loads/stores  Ideally : Efficiency = ν for ν-way vector instructions  assumes no vector instruction does more than ν scalar ops  assumes every vector instruction has the same cost ( not true : see hadd for example ) 63 64 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Vectorization Efficiency : Example 2  4 x 4 matrix-vector multiplication  Blackboard LSB LSB LSB LSB a b c d LSB LSB = x y SIMD Extensions and SSE  Overview : SSE family  SSE intrinsics  Compiler vectorization References : Intel icc manual ( look for auto vectorization ) 65 66 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Compiler Vectorization  Compiler flags  Aliasing  Proper code style  Alignment Compiler Flags ( icc 12.0 ) Linux * OS and Mac OS * X Windows * OS Description -vec -no-vec /Qvec /Qvec- Enables or disables vectorization and transformations enabled for vectorization . Vectorization is enabled by default . To disable , use -no-vec ( Linux * and MacOS * X ) or /Qvec- ( Windows * ) option . Supported on IA-32 and Intel® 64 architectures only . -vec-report /Qvec-report Controls the diagnostic messages from the vectorizer . See Vectorization Report . -simd -no-simd /Qsimd /Qsimd- Controls user-mandated ( SIMD ) vectorization . User-mandated ( SIMD ) vectorization is enabled by default . Use the -no-simd ( Linux * or MacOS * X ) or /Qsimd- ( Windows * ) option to disable SIMD transformations for vectorization . Architecture flags : Linux : -xHost ¾ -mHost Windows : /QxHost ¾ /Qarch : Host Host in { SSE2 , SSE3 , SSSE3 , SSE4.1 , SSE4.2 } Default : -mSSE2 , /Qarch : SSE2 67 68 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 How Do I Know the Compiler Vectorized ?  vec-report ( previous slide )  Look at assembly : mulps , addps , xxxps  Generate assembly with source code annotation :  Visual Studio + icc : /Fas  icc on Linux/Mac : -S 69 void myadd ( float * a , float * b , const int n ) { for ( int i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; } Example unvectorized : /Qvec- < more > ; ; ; a [ i ] = a [ i ] + b [ i ] ; movss addss movss < more > xmm0 , DWORD PTR [ rcx+rax * 4 ] xmm0 , DWORD PTR [ rdx+rax * 4 ] DWORD PTR [ rcx+rax * 4 ] , xmm0 vectorized : xmm0 , DWORD PTR [ rcx+r11 * 4 ] xmm0 , DWORD PTR [ rdx+r11 * 4 ] DWORD PTR [ rcx+r11 * 4 ] , xmm0 < more > ; ; ; a [ i ] = a [ i ] + b [ i ] ; movss addss movss … movups movups addps addps movaps movaps < more > xmm0 , XMMWORD PTR [ rdx+r10 * 4 ] xmm1 , XMMWORD PTR [ 16+rdx+r10 * 4 ] xmm0 , XMMWORD PTR [ rcx+r10 * 4 ] xmm1 , XMMWORD PTR [ 16+rcx+r10 * 4 ] XMMWORD PTR [ rcx+r10 * 4 ] , xmm0 XMMWORD PTR [ 16+rcx+r10 * 4 ] , xmm1 why this ? why everything twice ? why movups and movaps ? unaligned aligned 70 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Aliasing for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; Can not be vectorized in a straightforward way due to potential aliasing . However , in this case compiler can insert runtime check : if ( a + n < b || b + n < a ) / * vectorized loop * / ... else / * serial loop * / ... Removing Aliasing  Globally with compiler flag :  -fno-alias , /Oa  -fargument-noalias , /Qalias-args- ( function arguments only )  For one loop : pragma void add ( float * a , float * b , int n ) { # pragma ivdep for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; }  For specific arrays : restrict ( needs compiler flag –restrict , /Qrestrict ) void add ( float * restrict a , float * restrict b , int n ) { for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; } 71 72 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Proper Code Style  Use countable loops = number of iterations known at runtime  Number of iterations is a : constant loop invariant term linear function of outermost loop indices  Countable or not ? for ( i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; void vsum ( float * a , float * b , float * c ) { int i = 0 ; while ( a [ i ] > 0.0 ) { a [ i ] = b [ i ] * c [ i ] ; i++ ; } } Proper Code Style  Use arrays , structs of arrays , not arrays of structs  Ideally : unit stride access in innermost loop void mmm1 ( float * a , float * b , float * c ) { int N = 100 ; int i , j , k ; for ( i = 0 ; i < N ; i++ ) for ( j = 0 ; j < N ; j++ ) for ( k = 0 ; k < N ; k++ ) c [ i ] [ j ] = c [ i ] [ j ] + a [ i ] [ k ] * b [ k ] [ j ] ; } void mmm2 ( float * a , float * b , float * c ) { int N = 100 ; int i , j , k ; for ( i = 0 ; i < N ; i++ ) for ( k = 0 ; k < N ; k++ ) for ( j = 0 ; j < N ; j++ ) c [ i ] [ j ] = c [ i ] [ j ] + a [ i ] [ k ] * b [ k ] [ j ] ; } 73 74 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Alignment float * x = ( float * ) malloc ( 1024 * sizeof ( float ) ) ; int i ; for ( i = 0 ; i < 1024 ; i++ ) x [ i ] = 1 ; Can not be vectorized in a straightforward way since x may not be aligned However , the compiler can peel the loop to extract aligned part : float * x = ( float * ) malloc ( 1024 * sizeof ( float ) ) ; int i ; peel = x & 0x0f ; / * x mod 16 * / if ( peel ! = 0 ) { peel = 16 - peel ; / * initial segment * / for ( i = 0 ; i < peel ; i++ ) x [ i ] = 1 ; } / * 16-byte aligned access * / for ( i = peel ; i < 1024 ; i++ ) x [ i ] = 1 ; Ensuring Alignment  Align arrays to 16-byte boundaries ( see earlier discussion )  If compiler can not analyze :  Use pragma for loops float * x = ( float * ) malloc ( 1024 * sizeof ( float ) ) ; int i ; # pragma vector aligned for ( i = 0 ; i < 1024 ; i++ ) x [ i ] = 1 ;  For specific arrays : __assume_aligned ( a , 16 ) ; 75 76 © Markus Püschel Computer Science How to write fast numerical code Spring 2016 More Tips ( icc 14.0 ) https : //software.intel.com/en-us/node/512631  Use simple for loops . Avoid complex loop termination conditions – the upper iteration limit must be invariant within the loop . For the innermost loop in a nest of loops , you could set the upper limit iteration to be a function of the outer loop indices .  Write straight-line code . Avoid branches such as switch , goto , or return statements , most function calls , orif constructs that can not be treated as masked assignments .   Avoid dependencies between loop iterations or at the least , avoid read-after-write dependencies . Try to use array notations instead of the use of pointers . C programs in particular impose very few restrictions on the use of pointers ; aliased pointers may lead to unexpected dependencies . Without help , the compiler often can not tell whether it is safe to vectorize code containing pointers .  Wherever possible , use the loop index directly in array subscripts instead of incrementing a separate counter for use as an array address .  Access memory efficiently : Favor inner loops with unit stride .   Minimize indirect addressing .  Align your data to 16 byte boundaries ( for SSE instructions ) .   Choose a suitable data layout with care . Most multimedia extension instruction sets are rather sensitive to alignment . … 77 void myadd ( float * a , float * b , const int n ) { for ( int i = 0 ; i < n ; i++ ) a [ i ] = a [ i ] + b [ i ] ; } Yes : Through versioning © Markus Püschel Computer Science Assume : • No aliasing information • No alignment information Can compiler vectorize ? function runtime check a , b potentially aliased ? no yes runtime check a , b aligned ? unvectorized loop yes , yes yes , no no , yes no , no vectorized loop aligned loads vectorized loop aligned and unaligned loads or peeling and aligned loads vectorized loop unaligned loads or peeling and aligned loads © Markus Püschel Computer Science How to write fast numerical code Spring 2016 Compiler Vectorization  Read manual 79 © Markus Püschel Computer Science How to write fast numerical code Spring 2016",
    "ex8+9net.txt": "Objectives : To be familiar with wireless network installation . Set up the adhoc mode and infrastructure for the wireless network . Give the wireless network security . Learn about the Access point 's operation and its underlying principles . Construct a network and use the network we have created to send files and data . Introduction : There are two sorts of networks : the broadly address network ( WAN or WLAN ) , which mostly depends on wireless technology , and the local area network ( LAN ) , which primarily depends on Ethernet technology . Tools : Cisco access point . 2x PCs . 1 straight forward Ethernet cable . Console cable . Procedure : Part 1 : WLAN infrastructure : Getting and Assigning an IP Address First , we use the console cable to connect the first station to the access point so that we can begin configuring the AP . Once we enter the terminal to begin the configuration process , the access point asks for a password , which is CISCO . Please refer to the following image for clarification . Next , we were instructed to use the ( sh run ) command , which will display details about the settings of the access point , including the model number , the encryption used , the IP and MAC addresses , and so forth . Following that , we assign IP addresses to both stations ( PCs ) . It is important to ensure that we assign IP addresses to the wireless network card rather than the Ethernet , as shown in the following image : Next , we were requested to provide the access point an IP address . To do this , we first went into the AP 's setup mode and selected the interface that was connected to the first station , as seen in the following image : Configuring Basic Settings : After entering the browser 's address and the access point 's name in this section , the following page appears : Cisco was the username and password.After that , we logged in . Following our sign-in , the following page—dubbed the `` Summary Status page '' —was displayed . The summary status ( Association , Network Identity , Network Interface , and Event Log ) is available on this page . On the left side of it is a tiny menu as well . Next , we clicked on the Express Setup button to access the Express Setup page , where we modified the host name to AP-8 as shown in the following image : Setting up Security Configuration : The following screen shows up once we 've navigated to the Express Security page : We configured the setting as shown in the picture : This screen appears after applying the express security settings : Radio Interface Enabling : We selected 802.11G from the Summary Status page . The radio 802.11G home page appears . Then , we turned on 802.11G from the settings : Then clicked apply . Then we did the same steps for 802.11A . Network interfaces in the home page after enabling the radio 802.11G and 802.11A . Setting Up Wireless Settings : We saw that the wireless network connection list included the AP.8.It requested the Security key ( 123456 ) when we joined . Then we pinged between the PCs . Finally , we selected System Configuration from System Software and saved it by clicking on config.txt . If we ever needed to use it again , we saved it . Part 3 : Configuring an Ad Hoc Mode WLAN with Windows 7 . We did the configuration by following these steps : We set up the Ad Hoc network by give it the name ( Adhoc_lab_8 ) , security type ( WEP ) , security key ( Net123456 ) . Then we save the network . Then , we noticed that the ( Adhoc_lab_8 ) was shown in the wireless network connection list , and we connected to it from the two PC ’ s . We made a folder on the PC1 , then shared it with PC2 as we learned in the lab before , when we opened the folder on PC2 , we wrote on it , and we saw the folder after update it on PC1 , and everything was right . Conclusion : In this experiment we learned how to install and set up a wide area network ( WAN ) , and how to configure the access point and create a WLAN that any station can connect to it , also we know how to build the WLAN in both modes the infrastructure and the adhoc mode , in addition to the difference between these 2 modes and there pros and cons , we also get to know how to transmit the files using a wireless connection . Objectives : To get familiar with the routing algorithms such as DSDV protocol . To get familiar with the wireless networks and its types . To get familiar with the adhoc wireless network . Introduction : The experiment focuses on exploring routing protocols within wireless ad hoc networks , particularly emphasizing the performance evaluation of the Destination- Sequenced Distance-Vector ( DSDV ) protocol . It distinguishes between infrastructured networks , which rely on access points for communication and face challenges with mobility , and ad hoc networks , which facilitate direct peer-to-peer communication among devices without centralized infrastructure . Within ad hoc networks , routing protocols are categorized as proactive ( table-driven ) or reactive ( on-demand ) , with examples including DSDV , Dynamic Source Routing ( DSR ) , Ad Hoc On-Demand Distance Vector Routing ( AODV ) , and Temporally Ordered Routing Algorithm ( TORA ) . The experiment aims to provide practical insights into these protocols ' functionality and performance . Using simulation tools like Ns2 and Nam on Ubuntu 14.04 , students create network topologies , script simulation scenarios , and analyze trace files to extract performance metrics . These metrics include packet transmission , routing efficiency , and network behavior under varying conditions . Through experimentation and analysis , students gain a deeper understanding of wireless network dynamics , routing protocols , and performance evaluation methodologies . The experiment also highlights challenges inherent in wireless routing , particularly in dynamic environments characterized by mobility . It encourages students to consider alternative metrics , such as Average End-to-End packet delivery time , and leverage visualization tools like Nam for deeper insights into network behavior . Overall , the experiment offers a comprehensive exploration of routing protocols in wireless ad hoc networks , providing valuable insights into their operation and performance evaluation . Tools : Ubuntu 14.04 ( O.S . ) Ns2 ( application ) Nam ( application ) Xgraph ( application ) Procedure : Part1 : Simple Network Topology In the initial phase of our experiment , we were tasked with simulating a basic network setup featuring a Drop Tail queue . This involved initiating the process by compiling the primary file , known as ns-simple.tcl . Once compiled , this file yields an output in the form of a NAM file . NAM files are typically employed for modeling groundwater flows , but in our context , they serve as essential data repositories for our network simulation . Additionally , as part of the setup process , we launch Xgraph , a visualization tool . Xgraph provides graphical representation of the simulation , displaying various metrics and behaviors of the nodes within the network . Before commencing the actual simulation , it 's crucial to make necessary adjustments to the code within ( ns- simple.tcl ) . These modifications ensure that the network topology aligns with our experimental requirements , laying the groundwork for an accurate and meaningful simulation . For further clarification , refer to the accompanying images illustrating the network configuration and simulation setup . And here are the modified code to match the required network , see the following picture : And now for the code 's compilation result . As you can see in the following image , node 0 will begin transmitting data after 1.2 seconds based on TCP configuration , and data will also be lost after a certain amount of time because node 3 has reached its maximum . Node 0 and node 1 begin sending data to node 2 at the start of the simulation . Then we were asked to get the dropped and received packets in the simulated network , see the following results : Part2 : Three node ad hoc with DSDV We begin by generating the simple-dsdv.tcl file , which will include the adhoc network configuration , as we were instructed to establish three Wi-Fi nodes using the adhoc configuration mode in addition to the DSDV protocol . The written code is then compiled using the terminal , producing a file with the .tr extension . Following that , we discover both sent and received packets ; the ensuing image illustrates this . So we can the packet delivery fraction by dividing the received on the sent packets , so 5204 / 5225 which equal to 0.995 . Then after that we found the total number of routing packet sent , see the following picture : So we can figure out the routing load fraction which equal the routing packets dividing on the received packets , so it will equal to 41/5204 which equal to 0.0078 . Conclusion : In conclusion , this experiment has provided valuable insights into the distinction between ad hoc and infrastructure configuration modes , along with an understanding of various routing protocols and their practical application within specific network environments . Furthermore , we have acquired essential skills in network simulation using NS2 and NAM , supplemented by visualization through Xgraph . Overall , this hands-on experience has enriched our comprehension of wireless networking concepts and simulation techniques , laying a solid foundation for further exploration and study in this field .",
    "ilovepdf_merged (2).txt": "Digital Electronic Circuits © Dr. Samer Arandi - An-Najah National University Dr. Samer Arandi Course Outline © Dr. Samer Arandi - An-Najah National University Bipolar Families : RTL , DTL , TTL , ECL and I2L NMOS Transistor Analysis CMOS Inverters and gates CMOS Fabrication OP-AMPs Sensors and Transducers ( optical and ultrasonic ) Driver Circuits ( motors , relays , Triacs , Diacs ) Digital to Analogue and Analogue to Digital Regulated Power Supplies Introduction © Dr. Samer Arandi - An-Najah National University Integrated Circuits ( IC ) : arbitrary number of interconnected gates in a silicon semiconductor crystal ( chip ) Contains electronic components for constructing digital gates Mounted in a ceramic or plastic container that exposes a number of pins ( tens to thousands ) Complexity is measured by the number of logic gates in a single chip Levels of Integration © Dr. Samer Arandi - An-Najah National University Small scale Integration ( SSI ) : typically fewer than 10 independent gates – early 60s Medium Scale Integration ( MSI ) : 10 to 1000 of gates ( decoders , adders , multiplexers ) – late 60s Large Scale Integration ( LSI ) : thousands of gates ( 1st and 2nd generation processors , memory chips , PLD ) – mid 70s Very Large Scale Integration ( VLSI/ULSI ) : hundreds of thousands of gates to several billions ( complex microcomputers chips ) – 80s till present System-on-a-Chip ( SoC ) : all components needed by a computer is included on a single chip . – Lower manufacturing cost and reduced power budget . Why ? 3 Dimensional Integrated Circuits ( 3D-ICs ) : two or more layers of components integrated both vertically and horizontally . Reduced power budget and overall wire length Digital Logic Families © Dr. Samer Arandi - An-Najah National University The basic circuit in each technology/family is a NAND , NOR or INVERTER . Many families have been introduced : Bipolar Transistors ( flow of two carriers ) RTL : Resistor-Transistor Logic DTL : Diode-Transistor Logic TTL : Transistor-Transistor Logic ECL : Emitter-Coupled Logic I2L : Integrated Injection Logic Unipolar Transistors ( Field Effect Transistors ) MOS : Metal-Oxide Semiconductor – high density CMOS : Complementary MOS – lower power consumption , dominant family , used in VLSI Logic Family Characterization © Dr. Samer Arandi - An-Najah National University Fan-Out Power Dissipation Propagation Delay Noise Margin The Standard TTL series Characteristics 1964 TI introduced first line of standard TTL IC ’ s . 54/74 series one of the most widely used series known as the 74 series ( 54 wider temperature range ) Many semiconductor IC manufactures produce TTL IC ’ s Fortunately all use the same numbering system allowing interchanging of components © Dr. Samer Arandi - An-Najah National University SN74 DM74 S74 Texas Instruments 74 Series National Semiconductor 74 Series Signetics 74 Series The Standard TTL series Characteristics Several other TTL series have been developed since the introduction of the 74 standard series . 74LS , 74S etc . Provide a wide choice of speed and power characteristics Speed Power ( picoJoules ) : the lower the better Differences in TTL family are not in Logic Levels , but in internal construction of the basic NAND gate . © Dr. Samer Arandi - An-Najah National University The Standard TTL series Characteristics The propagation delay of a transistor which goes into saturation depends on two factors : Saturation delay ( storage time delay ) RC time constant By reducing resistor values reduces RC time constant decreases propagation delay Trade-off is high power dissipation lower resistance draws more current from power supply © Dr. Samer Arandi - An-Najah National University Low Power , 74L series © Dr. Samer Arandi - An-Najah National University Similar to a standard TTL But all resistor values have been increased . good for applications with low frequency , battery operated circuits – calculators etc . High Speed , 74H series © Dr. Samer Arandi - An-Najah National University Similar to a standard TTL But all resistor values have been reduced .  faster switching  propagation delay 6 nseconds but  increased power dissipation 22 mW How to increase speed ? © Dr. Samer Arandi - An-Najah National University Whatever is done to the value of the resistors Speed is ultimately limited by the time required to pull the output transistors out of saturation . 74 , 74L and 74H series all operate with saturated switching many of the transistors , when conducting will be in a saturated condition As has been seen this causes a saturation delay ( storage delay ) , when switching from ON to OFF limits the circuit ’ s switching speed . Schottky TTL , 74S series © Dr. Samer Arandi - An-Najah National University Can this be improved ? In Schottky TTL ( STTL ) Transistors kept out of saturation by using Schottky barrier diodes ( SD ) Formed by a junction of a metal and semiconductor conventional diode with a junction of p-type and n-type semiconductor material SD connected between the base and the collector Do not allow the transistors to go as deeply into saturation SD has a forward voltage drop of 0.4V = Schottky TTL , 74S series © Dr. Samer Arandi - An-Najah National University When the Collector-Base junction becomes forward biased at the on-set of saturation  SD will conduct , diverting some input current away from base .  this has effect of reducing the excess base current .  decreases saturation ( storage time ) delay at turn-off 74S00 NAND has average propagation delay of 3 nsecs twice as fast as the 74H00 makes the 74H series redundant nowadays Schottky TTL , 74S series © Dr. Samer Arandi - An-Najah National University Circuit also uses smaller resistor values to improve switching times Improves the circuit average power dissipation to 20 mW NOTE All transistor are Schottky Transistors . Q4 is not required to be a Schottky , why ? Schottky TTL , 74S series Output A B C Q 1 370 Q 2 Q3 Q5 Q4 Q6 350 3.5k +5 V 55 2.8k 760 © Dr. Samer Arandi - An-Najah National University Low Power Schottky TTL , 74LS series © Dr. Samer Arandi - An-Najah National University 74 LS is a low powered version of the 74S series uses with larger resistor values than 74S Low circuit power requirements but at the expense of increase in switching times . Power Dissipation Propagation Delay 2 mW 9.5 nseconds This is the mainstay of the TTL family Found in nearly all new designs that do not require max speed . Advanced Schottky TTL , 74AS series © Dr. Samer Arandi - An-Najah National University As a result of the recent development in IC design and manufacturing process – High speed Schottky diodes Power Dissipation Propagation Delay 10 mW 1.5 nseconds Advanced Low-Power Schottky TTL , 74ALS series © Dr. Samer Arandi - An-Najah National University Improvement in both power and speed . Power Dissipation Propagation Delay 1 mW 4 nseconds This series has the lowest speed-power product of the TTL series very close to the lowest gate power dissipation This will eventually replace 74LS as the most widely used TTL series . Emitter Coupled Logic © Dr. Samer Arandi - An-Najah National University Non-saturated digital logic family Since transistors do not saturate , it is possible to achieve a prop . delay of 1-2 ns ( fastest family ) Utilized in systems that require very high speed Power dissipation and noise immunity is the worst ! Power dissipation 25 mw © Dr. Samer Arandi - An-Najah National University Emitter Coupled Logic ( ECL ) Emitter Coupled Logic ( ECL ) © Dr. Samer Arandi - An-Najah National University A B VEE=-5.2 V 220 Ω 245 Ω 50 KΩ 50 KΩ GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -0.8 V High -1.8 V Low VBB=-1.3V VBB : bias voltage , mid-point of the logic swing Emitter Follower Output Differential Input amplifier © Dr. Samer Arandi - An-Najah National University Use of VCC as ground and VEE at -5.2 V results in best noise immunity ECL - Simplified 220 Ω A B VEE=-5.2 V © Dr. Samer Arandi - An-Najah National University 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -0.8 V High -1.8 V Low ECL - Simplified 220 Ω A = High ( -0.8 ) B VEE=-5.2 V © Dr. Samer Arandi - An-Najah National University 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -0.8 V High -1.8 V Low ECL - Simplified 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR NOR Q1 Q2 Q5 Q7 Q8 -1.6 V 779 Ω -0.8 V High -1.8 V Low A = High ( -0.8 ) B VEE=-5.2 V © Dr. Samer Arandi - An-Najah National University ECL - Simplified ON 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -1.6 V Difference between VBB & VE is 0.3 V only Q5 is cut-off A = High ( -0.8 ) B VEE=-5.2 V © Dr. Samer Arandi - An-Najah National University -0.8 V High -1.8 V Low ECL - Simplified 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -1.6 V Difference between VBB & VE is 0.3 V only Q5 is cut-off A = High ( -0.8 ) B VEE=-5.2 V © Dr. Samer Arandi - An-Najah National University -0.8 V -0.8 V High -1.8 V Low ECL - Simplified 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q8 -1.6 V Difference between VBB & VE is 0.3 V only Q5 is cut-off A = High ( -0.8 ) B VEE=-5.2 V © Dr. Samer Arandi - An-Najah National University -0.8 V 1.0 V Q7 NOR -1.8 V -0.8 V High -1.8 V Low ECL - Simplified ( -1.6 - -5.2 ) * 220/779 A © Dr. Samer Arandi - An-Najah National University B VEE=-5.2 V 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -0.8 V High -1.8 V Low ECL - Simplified 220 Ω A B VEE=-5.2 V = Low ( -1.8 ) = Low ( -1.8 ) © Dr. Samer Arandi - An-Najah National University 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR 779 Ω Q1 Q2 Q5 Q7 NOR Q8 -0.8 V High -1.8 V Low ECL - Simplified 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR NOR Q1 Q2 Q5 Q7 Q8 -2.1 V 779 Ω cut-off A B VEE=-5.2 V = Low ( -1.8 ) = Low ( -1.8 ) © Dr. Samer Arandi - An-Najah National University cut-off -0.8 V High -1.8 V Low ECL - Simplified 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND OR NOR Q1 Q2 Q5 Q7 Q8 -2.1 V 779 Ω cut-off A B VEE=-5.2 V = Low ( -1.8 ) = Low ( -1.8 ) © Dr. Samer Arandi - An-Najah National University cut-off 1.0 V -1.8 V -0.8 V High -1.8 V Low GND ( -2.1 - -5.2 ) * 245 / 779 ECL - Simplified 220 Ω 245 Ω 50 KΩ 50 KΩ VBB=-1.3V GND GND OR NOR -0.8 V Q2 Q5 Q7 Q8 -2.1 V 779 Ω cut-off A B VEE=-5.2 V = Low ( -1.8 ) = Low ( -1.8 ) © Dr. Samer Arandi - An-Najah National University cut-off Q1 1.0 V -1.8 V -0.8 V High -1.8 V Low ECL - Simplified Integrated Injection Logic © Dr. Samer Arandi - An-Najah National University Integrated Injection Logic ( I2L ) © Dr. Samer Arandi - An-Najah National University Saturated bipolar logic family Utilized in MSI and LSI Small size Low power consumption Cheaper fabrication cost Merges transistor components - Merged Transistor Logic ( MTL ) One semi-conductor region is part of two or more devices . This allows considerable saving in silicon chip area . Integrated Injection Logic ( I2L ) © Dr. Samer Arandi - An-Najah National University A single inverter is implemented as : Multi-collector npn transistor Multi-collector pnp transistor that is driving the npn transistor . The emitter of the driving transistor is called the injector Integrated Injection Logic ( I2L ) © Dr. Samer Arandi - An-Najah National University The injector distributes current to multiple units which form its multi-collectors . Open-collector output which allows a wired-and configuration ( typically followed by an inverter ) Integrated Injection Logic ( I2L ) The collector of the current injector transistor and the base of each multiple collector transistor are merged , i.e . one p region is used for both The base of the injector transistor is merged with the emitter of the multiple collector transistor . © Dr. Samer Arandi - An-Najah National University Metal Oxide Semiconductor © Dr. Samer Arandi - An-Najah National University Metal Oxide Semiconductor © Dr. Samer Arandi - An-Najah National University Field Effect Transistor ( FET ) : unipolar transistor as its operation depends on the flow of one type of carriers Two types of FETs : Junction Field Effect Transistor ( JFET ) – used mainly in linear circuits Metal-Oxide Semi-conductor FET ( MOSFET ) – used in digital circuits Advantage : fabricated in less area than Bipolar Transistors MOS Transistors p-channel n-type substrate ( lightly doped ) Two heavily doped regions with p-type impurities ( source and drain ) The region between the source and drain is called the channel The gate is the metal plate separated from the substrate by an insulated dielectric of silicon dioxide A negative voltage at the gate = > induced electric field at the channel = > attracts p-type carriers ( holes ) = > conductivity increases = > current flows from source to drain © Dr. Samer Arandi - An-Najah National University MOS Transistors © Dr. Samer Arandi - An-Najah National University Two modes of operation ( depends on the state of the channel at zero voltage ) : – Depletion channel is initially doped with p-type impurities , i.e . a conducting channel exists at 0 V Enhancement region beneath the gate is initially uncharged a voltage must be applied to the gate to induced a channel i.e . current is enhanced by gate voltage MOS Transistors © Dr. Samer Arandi - An-Najah National University The majority carriers enter the device from the source terminal to the drain when the voltage applied to the gate exceeds a threshold VT p-channel The source is connected to the substrate and a negative voltage is applied to the drain When the gate voltage is sufficiently negative below VT p-type carriers flow from S to D ( positive current flow ) n-channel The source is connected to the substrate and a positive voltage is applied to the drain When the gate voltage is sufficiently positive above VT n-type carriers flow from S to D ( equivalent to positive current flow from D to S ) MOS Transistors Symbols for MOS Transistors © Dr. Samer Arandi - An-Najah National University Enhancement Mode © Dr. Samer Arandi - An-Najah National University MOS – Logic Gates RQ1 : Load Resistor RQ2 < < RQ1 MOSFET can be used as resistor as well as a transistor Resistance value can be determined as the ratio between VDS and IDS Different resistor values may be constructed during manufacturing by fixing the channel length and width of the MOS device © Dr. Samer Arandi - An-Najah National University MOS – Logic Gates RQ2+RQ3 < < RQ1 Q1 Q2 Q3 © Dr. Samer Arandi - An-Najah National U niversity Complementary MOS s d d s Takes advantage of the ability to fabricate both n-type and p-type on the same substrate Basic circuit is the inverter : – The n-MOS conducts when gate-to-source is pos+ The p-MOS conducts when gate-to-source is neg- Both are turned off when gate-to-source is zero CMOS – Logic Gates © Dr. Samer Arandi - An-Najah National University CMOS – Models/Symbols © Dr. Samer Arandi - An-Najah National University MOS Operation and Analysis © Dr. Samer Arandi - An-Najah National University L : channel length ( 350nm – 90nm ~ 2004 ) W : channel width tox : gate oxide thickness ( < 25 Å ~2004 ) bulk ( substrate ) : doping density xj : junction depth ( 150 – 70 nm ~2004 ) © Dr. Samer Arandi - An-Najah National University Determine the electrical Characteristics of the transistor MOS Threshold Voltage © Dr. Samer Arandi - An-Najah National University Threshold Voltage ( VT ) : the minimum gate voltage needed to initiate the forming of a conducting channel VT mainly depends on the material properties - largely determined at the time of fabrication The most important factors affecting VT include : The gate conductor material ( poly vs. metal ) The gate insulation material ( SiO2 ) Impurities in the oxide The thickness of the gate material The channel doping concentration VT is also depends on : Temperature : changes by -2mV/degree C for low substrate doping levels Source-Bulk voltage VSB As VGS moves from 0 to a positive value : positive charge accumulates on the gate negative charge ( electrons ) accumulates in the substrate under the gate The mobile holes are pushed down creating a depletion layer ( contains the immobile negative charge ) As the voltage increases the depletion layer thickness increases and a layer of mobile electrons appear ( weak inversion condition ) Further increase in the voltage increases the concentration of the electrons until its equal to the concentration of the holes ( strong inversion condition ) © Dr. Samer Arandi - An-Najah National University For gate voltage above this point : The depletion layer thickness remains approximately constant Additional mobile carriers accumulate in the channel ( drawn from S & D ) Application of VDS > 0 causes current to flow in the channel The value of the VGS required to produce strong inversion is called the threshold voltage © Dr. Samer Arandi - An-Najah National University Threshold Voltage Components © Dr. Samer Arandi - An-Najah National University VT has three main components : ΦGC : difference in work function between the gate material ( G ) and the silicon substrate on the channel side ( C ) undesirable positive charge Qox due to imperfections in the semi-oxide interface doping voltage required to change the surface potential to the strong inversion condition and to offset the induced depletion layer charge QB VT = ΦGC – Qox/Cox – 2ΦF – QB/Cox At VSB = 0 , VT and QB are denoted as VT0 and QB0 VT0 = ΦGC – Qox/Cox – 2ΦF – QB0/Cox VFB ni K : intrinsic ( non-doped carrier concentration ) depends on temperature ( 1.45x1010 cm-3 ) NA : carriers density in doped semi-conductor for p-type material ( ND for n-type ) : Boltzman constant , T : temperature , q : electron charge F Φ = k * t ln ni q NA Thermal voltage = 26mV © Dr. Samer Arandi - An-Najah National University VFB : flat band voltage ΦF : equilibrium electrostatic potential ( the shift in Fermi level due to doping ) |2ΦF| : band bending voltage tox ox ox C = QB0 =  2q * Si * NA * | 2F| Q B0 = q * NA * Xd VSB q : electronic charge ( 1.6x10-19 ) Xd : depletion layer width εSi : permittivity of silicon ( 1.06x10-12 ) for p-type material ( ND for n-type ) : Source-Bulk voltage ( typically zero ) Cox εox tox : gate-oxide capacitance : permittivity of oxide : oxide thickness q * NA © Dr. Samer Arandi - An-Najah National University 2 * Si * | 2F | Xd = Signs © Dr. Samer Arandi - An-Najah National University VFB is negative in nMOS , positive in pMOS ΦF is negative in nMOS , positive in pMOS QB0 and QB are negative in nNMOS , positive in pMOS VSB is positive in nMOS , negative in pMOS Current-Voltage Characteristics MOS has three modes of operation : VGS < VT ( IDS is zero ) Cut-off Linear Saturation The mode depends on the terminal voltages : VGS VDS VGS > V © Dr. Samer Arandi - An-Najah National University T , VDS > 0 ( IDS is non-zero ) Linear Mode At VDS = 0 , the inverted channel is in equilibrium and IDS = 0 If a small VDS > 0 is applied , IDS will flow from S to D , such that IDS is proportional to VDS The transistor ( the channel ) acts as a voltage controlled resistor © Dr. Samer Arandi - An-Najah National University © Dr. Samer Arandi - An-Najah National University Linear Mode [ 2 ( V GS VT ) VDS VDS ] 2 IDS  K 2 IDS depends on both VGS and VDS L K  K ' W K '  n * Cox  nox tox µn : carrier mobility Saturation Mode © Dr. Samer Arandi - An-Najah National University As the drain voltage is increased the inversion layer charge and the channel depth at the drain decreases At VDS = VGS-VT0 ( called VDSAT ) the channel inversion charge at the drain becomes zero ( pinch-off point ) As VDS > VDSAT the inversion layer near the drain vanishes - > channel length decreases Saturation Mode Pinch-off point 2 IDS  K ( VGS VT ) 2 IDS  K ( VGS VT ) 2 ( 1  * VDS ) © Dr. Samer Arandi - An-Najah National University 2 ( account for channel modulation ) λ : channel length modulation coefficient Saturation Mode © Dr. Samer Arandi - An-Najah National University Practical Considerations © Dr. Samer Arandi - An-Najah National University The I-V characteristics discussed so far neglect many effects that are important in modern fabrication processes : Velocity Saturation We assumed that carrier drift velocity and hence current increase linearly with the electric field between source and drain . This is only true for weak electric fields , at high electric fields and short channel lengths carrier drift velocity saturates ( saturation occurs when carriers reach saturation velocity ) Thus , saturation current is linearly dependent on voltage rather than quadratically dependent Practical Considerations ( cont . ) © Dr. Samer Arandi - An-Najah National University Mobility Degradation Strong vertical electric fields resulting from large Vgs reduce carrier mobility μ. Sub-threshold conduction We assumed that no current flows from source to drain when Vgs < Vt . In reality this is not true and current drops off exponentially . This current is termed as leakage current Tunneling According to quantum mechanics , there is a finite probability that carriers will tunnel through the gate oxide . This results in gate leakage current flowing into the gate . Probability of tunneling drops off exponentially with oxide thickness , and so was negligible until recently . Practical Considerations ( cont . ) © Dr. Samer Arandi - An-Najah National University Junction leakage The p-n junctions between S & D and the substrate form diodes . The well to substrate junction is another diode . Although these diodes are reverse biased they still conduct a small amount of current Temperature Carrier mobility decreases with temperature The magnitude of the threshold voltage decreases nearly linearly with temperature Junction leakage increases with temperature because Is is strongly temperature dependent . Net effect : ON current decreases , OFF current increases , worse performance at high temperature Practical Considerations ( cont . ) © Dr. Samer Arandi - An-Najah National University Geometry Dependence Layout designers draw transistors with some width and length , Wdrawn and Ldrawn . The actual dimensions may differ , due to Polysilicon over-stretching Effective dimensions should be used rather than drawn dimensions for analysis or values can be significantly off . Below 0.25μm , transistor orientation and amount of nearby poly affect the effective length MOS Capacitance © Dr. Samer Arandi - An-Najah National University The switching speed of MOS circuits is limited by the time required to charge/discharge the capacitances at the internal nodes The capacitances must be calculated from device dimensions and dielectric constants The values are usually specified in femto- Farads per µmeter of width ( fF/µm ) – CG vs. Cg Types of MOS Capacitance Thin-oxide Capacitance – Cg = > ( Cgs , Cgd , Cgb ) Junction capacitance - Csb and Cdb Overlap Capacitance – Col Depletion layer capacitance - under the channel - Cjc ( associated with Cgb ) Non-linear voltage-dependant linear voltage-independant © Dr. Samer Arandi - An-Najah National University © Dr. Samer Arandi - An-Najah National University Thin-Oxide Capacitance The most important capacitance in MOS The two plates of the capacitor are the gate and the channel The dielectric is the oxide between the two plates CG  W * Cg Cg  Cox * L  ox * L tox © Dr. Samer Arandi - An-Najah National University Thin-Oxide Capacitance Calculations © Dr. Samer Arandi - An-Najah National University In 5 µm technology ( L=5 µm ) , tox = 1100 Å Cg = Cox * L = ( ( 4 * 8.85x10-14 ) /110 ) * 5 µm = 1.6 fF/µm In 0.35 µm technology ( L=0.35 µm ) , tox = 75 Å Cg = Cox * L = ( ( 4 * 8.85x10-14 ) /75 ) * 0.35 µm = 1.6 fF/µm In 0.13 µm technology ( L=0.1 µm ) , tox = 22 Å Cg = Cox * L = ( ( 4 * 8.85x10-14 ) /22 ) * 0.1 µm = 1.6 fF/µm The factor remained constant for over 25 years – Both L and tox are scaled at the same rate and so their effects cancel each other Thin-Oxide Capacitance © Dr. Samer Arandi - An-Najah National University The gate capacitance is decomposed into three capacitances : Cgs : gate-to-source capacitance Cgd : gate-to-drain capacitance Cgb : gate-to-bulk capacitance The composition vary depending on whether the device is in cut-off , linear or saturation states Thin-Oxide Capacitance © Dr. Samer Arandi - An-Najah National University * assuming a VGS = 0 ( in the cut-off region Cgb is in series with the depletion capacitance Cjc ) Junction Capacitance © Dr. Samer Arandi - An-Najah National University The S and D regions and the substrate forms pn junctions that give rise to two additional capacitances - Csb and Cdb In addition , a junction capacitance is formed between the inverted channel and the substrate – Cjc This capacitance depends on the terminal voltage Junction Capacitance B  k * T ln NA * ND q ni 2 si * q * NA 2 * B ( 2 * B ) ( si * q ) * NA * ND  NA  ND Cj0  Cj0 * A © Dr. Samer Arandi - An-Najah National University ( 1 CJ  CJ : junction capacitance Cj0 : zero-bias junction capacitance ( fF/cm2 ) A : area of the junction = W * ( xj+Y ) m : the junction grading coefficient ( approx . 1/2 for abrupt junctions ) ΦB : built-in junction potential VJ ) m B Junction Capacitance Since the terminal voltages change during dynamic operation we need to calculate the capacitance under such transient conditions We approximate this capacitance by finding the large-signal average junction capacitance * : CJ  Keq * Cj0 * A * ( B V 2  B V1 ) © Dr. Samer Arandi - An-Najah National University V 2 V1 Keq   2 * B Keq : dimensionless coefficient * calculated for a transition between two known voltages , V1 and V2 © Dr. Samer Arandi - An-Najah National Unive rsity Overlap Capacitance Voltage-independent capacitance that exists on both sides of the gate Composed of two components : diffusion capacitance between the gate and the diffusion extensions of the source and drain - Cov fringing capacitance between sidewall of the poly-silicon and surface of drain and source - Cf Col = Cov + Cf Overlap Capacitance Cf  2ox ln ( 1 Tpoly ) © Dr. Samer Arandi - An-Najah National University tox  Cov  Cox * LD Col  Cov  Cf MOS Inverter Static Characteristics © Dr. Samer Arandi - An-Najah National University Voltage Transfer Characteristics © Dr. Samer Arandi - An-Najah National University DC Voltage Transfer Characteristics in Vout Gain = V In an ideal implementation of an inverter , the two binary levels are ground and VDD . The output transition between the 1 and 0 states occurs when the input is exactly VDD/2 . © Dr. Samer Arandi - An-Najah National University Voltage Transfer Characteristics Range : voltage interval over which a signal is considered to be logic 0 or logic 1 . For an ideal inverter : -The input range is very large -The output range is small This is desirable as it implies : the input can vary significantly with little or no effect on the output ( the gate rejects noise at the input ) Practical VTC © Dr. Samer Arandi - An-Najah National University VOL may not reach GND VOH may not reach VDD Vout doesn ’ t switch from VDD to GND at VDD/2 Vs : point where Vout = Vin instead of 3 regions ( 0 gain , infinite gain , 0 gain ) we have ( low gain , high gain , low gain ) h National University Practical VTC © Dr. Samer Arandi - An-Naja The input ranges that define 0 and 1 are smaller than the ideal case 0 to VIL VIH to VDD The two output ranges are larger than the ideal case VOL to VOUL VOUH to VOH © Dr. Samer Arandi - An-Najah National University Noise When the input range is larger than the output range , the gate retains the noise rejection property i.e . output fluctuation are small even with large input fluctuation This attenuates the noise when multiple gates are connected successively Noise Margin Definitions © Dr. Samer Arandi - An-Najah National University If the noise amplitude at the input of any logic circuit is smaller than the noise margin of the circuit the noise will be attenuated Noise may be transferred to logic nodes or interconnecting lines by : Unwanted capacitive or inductive coupling Series inductance and resistance in the shared ground and power supply lines The robustness of a gate depends on : How much noise can be applied before the gate fails ( gate properties ) How much noise actually couples into the gate ( environ . ) Noise Margins © Dr. Samer Arandi - An-Najah National University The noise margin specifies the range over which the circuit will function properly . Noise margin metrics : single-source noise margin ( SSNM ) : assumes a single noise source affecting one logic node ( not realistic ) multiple-source noise margin ( MSNM ) : assumes multiple noise sources potentially affecting all nodes ( more realistic ) Noise Margins ( cont . ) System with single-stage noise of magnitude Vn System with multi-stage noise © Dr. Samer Arandi - An-Najah National University Noiseless System Noise Margins ( cont . ) © Dr. Samer Arandi - An-Najah National University For a noiseless system : Vout = f ( Vin ) When adding noise Vn the output : Vout = f ( Vin+Vn ) Can be eventually simplified into : Vout = Noiseless_Output + noise * gain This implies that if the inverter is operating in the region where : The gain > 1 , noise is amplified ( undesired ) The gain < 1 , noise is attenuated ( desired ) Noise Margins ( cont . ) © Dr. Samer Arandi - An-Najah National University We can define the noise margins by using the VTC points where the gain is 1 to establish the transition points of the range Noise Margins ( cont . ) © Dr. Samer Arandi - An-Najah National University NMH = VOH - VIH NML = VIL - VOL Vin  Vout Inverter Noise Margins ( cont . ) © Dr. Samer Arandi - An-Najah National University NMH = VOH - VIH NML = VIL - VOL Buffer Resistive-Load NMOS Inverter Vin = VGS Vout = VDS VSB = 0 VT = VT0 © Dr. Samer Arandi - An-Najah National University Since IG is negligible IR = ID To calculate the noise margins we find the five critical points on the VTC : VOH , VOL , VIH , VIL and Vs © Dr. Samer Arandi - An-Najah National University VTC Calculating VOH © Dr. Samer Arandi - An-Najah National University To calculate VOH we set the input voltage below VT Therefore , no current flows And so : VOH = VDD Calculating VOL When a logic 1 is applied at the gate input ( represented by VOH of a previous gate ) the transistor is driven into the linear region . This implies : IR = IDS ( linear ) VDD VOL RL 2 © Dr. Samer Arandi - An-Najah National University  [ 2 ( V K T ) VOL VOL ] OH V 2 Calculating VOL To make VOL small : increase k ( i.e . W/L ) [ increase area , faster fall- time ] increase RL [ increase area , slower rise-time ] Decreasing VOL increases the power marginally , however increasing RL reduces power VDD 1 k * RL ( VDD VT ) VOL  RL © Dr. Samer Arandi - An-Najah National University P  I * V  ( VDD VOL ) * VDD Calculating VIL At Vin = VIL the output voltage is near VDD and the transistor is operating in the saturation region . This implies : IR = IDS ( saturation ) VDD VOut  k ( VIL VT ) 2 RL 2 © Dr. Samer Arandi - An-Najah National University Calculating VIL To increase VIL : Decrease k and RL . However , this increases VOL which is not desirable Both VIL and VOL shift in the same direction and so it 's difficult to affect the NML significantly 1 k * RL VIL  VT  © Dr. Samer Arandi - An-Najah National University Calculating VIH When Vin=VIH the output voltage is near 0 and the transistor is operating in the linear region IR = IDS ( linear ) Following a similar procedure we end-up with : k * RL © Dr. Samer Arandi - An-Najah National University 3 * k * RL 8 * VDD VIH  VT  1  Calculating VIH To decrease VIH we can increase kRL , however , this increases the rising delay and increases the power slightly Changes in k and RL have no effect on VOH so its possible to increase NMH 8 * VDD 1 3 * k * RL k * RL  VIH  VT  © Dr. Samer Arandi - An-Najah National University NMOS as Load Devices © Dr. Samer Arandi - An-Najah National University The resistor load ( RL ) requires large amount of chip area if realized in a standard MOS process The area would be more than 100 times that of a transistor ! It would also result in a large Rise Time Consequently resistors are rarely used as loads in MOS digital circuits Instead an NMOS transistor is used to perform the function of a pull-up resistor . Saturated Enhancement Load Inverter © Dr. Samer Arandi - An-Najah National University Pull-up transistor Pull-down transistor G of the pull-up is connected to VDD The transistor is working in the saturation mode or cut-off mode The relative sizes of the two transistors determine the output voltages ( must ensure VOL is < VT ) Saturated Enhancement Load Inverter © Dr. Samer Arandi - An-Najah National University Pull-up transistor Pull-down transistor Advantages : Single power supply Simple Fabrication Disadvantages : VOH is limited to VDD - VTL Linear Enhancement Load Inverter © Dr. Samer Arandi - An-Najah National University G of the pull-up is connected to VGG such that VGG > VDD + VTL The transistor is working in the linear mode for all the range of VOH VOH can reach to VDD Linear Enhancement Load Inverter © Dr. Samer Arandi - An-Najah National University Advantages : - VOH can reach to VDD Disadvantage : -The extra voltage source is associated with additional interconnections ( more chip area ) - DC power dissipation in the output low state Solution ? Depletion Load Inverter Better noise margins Single power supply Smaller overall layer More complicated fabrication process CMOS Inverter Steady-state power dissipation negligible ( only due to leakage currents ) VTC Transition is very sharp ( close to an ideal inverter ) © Dr. Samer Arandi - An-Najah National University CMOS Inverter © Dr. Samer Arandi - An-Najah National University Vin is at VDD : the NMOS device is conducting while the PMOS ( VGS=0 ) is cut-off and so VOUT is 0 and IDN is almost zero . Vin is at GND , the NMOS is cut-off while the PMOS is conducting and so Vout is equal to VDD and IDN is almost zero . VOH = VDD VOL = 0 large noise margins VTC 5 regions © Dr. Samer Arandi - An-Najah National University VTC © Dr. Samer Arandi - An-Najah National University VTC Symmetry A completely symmetrical VTC is obtained if VTP = - VTN and kP = kN Vs  VDD | VTP | VTN 1  WP © Dr. Samer Arandi - An-Najah National University WN nWN pWP   ECP * LP ECN * LN  © Dr. Samer Arandi - An-Najah National University CMOS Inverter Timing tpHL ( propagation delay high to low ) : time delay between V50 % transition of the rising input voltage and the V50 % transition of the falling output voltage . tpLH ( propagation delay low to low ) : time delay between V50 % transition of the falling input voltage and the V50 % transition of the rising output voltage . Propagation time delay ( tP ) tP  tPHL  tPLH 2 CMOS Inverter Timing occurs at = > t = 0.69 * Reff * CL We can model the inverter as an effective on- resistance ( Reff ) driving a load capacitance CL When the output is falling : Reff = RN Vout ( t )  VDD * e-t/RN * CL When the output is rising : Reff = RP Vout ( t )  VDD * ( 1 e-t/RP * CL ) In both cases the 50 % © Dr. Samer Arandi - An-Najah National University Effective On-Resistance Reff is inversely proportional to W/L The NMOS and PMOS have difference Reff . RN = Reqn * ( LN/WN ) RP = Reqp * ( LP/WP ) Reqn is defined in units of L/W © Dr. Samer Arandi - An-Najah National University Load Capacitance ( CL ) CL accounts for ( is the sum of ) : the internal capacitance of the inverter the capacitance of the wiring – the capacitance of the fan-out extrinsic © Dr. Samer Arandi - An-Najah National University intrinsic Internal Capacitance Comprised of the Capacitances connected to the output ( D ) : Cdb1 and Cdb2 are the junction capacitance ( D-to-B ) Since we mostly work in cut-off and saturation Cgd12 ( gate capacitance ) is almost negligible except from the overlap capacitance © Dr. Samer Arandi - An-Najah National University Fan-out Capacitance The Fan-out capacitance is due to the input of subsequent gates . This capacitance can be large : the sum of each of the driven gate capacitances Each gate capacitance comprises : gate capacitance ( thin-oxide capacitance ) overlap capacitances © Dr. Samer Arandi - An-Najah National University Minimizing Propagation Delay © Dr. Samer Arandi - An-Najah National University Reducing CL Careful layout can reduce this capacitance . Increase W/L ratio of the transistors . Warning : doing so increases the intrinsic capacitance Increase VDD ( Req depends on VDD ) The delay of a gate can be modulated by modifying the supply voltage . This allows the designer to trade off energy dissipation for performance . However , rising above a certain level yields only a minor improvement . Also , reliability concerns ( oxide breakdown , hot-electron effects ) set firm upper bounds . Req vs. VDD © Dr. Samer Arandi - An-Najah National University © Dr. Samer Arandi - An-Najah National University 0.8 1 1.2 1.4 1.6 1.8 2 2.2 2.4 5.5 5 4.5 4 3.5 3 2.5 2 1.5 1 V DD ( V ) p t ( normalized ) tp vs. VDD CMOS Fabrication © Dr. Samer Arandi - An-Najah National University CMOS Technology depends on using both N-Type and P- Type devices on the same chip . The two main technologies to do this task are : P-Well The substrate is N-Type . The N-Channel device is built into a P- Type well within the parent N-Type substrate . The P-channel device is built directly on the substrate . N-Well The substrate is P-Type . The N-channel device is built directly on the substrate , while the P-channel device is built into a N- type well within the parent P-Type substrate . © Dr. Samer Arandi - An-Najah National University CMOS Fabrication Two more advanced technologies to do this task are becoming more popular for sub-micron geometries where device performance and density must be pushed beyond the limits of the conventional p & n-well CMOS processes . Twin Tub Both an N-Well and a P-Well are manufactured on a lightly doped N-type substrate . Silicon-on-Insulator ( SOI ) CMOS Process SOI allows the creation of independent , completely isolated nMOS and pMOS transistors virtually side-by-side on an insulating substrate . © Dr. Samer Arandi - An-Najah National University CMOS Requires that both n-channel ( nMOS ) and p- channel ( pMOS ) transistors be built on the same chip substrate . To accommodate both nMOS and pMOS devices , special regions must be created in which the semiconductor type is opposite to the substrate type . These regions are called wells or tubs . A p-well is created in an n-type substrate or , alternatively , an n- well is created in a p-type substrate . In the simple n-well CMOS fabrication technology , the nMOS transistor is created in the p-type substrate , and the pMOS transistor is created in the n-well , which is built-in into the p-type substrate . © Dr. Samer Arandi - An-Najah National University N- & P-Well Method N-Well Fabrication Process © Dr. Samer Arandi - An-Najah National University The creation of the n-well regions for pMOS transistors , by impurity implantation into the substrate . A thick oxide is grown in the regions surrounding the nMOS and pMOS active regions . The thin gate oxide is subsequently grown on the surface through thermal oxidation . The creation of n+ and p+ regions ( source , drain and channel- stop implants ) . The metallization is created ( creation of metal interconnects ) . Lithography © Dr. Samer Arandi - An-Najah National University Each processing step requires that certain areas are defined on chip by appropriate masks . Consequently , the integrated circuit may be viewed as a set of patterned layers of doped silicon , polysilicon , metal and insulating silicon dioxide . In general , a layer must be patterned before the next layer of material is applied on chip . The process used to transfer a pattern to a layer on the chip is called lithography . Thermal oxidation of the silicon surface : an oxide layer of about 1 micrometer thickness is created on the substrate , see ( b ) . The entire oxide surface is covered with a layer of photoresist , which is a light-sensitive , acid-resistant organic polymer , initially insoluble in the developing solution ( c ) . The photoresist material is exposed to ultraviolet ( UV ) light , the exposed areas become soluble so that the they are no longer resistant to etching solvents . To selectively expose the photoresist , we have to cover some of the areas on the surface with a mask during exposure . Thus , when the structure with the mask on top is exposed to UV light : areas which are covered by the opaque features on the mask are shielded . areas where the UV light strikes the photoresist , it is “ exposed ” and becomes soluble in certain solutes ( d ) . © Dr. Samer Arandi - An-Najah National University Basic Steps PhotoResist After the PR is applied , the wafer is heated ( ~160C ) to evaporate the solvent , leaving a smooth solid coating . The type of photoresist which is initially insoluble and becomes soluble after exposure to UV light is called positive photoresist . PhotoResist normally comes in powder form , which is insensitive to light . It is reconstituted into liquid form by adding a solvent , typically alcohol . The wafer is mounted on a turntable , spinning slowly , and the photoresist is discharged into its center . Centrifugal force spreads the resist outward across the wafer . The thickness that remains on the wafer is a function of the rate of wafer spin and the viscosity of the photoresist . The thickness is monitored by light diffraction , which is used to adjust the spin rate to reach the correct PR thickness . Phase Interference gives Photoresist Thickness © Dr. Samer Arandi - An-Najah National University Following the UV exposure step , the © Dr. Samer Arandi - An-Najah National University unexposed portions of the photoresist can be removed by a solvent . The silicon dioxide regions which are not covered by hardened photoresist can be etched away either by using a chemical solvent ( HF acid ) or by using a dry etch ( plasma etch ) process ( e ) . At the end of this step , we obtain an oxide window that reaches down to the silicon surface ( f ) . The remaining ( unexposed ) photoresist can be stripped from the silicon dioxide surface by using another solvent , leaving the patterned silicon dioxide feature on the surface , see ( g ) . The fabrication of semiconductor devices requires several such pattern transfers to be performed on silicon dioxide , polysilicon , and metal . The basic patterning process used in all fabrication steps , however , is quite similar to the one shown . Summary 9 steps to make this simple hole : Oxidize silicon surface Deposit photoresist Anneal photoresist Mount mask above silicon Expose to UV light Develop photoresist Etch photoresist exposed to UV Etch SiO2 through photoresist hole Remove photoresist © Dr. Samer Arandi - An-Najah National University Making a CMOS device The oxidation of the silicon ( field oxide ) is created on the surface ( b ) . The field oxide is selectively etched to expose the silicon surface on which the MOS transistor will be created ( c ) . The surface is covered with a thin , high-quality oxide layer which will eventually form the gate oxide of the MOS transistor ( d ) . A layer of polysilicon ( polycrystalline silicon ) is deposited ( e ) . Polysilicon is used both as gate electrode material for MOS transistors and also as an interconnect medium in silicon integrated circuits . The resistivity of polysilicon is reduced by doping it with impurity atoms . The polysilicon layer is patterned and etched to form the interconnects and the MOS transistor gates ( f ) . © Dr. Samer Arandi - An-Najah National University Making a CMOS device The thin gate oxide not covered by polysilicon is also etched away , which exposes the bare silicon surface on which the source and drain junctions are to be formed ( g ) The entire silicon surface is then doped with a high concentration of impurities , either through diffusion or ion implantation ( in this case with donor atoms to produce n-type doping ) . ( h ) shows that the doping penetrates the exposed areas on the silicon surface to create two n-type regions ( source and drain junctions ) in the p-type substrate . Note that the polysilicon gate , which is patterned before doping actually defines the precise location of the channel region and , hence , the location of the source and the drain regions . ( self-aligned process ) Once the source and drain regions are completed , the entire surface is again covered with an insulating layer of silicon dioxide ( i ) . The insulating oxide layer is then patterned in order to provide contact windows for the drain and source junctions ( j ) . © Dr. Samer Arandi - An-Najah National University The surface is covered with evaporated aluminum ( 5000A ) which will form the interconnects ( k ) . Finally , the metal layer is patterned and etched , completing the interconnection of the MOS transistors on the surface ( l ) . © Dr. Samer Arandi - An-Najah National University Making a CMOS device We have covered the basic process steps for pattern transfer through lithography , and gone through the fabrication procedure of a single n-type MOS transistor . The n-well CMOS integrated circuits fabrication follows the same steps , however for creating two devices : N-MOS and P- MOS . The first lithographic mask defines the n-well region . Donor atoms , usually phosphorus , are implanted through this window in the oxide . Once the n-well is created The rest of the steps follows similarly © Dr. Samer Arandi - An-Najah National University The N-Well Fabrication Process Operational Amplifiers Analog Interface Dr. Manar Qamhieh Fall 2015 Digital Electronic Circuits 66332 Computer Engineering Department 1 NOTE : the content of these slides is collected from various sources ( books , websites and author pages ) , no originality is claimed . 2 Interface : is to connect devices in a compatible manner Everything in nature is analog Digital circuits are more stable and more reliable than analog circuits Analog Interface : is the techniques that are used to allow digital circuits to monitor and control analog devices . Analog Interface 3 Analog Interfacing Applications Analog Comparator : An op-amp circuit to know if the analog signal has exceeded a particular threshold or not . Open-Collector Buffer for DC devices or Electromechanical Solid-state relay for AC devices : To control the ON/OFF state of an analog device . Digital-to-Analog ( DAC ) and Analog-to-Digital ( ADC ) circuits : The interface of such circuits require the interface between an Op-Amp and a logic gate . 4 Operational Amplifier ( Op-Amp ) Op-Amp circuit is invaluable for the processing of analog signals . It processes signals in the same way logic gates process digital signals . It can be used to amplify , attenuate and offset analog signals . It can be used to separate different elements of a circuit from each others . It is the universal analog IC because it performs all analog tasks : comparator , one-bit A/D , amplifier , level-shifter , filter , current source , voltage source and many other applications . Op-Amp : Pin Description Op-Amps are differential amplifiers where the output is dependent on the voltage difference applied to its two inputs . Op-Amp is designed to be an almost ideal control device ( a voltage-controlled voltage source ) . Pin Description Two input pins Two power supply pins An output pin 5 6 Op-Amp : Pin Description Input port consists of an inverting input V ( - ) and a non-inverting input V ( + ) . These values can be positive or negative based on the circuit . The difference voltage Vid = V ( + ) - V ( - ) Power supply pins are V+ and V- Typical values are ±12v and it may be as high as ±18v . Output voltage is dependent on Vid , and it is limited to approximately 1v less than the supply voltage . These values are often referred to as ±Vsat . Op-Amp : Idealized Abstract Model Input impedance is infinity . Output impedance is zero . No connection between input & output ( open-loop ) . The Open-loop gain AOL ( the factor by which the input voltage is amplified ) 7 is infinity . Vout = AOL * Vid This is the mathematical representation of a voltage-dependent voltage source controlled by Vid Input circuit is separated from the output circuit . 8 Op-Amp : Abstract Model At low frequencies , AOL is between 100 and 100,000 at dc . Hence , It is normal for an open-loop op-amp circuit to operate in saturation Vout = ±Vsat For an output not to be in saturation , Vid should be as small as : Vid < ( Vsat / AOL ) Accordingly , if Vsat = +11v and AOL = 100,000 , then Vid must be less than 110µv . Ap-Amp : Open-Loop Saturation Mode Without feedback , the output of an op-amp is always in saturation . Large gain saturates the output with only tiny difference voltage on the input port . The output is either +Vsat or -Vsat , hence the operation is nonlinear . 9 Op-Amp : Open-Loop Output Voltage Tiny input difference voltage ( ±50µv ) Output has linear parts , but signal get trimmed when voltage saturates 10 Op-Amp : Open-Loop Output Voltage 11 Input difference voltage ( ±5v ) Output signal is pulse like , since linear parts are tiny when compared to saturated parts 12 Op-Amp : Closed-Loop Configuration An Op-Amp operates in closed-loop when a portion of its output is fed back to its inverting input pin V ( - ) . -- negative feedback -- Normally in Closed-Loop operation , the op-amp responds linearly to its input . Op-Amp : Why Negative Feedback ? We can add a resistor and a capacitor to model the accumulation of charge in an op-amp . This is not an accurate representation of the inside of an op-amp , but it is a model of how an op-amp works ! 13 Op-Amp : Why Negative Feedback ? If Vi suddenly increases VO = AOL ( Vi-V- ) increases Current flows into capacitor ( charges ) VO gradually increases the difference ( V+-V- ) decreases Less current flows and VO approaches a final value equal to Vi Negative feedback 14 Op-Amp : Why Negative Feedback ? If Vi suddenly decreases VO = AOL ( Vi-V- ) decreases Current flows out of the capacitor ( discharges ) VO gradually decreases the difference |V+-V-| decreases Less current flows and VO approaches a final value equal to Vi Negative feedback 15 Op-Amp : Why Negative Feedback ? 16 If Vi suddenly increases VO = AOL ( V+-Vi ) decreases Current flows out of the capacitor ( discharges ) VO gradually decreases The difference ( V+- Vi ) increases Positive feedback Op-Amp : Why Negative Feedback ? If Vi suddenly decreases VO = AOL ( V+-Vi ) increases Current flows into the capacitor ( charges ) VO gradually increases The difference ( V+- Vi ) increases Positive feedback of an op-amp is unstable Positive feedback 17 Op-Amp : Inverting Amplifier Vin is applied to Ra and it is not Vid Key assumptions : if output is not saturated , Vid must be nearly 0v ( less than 110µv ) if Vid = 0 , the summing node must be at 0v ( virtual ground ) No current flows into the op-amp inputs ( typically , input resistance of op-amp pins are greater than 1MΩ ) Summing node 18 19 For AOL ≅ 100,000 , and the ratio Ra / ( Ra+Rb ) not less than 0.001 . Then : Vout ≅ - ( Rb / Ra ) * Vin The relation between the input and the output voltage is almost independent Open-Loop gain AOL of the Op-Amp , and dependent only on resistor ratio . The Closed-Loop gain ACL of this circuit is ACL = - Rb / Ra Op-Amp : Inverting Amplifier Op-Amp : Non-Inverting Amplifier The input voltage Vin is connected to V ( + ) pin of the Op-Amp . Key assumptions : if op-amp is not saturated , then Vid is so small ( ≅ 0v ) The summing node is biased at a voltage equal to Vin Input current of op-amp is zero . 20 21 Op-Amp : Non-Inverting Amplifier For large value of Open-loop gain ( AOL ≅ 100,000 ) : Vout ≅ [ 1+ ( R2 / R1 ) ] * Vin The closed-loop gain ACL of this circuit is : ACL = 1 + R2 / R1 22 Op-Amp : Choice of Resistors The gain of closed-loop circuits is based on the ratio of the resistors and not on their actual values . The designer can choose any desired value within practical limits . The values of resistors determine the current drain and the effect stray capacitance will have . If values of resistors are too low higher current is required for Op-Amp operation , which leads excessive dissipation . self-heating of the chip , If values of resistors are too high an increase in noise and parasitic capacitances leads to instability and oscillation 23 Op-Amp : Closed-loop Circuits Advantages of closed-loop circuits ( inverting & non-inverting ) : Vout is not dependant on AOL , but on the values of resistors . Resistors are more stable , reliable and very insensitive to temperature than AOL . It becomes a precision circuit , because ACLis dependant on passive components ( resistors ) which can be very accurate . Disadvantage : Closed-Loop gain ACL is much less than the Open-Loop gain AOL . ACL is between 1 and 1000 . 24 Op-Amp : Closed-Loop Circuits The power supply pins V+ and V- are necessary to power the op-amp The op-amp uses current from the power supplies to regulate the output voltage and to supply the necessary output current . They are not included in the analysis of closed-loop circuits , because : the used KCL calculation does not yield a useful relation . calculating the current through a voltage source rarely provides useful insights . A voltage source can support any current . Op-Amp : Bandwidth Typically , op-amps are used for comparatively low frequencies ( where AOL is large ≃+100 , 000 ) . At high frequencies , the gain falls below unity ( A < < 1 ) . Op-Amp bandwidth depends on the process used to make the op-amp . BJT op-amps have the highest bandwidth and current drain . MOSFET op-amps the lowest bandwidth and current drain . 25 26 Op-Amp : Bandwidth In closed-loop circuits , we assumed that AOL is so large so as to calculate the Closed-loop Gain ACL . At high frequencies , when A drops below ( R2+R1 ) /R1 ( where R1 is the input resistance ) , ACL drops too . The frequency at which ACL falls below the ideal gain is called the closed- loop bandwidth fCL . 27 fCL = fU / AN where fU is the unity gain frequency and AN is the noise gain The noise gain is modeled as a voltage source at the positive input of the op-amp . Hence : AN = ACL = ( R1+R2 ) / R1 Op-Amp : Non-Inverting Bandwidth 28 Example : Consider a non-inverting amplifier having a fU = 10MHz and R1 = R2 = 10㏀ . What is its closed-loop bandwidth fCL ? fCL = 5MHz Op-Amp : Non-Inverting Bandwidth 29 Unity gain frequency is called the Gain-Bandwidth-Product ( GBP ) . The product of Noise Gain AN and bandwidth fCL is constant and bounded by GBP . If you need : a higher AN , then the bandwidth fCL drops . a higher bandwidth , then you must choose a lower gain . both higher gain and bandwidth , then you need to pick an op amp with a higher GBP ( fU ) on its data sheet . Op-Amp : Non-inverting Bandwidth 30 Op-Amp : Inverting Bandwidth The bandwidth frequency fCL of inverting circuit has the same value of non- inverting frequency . fCL = fU / AN , where AN = ( R1+R2 ) / R1 Disadvantage of inverting circuit : signals are amplified by R2/R1 ratio , but the bandwidth is dependent on the larger ratio ( R1+R2 ) /R1 Previous Example : ACL is equal to -10k/10k = -1 , while AN = 2 . Hence , fCL = 10MHz / 2 = 5MHz Op-Amp : Unity Gain Buffer In a non-inverting amplifier with ACL = ( Rin+R1 ) /Rin If Rin is very large w.r.t . R1 , then ACL becomes 1 Vout = Vin → this circuit is a unity gain buffer Rin is usually deleted , while R1 can be shorted . R1 ( usually 20kΩ ) is included in many buffer designs to protect the inverting input from an over voltage 31 Using a variable voltage to control a motor From a power supply voltage = 15v , we need 7.5v for the motor . We can use a voltage divider with two equal resistors The voltage of the motor depends on the resistance of the motor . For example , if the resistance of the motor is equal to 100Ω , then the voltage of the motor will be very close to 0 . Op-Amp : Application of Unity Gain Buffer 32 The use of a unity gain buffer separates the input circuit from the output . The voltage of the motor will stay 7.5v no matter what the resistance of the motor . The resistance of the motor specifies the maximum current to pass through the motor . Op-Amp : Application of Unity Gain Buffer 33 Op-Amp : Summing Inverter It is an amplifier with multiple inputs . It sums the effects of its inputs . Vout = - [ V1/R1 + V2/R2 + ... ] * RF This circuit is equivalent to a three-channel amplifier with each channel having a separate gain ( -RF/Rn ) 34 Op-Amp : Differential Amplifier It amplifies the difference between signals applied to the inputs . By using superpositioning and assuming that RG = RG ’ and RF = RF ’ Vout = ( V1 - V2 ) * RF / RG This circuit rejects the common-mode portion of the input signal if noise voltages appear between grounds , the noise will be suppressed by the common-mode rejection ( CMR ) of the differential amplifier . 35 Op-Amp : Differential Amplifier For proper operation , input resistors ( RG & RG ’ ) and feedback resistors ( RF & RF ’ ) must be matched . The CMR of the differential circuit depends on this matching . Problem : If the driving impedance ( from V1 and V2 ) is not low compared to input resistors , then additional errors will be introduced to the circuit which affect the ratio of resistors and the operation of the circuit . 36 Op-Amp : Differential Amplifier Solution : 37 38 Op-Amp : Instrumentation Amplifier High gain differential amplifiers with high input impedance and a single ended output . Eliminates the need for input impedance matching . Low noise and very high common-mode rejection ratio . Suitable for use in measurement and test equipments where it is mainly used to amplify very small differential signals from certain kinds of transducers or sensors . Provides great accuracy and stability of the circuit . Op-Amp : Instrumentation Amplifier 39 40 Op-Amp : Video Amplifier Video signals can suffer deterioration over relatively short cable distances . Video amplifiers are used to compensate for that loss . Video signals contain high frequencies . These signals use coaxial cable to transmit and receive signals . The used cable has a characteristic impedance of 75Ω . In video amplifiers , op-amps must have input and output impedances matching the 75Ω To prevent reflections which cause distortion and ghosting of video signals Op-Amp : Video Amplifier Non-inverting circuit is used . RIN = 75Ω ( since input impedance of op-amp is very high ) . RF and RG have high values ( in kΩ ) to have minimal affect on input or output impedances . A matching resistor RM is placed in series with the op-amp output so as to raise output impedance to 75Ω . A terminating resistor RT is placed at the input of the next stage to match the cable . 41 Op-Amp : Video Amplifier RM = RT they form a voltage divider of 1/2 Very often , RF is selected to be equal to RG , so as the non-inverting circuit has a gain ACL = 2 Hence , the video amplifier has a unity gain ( 2 * ½ = 1 ) 42 Op-Amp : Input Offset Voltage VOS e Ideal : if both inputs of an op amp are at exactly the sam voltage , then the output should be at zero volts . Practical : The input stage of the op amp consists of a differential pair of transistors . If the two transistors are not perfectly matched , this mismatch will show up as a non-zero DC offset at the output . 43 Op-Amp : Input Offset Voltage VOS Input Offset Voltage VOS is a small differential voltage which is applied to the inputs of an op-amp to force the output to zero . VOS is modeled as a voltage source in series with the non-inverting input of the op- amp . 44 45 Op-Amp : Input Offset Voltage VOS Ranges Chopper Stabilized / Auto-zeroed Op Amps : General Purpose Precision Op Amps : Best Bipolar Op Amps : Best JFET Input Op Amps : High Speed Op Amps : Untrimmed CMOS Op Amps : DigiTrim™ CMOS Op Amps : < 1µV 50-500µV 10-25µV 100-1,000µV 100-2,000µV 5,000 - 50,000µV 100µV - 1,000µV 46 Op-Amp : Input Offset Voltage VOS Input Offset Voltage VOS varies with temperature . TCVOS is its temperature coefficient , or drift . Offset drift is affected by the offset adjustments to the op-amp . Most op-amps have a specified value of TCVOS Typical drift values for a range of general purpose precision op amps lie in the range 1-10 µV/°C Maximum VOS may be provided over the operated range of temperature . It is less useful because there is no guarantee that TCVOS is constant or monotonic . The Offset Voltage VOS changes as time passes ( aging ) . Generally , aging is specified in µV/1000 hours . It is proportional to the square root of the elapsed time . Op-Amp : Measuring Input Offset Voltage VOS Measuring VOS ( µv ) requires that the circuit does not introduce more error than VOS itself . The circuit amplifies the input offset voltage by the noise gain of 1001 . The Vout is measured using an accurate digital voltmeter . 47 Op-Amp : Adjusting VOS ( Null Pins ) Many single op amps have pins available for optional offset null . Two pins are joined by a potentiometer , and the wiper goes to one of the supplies through a resistor , Wiper connection may be to either +VS or -VS depending on the op amp . Values for R1 and R2 depend on op amp . Use to null out the op amp input offset voltage , not the overall system offsets . There may be high gain from offset pins to output . Nulling offset causes increase in offset temperature coefficient , approximately 4 µV/°C for 1mV offset null for FET input amplifiers 48 Op-Amp : Adjusting VOS ( External Method # 1 ) Injecting current into the inverting input of \\n inverting amplifier circuit . Disadvantage a possible increase in noise gain , due to the parallel path of R3 and the potentiometer resistance . Noise gain may be reduced by making ±VR large enough so that the R3 value is much greater than R1II R2 if the power supplies are stable and noise-free , they can be used as ±VR . Otherwise , separate regulated low noise ( filtered ) sources should be used . 49 Op-Amp : Adjusting VOS ( External Method # 2 ) injecting a small offset voltage into the non-inverting input . Advantage no noise gain increase Disadvantage It requires adding RP If the op amp has matched input bias currents , then RP should equal R1II R2 ( to minimize the added offset voltage ) . Otherwise , RP should be less than 50Ω . 50 Op-Amp : Adjusting VOS ( External Method # 3 ) Injecting a small offset voltage when using an op amp in the non-inverting circuit . It works well for small offsets , where R3 can be made much greater than R1 . The signal gain might be affected as the offset potentiometer is adjusted . The gain may be stabilized , if R3 is connected to a fixed low impedance reference voltage sources , ±VR . 51 Op-Amp : Input Bias Current Ideal Op-Amp : No current flows into input terminals Practical Op-Amp : There are two input bias currents IB+ & IB- IB can vary from 60 fA to many µA , depending on the device . Some structures have well-matched IB , others do not . In some structures , IB varies little with temperature . Some structures have IB which may flow in either direction . Bias current is a problem for the op amp user it flows in external impedances and produces voltages , which add to system errors . 52 53 Op-Amp : Input Offset Current IOS IOS is the difference between the two input bias currents . ○ IOS = IB+ - IB- IOS is meaningful where the two individual bias currents are fundamentally reasonably well-matched . This is true for most voltage feedback ( VFB ) op amps . Op-Amp ’ s input stages comprise of two complementary parallel stages which have bias currents that change direction as the common-mode voltage passes through the transition region . Bias and offset currents for these devices are especially difficult to specify , other than simply giving a maximum positive/negative value . Op-Amp : Internal Bias Current Cancellation Necessary bias currents are provided via an internal current source . External current flowing in the input terminals of the op-amp is the difference current between the base current and the current source . Pros Low offset voltage and drift , low bias current and voltage noise . Cons Poor bias current match , higher current noise , not very useful at high frequencies . Most modern precision bipolar input stage op amps use some means of internal bias current compensation . 54 55 Op-Amp : Internal Bias Current Cancellation In many cases , the bias current compensation feature is not mentioned on data sheets , and a simplified schematic is n't supplied . How to verify ? Examine the bias current specification . If bias current is specified as a “ ± ” value , the op amp is most likely compensated for bias current . To do so , examine the offset current specification : If internal bias current compensation exists , the offset current will be of the same magnitude as the bias current . Without bias current compensation , the offset current will generally be at least a factor of 10 smaller than the bias current . Op-Amp : Cancelling Bias Current ( External ) Bias currents should be well matched simple bipolar input stage op amps not internally bias compensated op amps Add a bias compensation resistor R3 ( = R1 || R2 ) to the non-inverting input . It provides a voltage drop equal to the one on the inverting input of the op amp . This method should not be used when bias currents are not well matched . It makes matters worse ! 56 Op-Amp : Cancelling Bias Current ( External ) Large resistance RS in series with the input to be tested . Typically , RS values vary from 100KΩ for BJT op amps to 1000MΩ for FETs . It creates an offset voltage = IB * RS The change in VOS ( previously measured ) due to RS can be measured , which leads to IB . IB is the average of IB+ and IB- 57 Op-Amp : Offset Errors due to VOS and IB Errors ( due to offset voltage and induced offset voltage from bias current ) are Referred To the Input ( RTI ) or Referred to the Output ( RTO ) of the op amp . 58 Op-Amp : Offset Errors due to VOS and IB RTI is useful to compare the cumulative op amp offset error to the input signal . RTO is useful if the op amp drives additional circuitry , to compare the net errors with that of the next stage . 59 60 Op-Amp : Minimize Errors Keep input/feedback resistance values as low as practical , to minimize offset voltage due to bias current effects . Use a bias compensation resistance with VFB op amps not designed with internal bias compensation . Bypass this resistance , for lowest noise pickup . If a VFB op amp does use internal bias current compensation , do n't use the compensation resistance . Choose an appropriate precision op amp specified for low offset and drift . Operational Amplifier 2 Current Source & Comparators The content of these slides is collected from various sources ( books , websites and author pages ) , no originality is claimed Digital Electronic Circuits 66332 Computer Engineering Department Dr. Manar Qamhieh Fall 2015 1 Precision Voltage to Current Converter A nearly ideal voltage controlled current source . The input voltage to be converted is applied to the non-inverting input of op amp . The inverting input terminal is connected in feedback to one end of the resistor R1 and the source of the transistor M1 . The output of the op amp drives the gate of the transistor . 2 Precision Voltage to Current Converter Key considerations : No current enters the inputs of the op amp . The op amp automatically adjusts its output to bring its inverting input to the same voltage of its non-inverting input . No current enters the gate of the transistor M1 . Hence The high AOL of the op amp forces the gate of M1 to the required voltage such that VIN appears across R1 . The drain current passes through R1 and it is equal to VIN / R1 . Cons : unidirectional current source . 3 Current Source : Basic Howland Current Pump Pros : Bidirectional current source ( controlled by the difference of input voltages ) AC currents ratios R1/R2 and R3/R4 are the same . 4 Basic Howland Current Pump : Analysis R1 = R R2 = R R3 = R R4 = R Modified circuit 5 R1 = R2 = R3 = R4 = R V-input = 0 Vout = 2 VX ( non-inverting circuit ) Output current is controlled by V+input and the value resistor of the circuit and it is independent of the load resistor . Basic Howland Current Pump : Analysis Example 1 : Consider V+input = 10v R = 10kΩ Iout = 1mA Suppose that the load has a resistance equal to 1kΩ VX ( voltage drop over RL ) = 1v Even with this load resistor , the output current Iout remains 1mA . R1 = R R2 = R R3 = R R4 = R 6 Basic Howland Current Pump : Analysis 7 R1 = R R2 = R R3 = R R4 = R Example 2 : no load : RL = 0 , VX = GND No current passes through R3 , R4 Vout = 0 , hence , IR2 = 0 Iout = IR1 = V+input / R = 1mA Example 3 : RL = 5kΩ Iout = 1mA ( controlled by Vin & R1 ) VX = 5v , Vout = 10v Iout = IR1 + IR2 = 0mA + 1mA Test other values of RL ( 2k , 6k , … ) . What do you notice ? Basic Howland Current Pump : Analysis 8 R1 = R R2 = R R3 = R R4 = R Output voltage of op amp is not fixed . negative & positive feedbacks The load current Iout remains constant ( related to V+in ) what varies to accommodate the changes in load is the op amp output voltage Output current is independent of the load . Basic Howland Current Pump : Analysis The constant current source of the output ( Iout ) is guaranteed as long as the op amp does not saturate . Vout required by the load should not exceed the power supply voltage of the op amp . Example : Consider R = 10kΩ , V+in = 10v RL = 10kΩ , Vsupply = ±15v Iout = 1mA VX = 10v Not possible . This is well above most op amp positive power supply voltages 9 R1 = R R2 = R R3 = R R4 = R Basic Howland Current Pump : Limitations Inefficiency Op Amp has to put out a lot of drive if the load voltage swings a lot Output capabilities & limited Iout Output node does not swing very close to the rail Example : R = 1kΩ , V+in = 10v , Iout = 10mA RL = 1kΩ VX = 10v , Vout = 20v R1 = R R2 = R R3 = R R4 = R 10 Improved Howland Current Pump Avoids the weaknesses of the basic Howland current pump . Helps the op amp output voltage to exceed the op amp supply voltage . The op amp is still limited by the current it can source . Additional resistor R2 between the non- inverting input V+ of op amp and the output node VX . 11 Improved Howland Current Pump Consider R4 = R5 RL = 0 , VX = GND General form of Vin/Iout transfer function . 12 Improved Howland Current Pump 13 Special case : R1 = R2 + R3 Example : R1 = 10kΩ , R2 = 9.9kΩ , then R3 = 100Ω . V+input = 10v IR2 = 502.5 µA V+ = 4.975v Vout ≅ 9.95v IR3 = 0.0995A Iout = 100mA This current is achieved without saturating the op amp . The choice of resistors makes the output voltage proportional to the numeric value of Iout Improved Howland Current Pump For this special case : R1 = R2 + R3 The relation between Iout and V+input is provided as follows : ○ By simplifying the terms , it becomes : 14 Op Amp as Comparator Basic non-inverting op amp comparator Voltage transfer characteristics Vref = 0 15 Voltage transfer characteristics Vref ≠ 0 16 Op Amps as Comparators Common features : Both comparators & op amps have two input terminals ( inverting and noninverting ) and an output which swings from rail to rail . Both have low offset , high gain and high common-mode rejection . Comparator Gives a logic output indicating the relative potentials on its two inputs . Op Amp Amplifies the differential voltage between its two inputs and it is designed always to be used in closed-loop applications . 17 It is not recommended to use op amps as comparators Despite these differences , it is still tempting to use op amps as comparators . Op Amps as Comparators ❏ Comparators are designed to work open-loop ❏ they are designed to drive logic circuits ❏ they are designed to work at high speed even when over-driven ❏ Op amps are designed to work in closed-loop ❏ they are designed to drive simple resistive or reactive loads ❏ They are slower when over-driven due to saturation Op Amps as Comparators Advantages of using op amps as comparators : Convenience and economy : They are cheaper and they come usually in packages containing two or four op amps . So it is better to use the “ spare ” op amp of the package as comparator instead of buying a separate comparator . Low Bias Current IB and Low Offset Voltage VOS : Comparators are designed for clean and fast switching . As a result , they have worse dc parameters than op amps . It is more convenient to use an op amp as a comparator in applications requiring low VOS , low IB and wide CMR . Disadvantage of using op amps as comparators : Slower speed output levels and input structure stability and hysteresis 18 Speed Problem in Op Amp Comparators 19 Op amp comparator suffers from saturation which makes it slower than the same op amp used in closed-loop . Comparators are used with large differential input voltages Closed-loop op amps operate with their input voltages minimized by negative feedback . When op amp saturates due to overdriving , some of its stages may saturate and it requires a certain delay to come out of saturation . Speed Problem in Op Amp Comparators 20 When op amp saturates due to overdriving , some of its stages may saturate and it requires a certain delay to come out of saturation . The desaturation time of an over- driven op amp is longer than its normal group delay ( the time the signal takes from input to output ) . Desaturation time depends on the amount of overdrive . Op Amps as Comparators : Interface Circuit Usually , the output of a comparator is designed to drive logic family or families . Op amps has rail-to-rail output maximum positive output is close to positive supply and the minimum negative level is close to the negative supply . If logic and op amp share the same supply , then a rail-to-rail op amp will drive TTL and CMOS logic families . Notice that for an op amp with ±5v supplies , the logic may be damaged when -5v is applied . If logic and op amp have different supply , then an additional interface circuit is necessary . 21 Interfacing Circuit : Using Inverters 22 The simplest interface is done using inverters NPN transistors can be used but they consume base current . NMOS are more convenient . ○ +VA must be more positive than -VL by a voltage difference enough to turn on the NMOS transistor . -VA must be less than -VL RB sets the base current and RL sets the collector/drain current Interfacing Circuit : Using CMOS CMOS can be used as inverter in the interfacing circuit It draws no standby current , hence it has lower power dissipation The op amp positive supply +VA must be equal to or greater than +VL The op amp negative supply -VA must be equal to or smaller than -VL 23 The interface between op amp comparator and ECL logic family requires 3 resistors . The ratio of R1 , R2 and R3 is set to respect the following requirement : when the op amp output is at +VA , the voltage level at ECL input is -0.8v . when the op amp output is at -VA , the voltage level at ECL input is -1.8v . Why there aren ’ t many applications in which op amp comparators are used to drive ECL logic circuits ? Interfacing Circuit : Using ECL 24 Some older types of op amps suffer from a phenomenon called the “ phase inversion ” This happens when the input common-mode voltage ( average voltage of V+ and V- ) is exceeded . One of the internal stages of the op amp no longer has sufficient bias voltage and it turns off . The output voltage swings to the opposite rail until the input comes back within the common-mode range . It is so important to ensure that the op amp comparator is free from phase inversion or that the system is designed to so that the comparator inputs never approach the region which causes inversion . 25 Problem of Phase Inversion Op amp comparators work at their full open- loop gain and may suffer from instability due to feedback from stray capacity or due to common ground impedances . A comparator normally changes its output state when the voltage between its inputs crosses through approximately zero volts . When the input voltage difference is near 0 , any noise can cause undesirable rapid change of the output . Instability and Hysteresis 26 Instability and Hysteresis 27 Single reference voltage range of reference voltages ( hysteresis ) tage To prevent output oscillation , a small hysteresis of few millivolts are integrated into comparator . Instead of one switching point , hysteresis introduces two : rising ( positive ) voltage and falling ( negative ) vol Positive feedback is used to produce hysteresis . The amount of hysteresis is predictable and is controlled by the ratio of the positive feedback resistors . Instability and Hysteresis 28 A Schmitt Trigger is a comparator circuit with hysteresis implemented by applying positive feedback to the noninverting input of an op amp . The output retains its value until the input changes sufficiently to trigger a change Two threshold voltages : Positive and negative voltages . Instability and Hysteresis 29 Schmitt Trigger An inverting Circuit A non-inverting Circuit 30 1 Data Conversion Systems Digital Electronic Circuits Manar Qamhieh 2 Digital-to-Analog Converter ( DAC ) DACs accept digital inputs and provide analog outputs . The number of their digital input lines varies between 6 ( low cost ) and 16 input lines ( expensive DACs ) . Application example : The speed of a DC motor depends on the voltage ( or current ) applied to its field windings . A DAC system can be used to control the speed . The DAC should output a continuous range of voltages from zero to some full-scale maximum to be used as an input to the DC motor . DAC System 3 DAC System The transfer curve of a DAC shows a graph of the analog output voltage vs. binary inputs . As the binary input increases , the analog output steps up in a staircase fashion ( monotonicity ) . The size of each step is : n step size = VFS / 2 where VFS is the full-scale output voltage and n is the number of binary input bits . A 3-bit DAC 4 5 DAC System Example : A certain 8-bit DAC has VFS = 5v . Calculate the step size and the maximum output voltage for this DAC . Solution : Step size Maximum output voltage = 5 / 28 = 19.53mV = 255 * 19.53mV = 4.98V This corresponds to one step ( or 1 bit ) less than the full scale . Increasing the number of binary bits , the step size will decrease . Resolution of a DAC is the same as its step size . DAC System The accuracy of a DAC depends on several factors : Quantization error : fractional steps are not possible when an output voltage is required , which causes a worst-case error of ±1/2 LSB ( least significant bit ) . An 8-bit DAC with VFS = 5V can produce output steps of 19.53mV . For an output of 4v , 205 steps are required ( instead of 204.8 steps ) which corresponds to 4.004V ( 4mV of error ) . Offset and gain errors : Offset error : when the binary input is 0 , the output of a DAC may not be 0 . Gain errors : they cause the slope of the transfer curve to bend upward or downward due to imbalances with DAC . Both errors can be nulled via an external potentiometer . 6 DAC System The accuracy of a DAC depends on several factors : Nonlinearity : the maximum deviation of the transfer curve from a straight line drawn between zero and full scale . It is due to the mismatching of components within the DAC and can not be easily removed . Settling line : this is the time required by the DAC to settle to within ½ LSB after receipt of the binary input . It ranges from less than 100ns for some high-speed DACs to more than 1µs for low-cost versions . 7 Switched-Voltage R-2R DAC 8 Digital input consists of three switches that may be connected either to GND ( logic 0 ) or VREF ( logic 1 ) Switched-Voltage R-2R DAC Equivalent circuit at node A when switch D0 ( only ) is closed . 9 At each node , the current splits exactly in half . 10 Switched-Voltage R-2R DAC Example : Assume that the DAC in the previous figure has a binary input of 101 . Calculate the output voltage if VREF = 3v , R = 1kΩ and RF = 10kΩ . Vout I = 3v / [ ( 2R || 2R ) + 2R ] = 3v / 3k = 1mA ○ ○ = - ( 1 * 1m/8 + 0 * 1m/4 + 1 * 1m/2 ) * 10k = -6.25v DAC 0800 : Switched-Current Multiplying DAC 11 An 8-bit DAC . A switched-current R-2R DAC It uses a constant-current source to establish the reference current . Each data switch is connected to GND ( actual or virtual through op- amp ) . The current in each path is constant and independent of the digital input . A multiplying DAC The output current IOUT is equal to the product of the digital input and the reference current . Example : if input is 11001001 ( 201 ) and reference current is 2mA . IOUT is equal to ( 201/256 * 2mA ) = 1.57mA DAC 0800 : Interfacing Circuit Zener diode with R1 & R2 provide a 2mA reference current ( 5v/2.5k ) 12 1N914 diodes help minimizing changes in the 5v reference with temperature Multiplied output current is forced by the op amp to flow through RF . VOUT = IO * RF 13 DAC 0800 : Switched-Current Multiplying DAC Example : Calculate the full-scale output voltage , maximum output voltage and resolution of the DAC 0800 interface ( presented in the previous slide ) . The full-scale output current is IREF = 2mA Full-scale output voltage = 2mA * 5k = 10v Maximum output voltage = 255/256 * 10 = 9.96v Resolution ( contribution of 1bit ) = 1/256 * 10v = 39mv Many DACs are switched-current rather than switched-voltage . Switched-current DACs provide faster settling time because the junction capacitances of the resistors need not be continually charged and discharged . Synthesizing a Sine Wave 14 Microcontrollers can be programmed to play music or other sounds . The samples of the waveform to be produced must be stored in a table and output at a periodic rate to the DAC . Example : a synthesized version of a sine wave of 6v peak-peak produced from a 5v DC level obtained from a DAC that is programmed to receive a voltage sample every 30° . VOUT = 5v + 3v * sin θ where θ = 0° , 30° , 60° , … For VFS = 10v Output code = HEX ( [ VOUT * 256 ] / VFS ) Synthesizing a Sine Wave A complete table can be filled w.r.t . the previous equations The frequency of the output waveform produced by this DAC depends on the speed at which the software outputs the values in the table . Example : for a 1KHz frequency ( 1000µs period ) , a new sample must be output every 1000µ/12 sample = 83.3µs 15 16 Analog-to-Digital Converters ( ADC ) ADCs are integrated circuits that that are part of data acquisition systems . They accept analog inputs and provide digital outputs . Resolution of ADCs gets better by increasing the number of digital lines . Typical ADCs have 8 , 10 and 12 bits as digital lines . An ADC can provide a range of digital outputs that correspond to the variations of the analog signal being monitored . Multichannel Data Acquisition System An amplifier is necessary because usually the input signal ( from sensors ) are small . Amplifier should have high input impedance so as the ADC circuit does not to affect the signal being measured 17 Necessary if the analog signal is changing rapidly . 18 Analog-to-Digital Converter ADC The resolution of an ADC is determined by its step size , which is step size = V / 2n FS where VFS is the full-scale reference voltage and n the number of bits . Example : For a 10-bit ADC with VFS = 5v , its resolution is equal to 5/1024 = 4.88mV . This means that the input voltage has to change by at least 4.88mV for the ADC to distinguish the new input level . An input voltage of 2.5v is equivalent to 512 steps ( corresponds to 1000000000B ) , where : Binary output = BINARY ( VIN / Step Size ) ADC : Sampling 19 Conversion time ( aperture time ) : ADCs require a period of time to convert their analog input into its digital equivalent . The effect of this conversion time is to limit the ADC to taking samples of the input waveform instead of one continuous conversion . Sample-and-hold circuit is used to reduce errors due to the change of input signal during the conversion time . It consists of a capacitor and a switch . The capacitor holds the input voltage steady long enough for an accurate conversion to take place . ADC : Sampling If sampling occurs at a fast enough rate , the sampled signal will be a good representation of the input . If the sampling is done too slowly , a false ( or alias ) signal may be detected . The Nyquist criterion : If the input is sampled at a frequency that is greater than twice that of the input , the original waveform can be reproduced accurately . Sampling rates of typical ADCs are limited to 10 to 100 kHz . 20 21 A-to-D Conversion Methods Open-Loop Flash Converters Tracking Converters Successive-Approximation Converters Integrating Converters A 0-v to 4-v 2-bit flash converter 22 Open-Loop Flash Converter It converts its analog input to a digital output very quickly . Just the propagation delay times through the analog comparators and logic gates . All comparators are open-loop There is no feedback between input and output . There are 2n-1 comparators for an n-bit converter . A separate comparator for each voltage step to be detected ( 0 is not included ) The logic gate array is needed to convert the output of comparators into standard 1-2-4-8 binary . 23 Open-Loop Flash Converter Advantage : Very high speed of operation . For example , TDC1018 converter operates at speeds up t0 125 million conversions per second and it is ECL compatible and intended for high-resolution graphics displays used in image processing . Disadvantage : The number of comparators double for each additional output bit . 255 comparators for 8-bit ADCs , 4095 comparators for 12-bit ADCs . Flash converters are usually expensive and reserved for specialized applications Tracking Converters Tracking ADCs are slower than flash converters but much less costly . An analog comparator compares the analog input voltage with the output of the DAC . If the DAC is less than VIN , the output of the comparator will be pulled high . This will select the count-up mode of the counter and increase its output , which increases the input of the DAC as well . Eventually , the output voltage of DAC will exceed VIN and switches the comparator to low . The counter will start counting down until inputs of comparator are equal . 24 Tracking Converters 25 Tracking converters are good for input signals that vary slowly with time . The counter will follow the change in input and the digital output will remain close to its correct value . If the input should make a sudden change , the circuit requires a considerable amount of time to reacquire lock . In a worst case when VIN switches from 0-v to VFS or vice versa , 2n-1 clock cycles will be required before lock is obtained . 26 Successive-Approximation Converter Successive approximations can converge on the result in just n cycles instead of 2n-1 cycles required by tracking converter . In this design , the up/down counter is replaced with a successive- approximation register ( SAR ) . One conversion cycle of the SAR consists of : Set the MSB ( Most Significant Bit ) and output this result to the DAC If the DAC output is greater than VIN , reset the bit ; otherwise , leave this bit set . Repeat steps 1 and 2 , setting the next most significant bits until all n bits have been tested . Successive-Approximation Converter Example : List the analog and digital outputs produced during one conversion cycle by an 8-bit successive-approximations ADC when the analog input is 8v . Assume that VFS = 10v . 27 Successive-Approximation Converter The ability of this converter to return an accurate representation of the input voltage depends on the speed of conversion . If the input changes too rapidly , the converter can be “ fooled ” ( as in Conversion 2 ) . 28 Integrating Converters It is commonly used in digital voltmeters and multimeters . Digital Output 29 30 Integrating Converters The conversion begins with the electronic switch in the T1 position , the T3 switch is open , and the counter is reset to zero . The input voltage causes the capacitor connected to the op amp to charge at a rate dependent on the magnitude of the input voltage ( VIN/R ) . The total charge stored by the capacitor is Q1 = ( VIN * T1 ) / R After T1 seconds have elapsed , the selector switch is moved to position T2 by the control logic . 31 Integrating Converters The reference voltage is of opposite polarity to VIN , hence the capacitor discharges and the counter starts . When the capacitor fully discharges , the comparator output level switches and the counter is halted . The amount of removed charge is : Q2 = ( VREF * T2 ) / R Since Q1 = Q2 , we conclude that : VIN = ( T2 / T1 ) * VREF The value stored in the counter is directly proportional to the input voltage . The larger the input voltage , the greater the charge stored in the capacitor during T1 . Larger voltages will require more time to discharge 32 Integrating Converters Integrating converters are quite slow , requiring anywhere from 1 to 200ms for one conversion . They are used mostly in digital panel meters , when conversions should be low enough for the human eye to detect . Advantages : Simplicity and low cost . Relative immunity to noise Since sampling period T1 is long , any noise will be added/subtracted to the signal . At the end of T1 , the voltage stored on the capacitor represents the average value of the input signal over this period of time . Sensors & Driver Circuits Analog Interface Dr. Manar Qamhieh Fall 2015 Note : the content of these slides is collected from various sources , no originality is claimed . Digital Electronic Circuits 66332 An-Najah National University 1 2 Sensors and Transducers The words “ sensors ” and “ transducers ” are used to describe the measurement systems A sensor is a device that detects a change in a physical stimulus and turns it into a signal which can be measured or recorded A transducer describes the sensing element plus any additional circuitry All transducers contains sensors while most ( not all ) of the sensors are transducers . 3 Sensors and Transducers A sensor converts mainly physical phenomena such as thermoelectric , photoelectric , photomagnetic , electromagnetic , magnetoelectric , thermoelastic , thermomagnetic , thermo-optic , photoelastic , and so on Acoustic wave , spectrum , wave velocity Electric charge , current , potential , electric field , conductivity , permittivity Magnetic magnetic field , magnetic flux , permeability Optical wave velocity , refractive index , emissivity , absorption Thermal temperature , specific heat , thermal conductivity Mechanical position , acceleration , force , pressure , torque , orientation , stiffness 4 LED : Light Emitting Diode LED main applications and uses : Indicator and display device Source of visible or infrared light as carrier of data and information over short distances . A LED is a specialised type of P-N junction diode made of thin chip of fairly heavily doped semiconductor material . When it is forward biased , electrons from the semiconductor conduction band can combine with holes from the valence band , releasing sufficient energy to produce photons of light . Because of the thin chip , a reasonable number of these photons can leave it and radiate away as its light output . 5 LED : Light Emitting Diode LEDs are made from compound semiconductor materials unlike regular diodes . The choice of semiconductor material determines the wavelength of peak emission of photons and hence the colour of the emitted light . It determines also the forward voltage drop for a given amount of forward conduction current . LED : Light Emitting Diode LEDs are operated from a low voltage DC source VS with a series resistor RS to limit the forward current IF to a suitable value IF from 5.6mA of a status indicator application to 20mA or more where more light output is needed . The resistor value is simply calculated using Ohm ’ s Law : 6 LEDs are intended to operate in forward mode and should not be subjected to reverse voltage and they can be damaged by accidental reverse connection at low supply voltages . If the LED needs to be operated from an AC source or unreliable signal source , it can be protected from reverse polarity by the use of regular diodes . LED : Light Emitting Diode Reverse voltage is limited to 0.6v . No light is emitted for the negative half cycles . 7 A bridge of 4 diodes . Current always flows in the LED in forward polarity . Voltages of diodes ( 1.2v ) should be included in the calculation of RS . 8 LED : Light Emitting Diode The maximum light output from a LED is essentially limited by the maximum average forward current which it can handle . When higher light output is required , it should operate from a pulsed current with higher value and a fairly short duty cycle . This increases current and light output during the pulses while keeping the average current level and power dissipation within its ratings . LED : Light Emitting Diode Advantages of using a pulsed current : The electro-optical efficiency of LEDs increases with current level . Short pulses with higher output result in higher average light output for the same average current . The pulse repetition frequency is higher than the eye ’ s critical fusion frequency . Hence humans can not detect the gaps and the light appears brighter than continuous light . Pulses generated by 555 ( 20 % duty cycle ) to drive the LED directly or via a MOSFET . RS is required here but it should allow a value of current about 100mA 9 10 Laser Diodes ( Injection Lasers ) Laser diodes are a specialized form of LEDs . Like LEDs , they are a form of P-N junction diode with a thin depletion layer where electrons and holes collide to create light photons when the diode is forward biased . The difference is that the active part of the depletion layer ( where most current flows ) is made quite narrow to concentrate the carriers . The ends of this active part is polished or coated with thin reflective layers to act as mirrors , so as to form a resonant optical cavity . The forward current level is increased so as the current density reaches a critical level where “ carrier population inversion ” occurs . More holes than electrons in the conduction band and more electrons than holes in the valence band . Hence , very large excess population of electrons and holes can combine to release photons . New photons can be created by the influence of passing photons and random collision . 11 Laser Diodes ( Injection Lasers ) Hence , laser action is summarized as “ Light Amplification by Stimulated Emission of Radiation ” . The photons triggered by passing photons have the same wavelength and they are in phase with them . They form a continuous-wave coherent radiation . Because of the resonant optical cavity , the photons are able to travel from one end of the active region to the other , triggering the production of more photons and a lot of light energy is generated . At the end of the cavity , some of this coherent light can leave the laser chip to form its output beam . 12 Electrical Operation : Laser Diode vs . LED The electrical operation must be much more carefully controlled than the LED . Laser diode operates at a high current and has a very low forward resistance when lasing action occurs . They are at risk of destroying themselves due to thermal runaway . Operating light density can rise to a level where the end mirrors can begin to melt . The current of the laser diode should be regulated by a constant current circuit rather than a simple series resistance . Also , optical negative feedback must generally be used to ensure that optical output is held to a constant safe level . Photodiodes Photodiodes are light detectors which generate an output proportional to light level when illuminated . Features and characteristics : Low noise Low cost Excellent linearity in output current Fast response time Basic application circuit 13 Electrical Operation : Laser Diode vs . LED To make the optical feedback easier , most laser diodes have monitor diodes built right into the package . monitor diode is a silicon PIN photodiode used to receive a fixed proportion of the laser ’ s output . The output of this monitor diode is used to control the current fed through the laser by the constant current circuit for stable and reliable operation . 14 Electrical Operation : Laser Diode vs . LED Current regulator circuit of laser LEDs : The monitor diode shunts the base forward bias for transistor Q1 ( which has its emitter voltage fixed by a zener diode ) when laser output rises , the monitor diode current increases as well The conduction of Q1 reduces and hence that of transistor Q2 which controls the laser current The laser current is automatically stabilized to a level set by the adjustable resistor VR . 15 Phototransistors Phototransistor is a semiconductor light sensor formed from a basic transistor with a transparent cover . Base current formed by light photons striking its junctions . Common-Emitter amplifier circuit generates an output which transitions from high to low when it is exposed to light . When there is no light , the phototransistor is cut-off and Vout is high due to the pull-up resistor When phototransistor is exposed to light , collector current is generated and it drives the output to low . 16 Phototransistors Common-Collector Amplifier generates an output which transitions from low to high state when light is detected by the phototransistor . When there is no light , the phototransistor is cut-off and the output is low due to the pull-down resistor When there is light , the phototransistor generates collector current which drives the output voltage to high state 17 Phototransistors In both circuits , phototransistor can be used in two modes : An active mode : VCC > RL * ICC Photoresistor generates a response proportional to the received light up to a certain light level . After this level , the phototransistor operates in saturation and output will not increase . This mode is useful in applications where it is desired to detect two levels of input for comparison . A switch mode : VCC < RL * ICC Photoresistor operates either in cut-off or saturation in response to light . This mode is useful when a digital output is required for object detection or encoder sensing . The value of the load resistor RL determines the mode of operation , where RL is the pull-up or pull-down resistor in the previous circuits . 18 Smoke Detector Diodes emit light detected by photo- transistors Q1 & Q2 Top region is sealed , the base of Q1 does not change When smoke enters the lower region , the base of Q2 changes 19 Smoke Detector Due to smoke , the intensity of light decreases , the base current of Q2 decreases and Vin increases . When Vin crosses Vref , the output of the comparator switches from VL to VH which triggers the alarm 20 Temperature-Dependent Current Source LM332 is a 3-terminal adjustable current source . Excellent current regulation wide dynamic voltage range of 1v to 40v current is established with one external resistor It produces output current which is directly proportional to temperature in Kelvin . Kelvin temperature scale is 273 degrees higher than the Celsius scale ( K = C + 273 ) . ● ISET = IR + IBIAS IBIAS is a percentage of ISET 21 Temperature-Dependent Current Source RSET determines the ISET which passes through RL . For RSET = 230Ω and RL = 10kΩ , we calculate : 22 Temperature-Dependent Current Source This circuit converts the temperature-dependent current ( ISET ) into a temperature-dependent voltage ( VOUT ) . ISET ( passing through R1 ) = 0.987µA/k R3 is a series resistance with the output where its value is around ( R2/16 ) to reduce R2 value by a factor of 5 . VR = 0.987µA * 10230 ≅ 0.01v/k VOUT = ( 0.01 * 10830 ) /10230 ≅ 10mv/k 23 Temperature-Dependent Current Source Determine the output voltage produced by a temperature of 100F or higher . Temp_k = ( ( 100F - 32 ) * 5/9 ) + 273 = 311 VOUT = 10mv * 311 = 3.11v Any output voltage equal to or greater than 3.11 v corresponds to a temperature of 100F or higher . 24 Design Example : Temperature Comparator Design a circuit that produces a 600 Hz warning tone if the temperature exceeds 100F . Required elements of the circuit : LM334 temperature-dependent current source as a temperature sensor . Op amp comparator which compares the sensor voltage with a reference voltage equivalent to 100F A speaker connected to a 555 timer to generate the warning tone . 555 timer generates pulses of various durations and adjustable pulse width and frequencies . The output toggles between high and low in response to inputs . 25 CTRL VOLTAGE : controls the threshold and trigger levels . It determines the pulse width of the output waveform . For reliable operation , connect it to GND through small capacitance . RESET : negative pulse applied to this pin to disable the timer ( forces output to low ) . Connect it to Vcc when not used . THRESHOLD : compares the voltage applied to the terminal with a Vref of 2/3 Vcc and resets the timer when output exceeds this value . TRIGGER : the output depends on the amplitude of the external trigger pulse applied to this pin . When pin voltage falls below ⅓ of Vcc , the timer output goes high . DISCHARGE : open collector output discharges a capacitor between intervals . It toggles its output from high to low when voltage reaches 2/3 Vcc . Design Example : 555 Timer 26 Design Example : 555 Timer By wiring 555 timer with resistors and capacitors in various ways , it can operate in different modes : monostable mode : creates time delay . A trigger outputs a pulse of adjustable duration . astable mode : outputs an oscillating pulse at tunable frequency and pulse width . bistable mode : toggle its output between high and low states depending on the state of two inputs In our design example , we are interested in astable mode to operate the alarm at a frequency of 600 Hz . 27 Design Example : 555 Timer The output frequency is adjusted by the external RC circuit ( R1 , R2 and C1 ) In the astable mode , it is necessary to continuously re- trigger the timer after each time cycle . The retriggering is done by connecting the trigger input and the threshold input together . Hence , the timer has no stable state and it continuously switches from one state to another . C1 charges itself through R1 and R2 , but discharge through R2 ( connected to discharge pin ) . 28 Design Example : Circuit If the temperature exceeds 100F , V+ will be greater than V- and the output of the op amp will be pulled high . 555 timer will begin oscillating which allows the speaker connected to the output to produce the warning tone . 29 30 ON/OFF Control of Analog Devices Many real-world devices require large control voltages and currents incompatible with TTL and CMOS outputs of a typical digital circuit . 5-v 100-mA DC relays 12-v 2-A indicator lamps 20-to 30-v DC pulses for EPROM programmers Driver circuits using open-collector transistor ( such as standard 7400 family TTL open-collector buffers ) can be used : When the device to be controlled requires DC When the control voltage and currents are not too high TTL 7406 features high-voltage open-collector output for interfacing with high-level circuits or for driving high-current loads . It withstands voltages as high as 30v and sink currents as large as 40mA . High-level input drives the output to low-level which turns ON the controlled device . When the output is high , the output becomes an open circuit and the controlled device goes off . When output is low , 7406 must sink the device ’ s ON current without overheating or allowing its VOL level to rise above few tenths of a volt . When the output is an open circuit , the controlled device acts like a pull-up resistor . The output transistor of 7406 must then be capable of withstanding the supply voltage without breaking down . Examples : Driver Circuits using 7406 inverting buffer 31 The driver circuit of a lamp requires the use of two 7406 inverters in parallel . This is necessary because the lamp ’ s ON state current exceeds that of a single 7406 Sink current of 7406 is 30-40 mA . Examples : Driver Circuits using 7406 inverting buffer 32 Examples : Driver Circuits using 7406 inverting buffer A relay is an electromagnetic switch operated by a relatively small electric current that can turn on or off a larger electric current It consists of a coil of wire that becomes a temporary magnet when electricity flows through it Relays operate as bridge between sensitive electronic devices that produce small amounts of current ( such as sensors ) and controlled devices that uses larger currents . 33 Electromagnetic devices ( such as a relay ) store energy when powered and will generate a “ back EMF ” when the supply is switched off . EMF ( ElectroMotive Force ) is the voltage produced by the interaction of current in the coil of the electro- magnet field and its magnetic field when one or both is changing . When the electromagnet is disconnected , it acts like a current source building whatever voltage is necessary to keep the original current flowing . If the back EMF is not controlled , then the generated voltage may reduce the performance of the circuit or even damage its elements . Examples : Driver Circuits using 7406 inverting buffer 34 The relay driver circuit uses a clamp diode to protect the output transistor of 7406 from back EMF . When the 7406 output is low , the relay conducts , and the diode is reversed biased ( cut-off ) . When the output is high , the relay disconnects and it generates back EMF in the opposite polarity . The diode conducts and clamps the voltage to around 0.6v . Hence , the output pin clamps to a voltage a little bit less than the power supply . Examples : Driver Circuits using 7406 inverting buffer 35 Peripheral Drivers Peripheral drivers are general-purpose drivers with the following characteristics : They are used for applications which require high currents and voltages . They are available in many models and logic functions ( INV , AND , NAND , OR , NOR ) . They have outputs rated as high as 80v and 1.5A . They may include built-in clamp diodes to protect their outputs . They may be input-compatible with TTL and CMOS logic families . SN75447 is a dual peripheral NAND driver 36 Peripheral Drivers : Lamp Driving Application 37 The control of a high-current lamp requires peripheral driver with a “ warm-up ” circuit . The cold resistance of a lamp can be as much as 10 times less than its hot resistance . Initial current passing through the lamp could be large enough to damage it . SN75447 peripheral driver is used in this application . Both NAND gates of this driver are used . When input control is active , only Q1 is on . Q2 is off due to the capacitor until it is charged . The Q1 current is limited by the 18Ω resistor . When the capacitor charges , Q2 turns ON and the load current is shifted to this transistor . During this time , the lamp heats up and its resistance increases . 38 Peripheral Drivers : ‘ H ’ Motor Drive Circuit In this application , we use an H Bridge to fully control and drive a DC motor . We use SN75449 peripheral driver with NOR gates , to provide three modes of operation : Peripheral Drivers : ‘ H ’ Motor Drive Circuit Enable = H. transistors of driver are on and inputs of bridge are low ( current sink ) . Enable = L , Direction = L , pin 6 is open circuit . Inputs 3 and 4 of bridge are pulled high and current flows in motor in B direction . Enable = L , Direction = H , drivers 1 and 2 of bridge are enabled and current flows in the A direction , which reverses the rotation direction of the motor . ≣ 39 1 AC Control Analog Interface Electromechanical Relays ( EMR ) EMR consists of : an electromagnetic coil a moving arm and spring a set of switched contacts ( normally open “ NO ” or normally closed “ NC ” ) When current passes through the coil , a magnetic field is developed that attracts the moving arm . This opens the NC contacts and closes the NO contacts . The relay can be operated by AC or DC at a particular voltage . The coil has a specific resistance and the switched contacts carry a voltage and current ratings . 2 3 Electromechanical Relays ( EMR ) It is important to match the output current and voltage capabilities of the driver circuit to the coil of the relay . Depending on the resistance of the coil , it may be possible to drive these relays with a standard TTL gate . Disadvantages : Pitting and corrosion of the switched contacts Contact bounce Slow operation 4 Solid-State Relays ( SSRs ) It is a relay that consists of : a sensor which responds to a control signal a solid-state electronic switching device which switches power to the load circuitry a coupling mechanism to enable the control signal to activate this switch without mechanical ( moving ) parts . There are two types based on the isolation between the control switch input and the solid-state output : Isolated SSR ● Nonisolated SSR The nonisolated SSR consists of : a peripheral driver to control the current flow through a diode bridge . 2N4992 AST ( Asymmetrical Trigger ) . A solid-state bilateral switch on-state current is 200mA Forward voltage = 1.7v off-state current is 0.1µA @ 5v A TRIAC ( stands for “ TRIode for AC ” where triode is a transistor ) It has 3 terminals : Gate ‘ G ’ and Main Terminals MT1 & MT2 It is related to SCR rectifiers . 5 Solid-State Relays ( SSRs ) Silicon Controlled Rectifier ( SCR ) Silicon : a multi-layer semiconductor device Four layer ( P-N-P-N ) semiconductor device that contains 3 P-N junctions in series . Controlled : it requires a gate signal to turn it ON . Controlled by gate current . Rectifier : an electronic device that converts AC current to DC . Applications : Power semiconductor devices ( such as SCR and TRIACs ) are very fast solid state AC switches for controlling large AC voltages and currents such as lamps , AC motors and phase control applications . 6 Silicon Controlled Rectifier ( SCR ) 7 Functionality : Regenerative feedback : IC of transistor TR2 feeds directly the base of TR1 and IC of TR1 feeds the base of TR2 . Until one of the transistors is given some base current , nothing can happen even if an Anode-to-Cathode voltage is present . Anode is -ve w.r.t . Cathode : center NP is forward biased and the outer junctions are reversed biased . SCR blocks reverse current unless breakdown voltage point of the outer junctions is exceeded and the SCR conducts without the application of a Gate signal . Anode is +ve w.r.t.Cathode : outer PN junctions are forward biased but the centre NP junction is reverse biased . forward current is blocked . If a +ve current is injected into IB of TR2 , its IC flows in the base of TR1 . This causes a IC to flow in TR1 which increases the IB of TR2 and so on . 8 Silicon Controlled Rectifier ( SCR ) Unlike transistors , SCR can not be biased to stay within some active region between its cutoff and saturation states . Very rapidly , the two transistors force each other to conduct to saturation due to regenerative feedback . Once triggered , the current flowing through the device can be limited only by external resistance . Any gate signal applied after conduction has no effect on SCR since it is fully on . It is not possible to turn an SCR off by its gate signal . There are two ways : either by removing the supply voltage and therefore the Anode current completely , or by reducing its Anode to Cathode current by some external means to below a value commonly called the “ minimum holding current ” , IH . So as internal PN-junctions can recover their blocking state . TRIAC is a component that conducts current in either directions when triggered : It turns on by applying a gate current It turns off when voltage across TRIAC becomes 0v . TRIAC is capable of conducting positive and negative half period of an alternating current , provided that the gate current also alters its direction . TRIACs are related to Silicon Controlled Rectifiers “ SCR ” . SCR is a unidirectional device that only conducts current in one direction . SCR can be triggered by a positive current at its gate only . 9 TRIAC DIAC DIAC stands for DIode for AC . It is a bi-directional switch that is used with TRIACs to improve operation of AC power switching systems . Unlike TRIACs , DIACs have no gate to control its conduction It conducts after a 'breakdown ' voltage is exceeded . Similarities to TRIACs : a semiconductor switch that is turned on in both forward and reverse polarities . 10 DIAC functional Analysis : DIAC starts to conduct when the supply voltage reaches the breakover voltage ( ≅32v ) . Even when the supply voltage becomes less than 32V , the DIAC remains conductive . The DIAC only closes , when the supply voltages becomes 0V . The DIAC also works for negative voltages . Hence , a DIAC does n't have an anode and cathode like a normal diode . 11 DIAC When a DIAC conducts , it enters the region of negative dynamic resistance . When the source voltage increases the voltage drop across the DIAC decreases . Hence , a sharp increase in the level of current that is conducted by the device is achieved . Below the holding current , the DIAC reverts to its high-resistance ( non-conducting ) state . DIACs are called symmetrical triggers due to the symmetry of their characteristic curve . 12 13 DIAC and TRIAC Typically the DIAC is placed in series with the gate of a TRIAC . TRIACs do not fire symmetrically as a result of slight differences between the two halves of the device . This results in harmonics being generated . Switching characteristic of DIACs is more even than TRIACs . DIAC prevents any gate current flowing until the trigger voltage has reached a certain voltage in either direction , this makes the firing point of the TRIAC more even in both directions . DIACs and TRIACs As the AC supply voltage increases at the beginning of the cycle , C is charged . When the charging voltage reaches the breakover voltage of the diac , the diac breaks down and C discharges through the diac , producing a sudden pulse of current , which fires the triac into conduction . While conduction , the voltage across the resistor–capacitor combination is limited by the “ ON ” voltage of the triac . At the end of the half cycle the supply voltage falls to zero , reducing the current through the triac below its holding current , IH turning it “ OFF ” and the diac stops conduction . 14 When ON : Current passes through the peripheral driver , transistor and the diode bridge . A voltage develops across 0.1µF capacitor . The 2N4992 asymmetric trigger produces current enough to con- duct the TRIAC when the voltage at the capacitor reaches the trigger threshold . The TRIAC conducts and a current passes through its terminals ( almost a short circuit ) Because the TRIAC conducts in both directions , MT2 and MT1 resemble the normally-open contacts of EMR . 15 Non-Isolated Solid-State Relays 16 Non-Isolated Solid-State Relays Advantages of SSRs : No moving parts , no contact bounce , fast operation ( < 1µs ) , TTL level control and a logic gate input . It eliminates the transients that would be produced by an abrupt turnoff . Because once the SSR conducts , it remains ON until a zero crossing of the line voltage ( regardless of the control signal ) . Ideal for AC control applications Disadvantages of SSRs : High voltage transients can destroy TRIAC and this circuit is directly connected to AC source where these transients are initiated . No isolation between the control circuit ( peripheral driver ) and the 120-v source . If TRIAC fails , the peripheral driver could be destroyed and AC could pass to the digital control circuit . Isolated Solid-State Relays 17 18 Isolated Solid-State Relays An improved SSR that includes : A snubber circuit which consists of a resistor and a capacitor that are placed across the power switches to suppress voltage spikes and transients . It also damps the ringing caused by circuit inductance when the power switches . An optocoupler ( MOC3011 ) to isolate the control circuit from the controlled circuit . It consists of an Infrared-Emitting LED ( IRED ) and an SBS ( Silicon Bilateral Switch ) . The digital input is protected against excessive currents and voltages by D1 and Q1 . 19 Isolated Solid-State Relays Functionality : When both inputs of the peripheral driver are high , its output transistor turns on which allows a current to flow through IRED and the 47-Ω resistor . The light emitted by the IRED triggers the SBS into conduction . SBS triggers the TRIAC into conduction . The advantage of this design is the isolation between the load ( and the AC signal ) and the control circuit . SSR chips are available and selected devices can handle voltages as high as 280-v AC at 25A . Explain the operation of this SSR circuit . Calculate the range of values of RL which guarantees the functionality of this circuit . RL 20 EXAMPLE",
    "علوم-الحياة-1920-1-اللغة-العربية.txt": "ﻢﺣﺎﺿﺭﺎﺗ ﻒﻳ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳﺓ ﺎﻋﺩﺍﺩ ﻼﻣﺩﺮﺳ ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﻖﺴﻣ ﻊﻟﻮﻣ ﻼﺤﻳﺍﺓ ﻚﻠﻳﺓ ﻼﺗﺮﺒﻳﺓ ﻞﻠﻌﻟﻮﻣ ﻼﺻﺮﻓﺓ ( ﺎﺒﻧ ﻼﻬﻴﺜﻣ ) ﺝﺎﻤﻋﺓ ﺐﻏﺩﺍﺩ ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻼﻤﻗﺪﻣﺓ ﻥ، ﻭﻼﺼﺒﻟﺓ ﻭﻼﺴﺒﻠﻣ ﻊﻤﯨ ﻢﺤﻣﺩ ﻮﻌﻤﯨ ﻵﻭ ﻥﻭﺭ ﻼﻴﻘﻳ ﺱﺭﺎﺟ ﻼﺤﻗ ﻭ ﻡﺩ ﻪﻠﻟ ﻻﺬﻳ ﻯﺪﯨ ﻺﯨ ﻼﺣ ﺲﻤﻣ . ﻮﺼﺤﺑﻭ ﻭ ﺐﻳﺍ ﻒﻛﺄﻨﻣﺍ ﺎﺴﺘﻳﺎﻧ ﺏﺍﻸﻣﺓ ﺲﺘﻳﺎﻧ ﻥ ﺃ ، ﻒﻣ ﺄﻨﻔﺳﻭ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ﻰﻳ ﺄﻌﻈﻣ ﺕﺭﺎﺛ ﻼﻋﺮﺑ ﻭﺄﻗﺪﻣﻭ ﻭ ﺩﺮﺠﺗ ﻒﻳ ﻢﻀﻣﺍﺭ ﻼﺤﺿﺍﺭﺓ ﻭﻼﺘﻗﺪﻣ ﺇﻻ ، ﻒﻣﺍ ﻢﻧ ﺄﻣﺓ ﻸﻴﻣ ﺞﺴﻴﻣ ﻮﯩﻣ ﻊﻈﻴﻣ ﻭ ﺬﻠﻛ ﺬﻨﺑ ﻼﻋﺮﺒﻳﺓ ﻦﻔﺴﻳﺍ، ﻭ ﺄﻋﺎﻨﺘﻳﺍ ﻊﻤﯨ ﻼﺘﻌﺒﻳﺭ ﻒﻳ ﺄﺳﻼﻴﺑ ﻭ ﻢﺼﻄﻤﺣﺎﺗ ﺎﻌﺘﻨﺗ ﺐﻤﻐﺘﻳﺍ، ﻭﺎﯩﺘﻤﺗ ﺐﻓﺭﻮﻌﻳﺍ ﻢﻧ ﻦﺣﻭ ، ﻮﺻﺮﻓ ﻭ ، ﻸﻧ ﻼﻤﻏﺓ ﻊﻧﻭﺎﻧ ﺶﺨﺼﻳﺓ ﻢﺟﺍﻼﺗ ﻼﺤﻳﺍﺓ ﻙﺎﻓﺓ، ﺱﻭﺍﺀ ﻒﻳ ﻼﺗﺍﺮﻴﺧ ﺄﻧ ﻒﻳ ﺍﻵﺩﺎﺑ ﺄﻣ ﻒﻳ ﻼﻌﻣﻮﻣ ﻼﻤﺨﺘﻤﻓﺓ ﺥﺫ ﻒﻳ ﻊﻤﻤﻳﺓ ﻼﺘﻃﻭﺭ ﻻ ﺖﻘﻓ ﻊﻧﺩ ﺡﺩﻭﺩ ﻢﻌﻴﻧﺓ، ﺇﺫ ﺕﺃ ﺎﺠﺘﻣﺎﻌﻳﺓ ﺖﺗﺄﺛﺭ ﺐﻧﻭﺍﺰﻋ ﻼﺤﻳﺍﺓ، ﻭ ﻰﻳ ﻅﺎﯨﺭﺓ ﺍﻸﻣﺓ ﻭ ﻙ ﻼﺘﻳ ﻞﻳﺍ ﺺﺒﻠﺗ ﺍﻼﺠﺘﻣﺎﻌﻳ ﻢﻣﺍ ﻲﺳﺎﻋﺪﯨﺍ ﻞﻣﻭﺎﻜﺑﺓ ﻼﻌﺻﺭ ﻢﻧ ﺩﻮﻧ ﺎﻨﻘﻃﺎﻋ ﻞﺟﺫﻭﺮﯨﺍ ﻼﺗﺭﺎﺜﻳﺓ ﻼﺴﻴﻣﺍ ﺖﻣ ﺲﺒﻠﻣﺓ ﻢﻨﻴﺠﻳﺍ، ﻲﻗﻮﻟ ﻼﻌﺒﻠﻣﺓ ﺕ ﺺﻳﺎﻏﺓ ﺲﻤﻴﻣﺓ ﺕﺪﻟ ﻊﻤﯨ ﺄﺻﻼﺘﻳﺍ ﻭ ﺺﻳﺎﻏﺓ ﻼﻌﺑﺍﺭﺍ ﺐﺗﺭﺎﻜﻴﺑ ﻼﺠﻤﻟ ﻭ ﻸﻣﺓ ﻙﺮﻴﻣﺓ ﻊﻈﻴﻣﺓ ﻮﻗﺩ ﺡﺎﻔﻈﺗ ﻊﻈﻴﻣﺓ ﻕﻮﻴﻣﺓ ﻼﻋﺮﺒﻳﺓ ﻞﻏﺓ ﺞﺴﻴﻣﺓ ﻭ « ﻼﻣﺮﺣﻮﻣ ﻻﺪﻜﺗﻭﺭ ﻢﺼﻄﻔﯨ ﺝﻭﺍﺩ » . ﺕﺭﺎﺜﻳﺍ ﺍﻷﺪﺒﻳ ﻼﺑﺍﺮﻋ ﻊﻤﯨ ﻕﻭﺎﻤﻳﺍ ﻮﻨﻇﺎﻤﻳﺍ ﻮﻜﺒﻠﻤﻳﺍ ﺐﻗﺭﺂﻨﻳﺍ ﻼﻋﺰﻳﺯ ﻭ ﻼﻤﻌﻨﯨ ﺃﻭ ﻻﺮﺴﻣ ﺃﻭ ﺍﻼﺴﺘﻌﻣﻻ، ﺄﻳ ﻼﺨﻃﺃ ﻒﻳ » ﻼﻤﺤﻧ « ﺏﻻﺮﻐﻣ ﻢﻧ ﺖﻤﻛ ﺍﻸﺻﻻﺓ ﻒﻗﺩ ﺄﺻﺎﺒﻳﺍ ﻭ ﻥ ﻁﺮﻴﻗ ﻢﻏﺎﻳﺭﺓ ﻞﻳﺍ ﺃﻭ ﻉ ﻞﻤﻏﺎﺗ ﺃﻭ ﻊﻧ ﻁﺮﻴﻗ ﻼﺗﺮﺠﻣﺓ ﻢﻧ ﻞﻏﺓ ﻼﺗﺄﺜﻳﺭ ﺐﻴﻧ ﺍ ﻊﻧ ﻁﺮﻴﻗ ﻼﺗﺄﺛﺭ ﻭ ﺬﻠﻛ ﻭ ﺭﺪﻧﺍ ﺐﻌﺿﺍ ﻢﻧ ﻼﻤﺑﺎﺤﺛ ﻼﻤﻏﻮﻳﺓ ﻭﻼﻨﺣﻮﻳﺓ ﻒﻳ ﻯﺫﺍ ﻼﻌﻤﻟ ﻼﻤﺗﻭﺎﻀﻋ ﺃﻭ ﻼﺘﻃﻭﺭ ﻻﺩﻼﻠﻳ ﻞﻤﻜﻤﻣﺓ . ﻭ ﻯﺬﻫ ﻞﻴﺴﻳﺭ ﻭ ﻝﻭ ﺏﻼﻧﺯﺭ ﺍ ﻥ ﻱﺭﻮﻣ ﺾﺒﻃ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ﻭ ﺍﻼﻤﺒﻠﺌﻳﺓ ﻞﺘﻛﻮﻧ ﺖﺤﺗ ﺄﻳﺪﻳ ﻚﻟ ﻡ ﻭﺍﻼﺴﻣﻮﺒﻳﺓ ﻭ ﻼﻤﺑﺎﺤﺛ ﻰﻳ : ﻼﻋﺮﺒﻳﺓ ﻉﻼﻣﺎﺗ ﻼﺗﺮﻘﻴﻣ ﻒﻳ ﻼﻤﻏﺓ ﻼﻤﺒﺤﺛ ﺍﻷﻮﻟ : ﻚﺗﺎﺑﺓ ﻼﻬﻣﺯﺓ ﻒﻳ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ﻼﻤﺒﺤﺛ ﻼﺛﺎﻨﻳ : ﺍﻼﻏﻼﻃ ﻼﻤﻏﻮﻳﺓ ﻼﺷﺎﺌﻋﺓ ﻒﻳ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ﻼﻤﺒﺤﺛ ﻼﺛﻼﺛ : ﻚﺗﺎﺑﺓ ﻼﺿﺍﺩ ﻭﻼﻇﺍﺀ ﻒﻳ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ﻼﻤﺒﺤﺛ ﻻﺭﺎﺒﻋ : 1 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻢﻣﺎﺗ ﻯﻭ ﻮﻀﻋ ﻊﺒﻠﻣﺎﺗ ﺎﺼﻄﺒﻠﺤﻳﺓ ﻒﻳ ﻼﻣﻭﺎﻀﻋ ﻼﺼﺤﻴﺣﺓ ﺐﻴﻧ ﻼﺠﻤﻟ ﺃﻭ ﻼﻛ ﻉﻼﻣﺎﺗ ﻼﺗﺮﻘﻴﻣ : ﻼﻌﺒﻠﻣﺎﺗ ﺐﺘﺣﺪﻳﺩ ﻡﻭﺎﻀﻋ ﻻﻮﻘﻓ، ﻭﻼﻔﺼﻟ، ﻭﻻﻮﺼﻟ، ﻼﻔﻴﻣ، ﺇﺫ ﺖﻗﻮﻣ ﻯﺬﻫ ﺍﻺﻔﻳﺎﻣ ﻭ ﻞﺘﺳﺎﻋﺩ ﻊﻤﯨ ﺖﺤﻘﻴﻗ ﻸﻏﺭﺎﺿ ﻼﻜﺗﺎﺑ، ﻒﺘﺳﺎﻋﺩ ﻊﻤﯨ ﺇﺩﺭﺎﻛ ﻼﻤﻌﻨﯨ ﻮﺘﻤﺜﻣﻭ، ﺖﻧﻮﻴﻋ ﻼﻨﺑﺭﺎﺗ ﻼﺻﻮﺘﻳﺓ ﻞﻤﻗﺍﺮﺋ ﻮﻔﻗﺍ ﻭﺍﻼﺒﺗﺩﺍﺀ، ﻭ ﻰﻳ ﻒﻳ ﻻﻮﻘﺗ ﻦﻔﺳﻭ ﺐﻌﺿ ﻼﺑﺩﺎﺌﻟ ﻼﺘﻳ ﻲﺴﺘﻌﻤﻤﻳﺍ ﻼﻛﺎﺘﺑ ﻞﻜﺛﺭ ﻢﻧ ﻮﻌﻤﯨ ﻒﻴﻣ ﻼﻌﺒﻠﻗﺎﺗ ﺐﻴﻧ ﻼﺠﻤﻟ . ﻭ ﻎﻳﺭ ﺬﻠﻛ ... ﻙﺎﻧ ﻢﺘﺣﺪﺛﺍ : ﻢﻧ ﺡﺮﻛﺓ ﻼﻳﺪﻴﻧ، ﻭﻻﺭﺄﺳ، ﻮﻨﺑﺭﺎﺗ ﻼﺻﻮﺗ، ﻭ ﻺﻤﻛﺎﻨﻳﺎﺗ ﻼﻤﺗﻮﻓﺭﺓ ﻝﺪﻳﻭ ﻝﻭ ﺍ ، ﺇﺫ ﺄﻧﻭ ﻲﻨﺴﻗ ﻼﻣﺍﺩﺓ ﻢﻔﻳﺩ ﻲﺣ ﻭ ﻼﻗﺭﺍﺀﺓ ﺐﺸﻜﻟ ﺺﺣ ﻒﻴﻳ ﺖﻨﻈﻴﻣ ﻼﻜﺗﺎﺑﺓ ﻭ ﺄﻣﺍ ﻮﻈﻴﻓﺓ ﻉﻼﻣﺎﺗ ﻼﺗﺮﻘﻴﻣ : ﻊﻤﯨ ﺕﻮﻀﻴﺣ ﻲﺳﺎﻋﺩ ﻼﻜﺗﺎﺑ ﻯﻭ ﺐﻳﺫﺍ ﻲﺧﺪﻣ ﻊﻤﻤﻳﺓ ﻒﻴﻣ ﻼﻤﻗﺭﻭﺀ؛ ﻑ ﻭﻭﺎﻀﺣﺓ ﻭ ﻲﺠﻌﻤﻳﺍ ﻡﺆﺛﺭﺓ ﻮﻴﻨﻈﻤﻳﺍ ﻭ ﻲﺳﺎﻋﺩ ﻼﻗﺍﺮﺋ ﻊﻤﯨ ﻒﻴﻣ ﻡﺍ ﻱﺮﻳﺩ ﻼﻛﺎﺘﺑ . ﺄﻔﻛﺍﺮﻫ ﻮﺠﻌﻤﻳﺍ ﻡﺆﺛﺭﺓ ﻭ ﻊﻤﻳﻭ ﻒﻤﻧ ﻼﺿﺭﻭﺮﻳ ﺝﺩﺍ ﺍﻼﯩﺘﻣﺎﻣ ﺐﻠﻗﺓ ﻮﺜﻴﻗﺓ ﺏﻼﺣﺮﻛﺎﺗ ﺍﻺﻋﺭﺎﺒﻳﺓ ﻭﻼﻔﻴﻣ، ﻭ ﻞﻤﺗﺮﻘﻴﻣ ﻉ ﻭ ﻚﺑﺍﺭﺍ . ﻢﻣﻮﺳﺓ ﺐﺴﺒﺑ ﺈﯩﻣﻻﻭ ﻝﺪﯨ ﻼﻜﺗﺎﺑ ﻭﻼﻗﺭﺍﺀ ﺺﻏﺍﺭﺍ ﻭ ﻼﻣ ﻡﻮﺿﻮﻋ، ﻹﺯﻻﺓ ﻼﺨﻃﻭﺭﺓ ﻼﺣﺎﺼﻣﺓ ﻭ ﺏﻻ ﻮﺴﻤﻣ ﻊﻧﺪﻣﺍ ﻰﺒﻃ ﺺﺤﺑﻭ ﻵﻭ ﻭ ﺡﺪﻴﺛ ﺮﺳﻮﻟ ﺎﻬﻠﻟ ﺺﻤﯨ ﺎﻬﻠﻟ ﻊﻤﻳﻭ ﻭ ﻡﺍ ﻲﻔﻴﻣ ﻢﻧ ﺲﺒﻴﻟ ﻼﻤﺛﻻ ﻒﻌﻤﯨ ) ﻻ ﻲﻋﺮﻓ ﻼﻗﺭﺍﺀﺓ  ﺏﺄﻧ ﻻﺮﺳﻮﻟ ( » ﻡﺍ ﺄﻧﺍ ﺐﻗﺍﺮﺋ ؟  ) « ﻑﺄﺟﺎﺑﻭ ﻻﺮﺳﻮﻟ ( ! ﻊﻤﻳﻭ ﻻﻮﺤﻳ ﻮﻗﻻ ﻝﻭ ﺎﻗﺭﺃ ﻼﺗﺮﻘﻴﻣ ﻒﺠﻌﻣﻭﺍ ( ﻡﺍ ﻥﺎﻔﻳﺓ ) ﻰﻧﺍ ﻮﻠﻜﻧ ﻝﻭ ﻮﻀﻌﺗ ﻲﻋﻭﺩ ﻼﺴﺒﺑ ﻒﻳ ﺬﻠﻛ ﻺﯨ ﻼﺠﻴﻟ ﺐﻌﺒﻠﻣﺎﺗ ﻭﻼﻜﺗﺎﺑﺓ ﻭ ﺏﺬﻠﻛ ﻦﻨﻛﺭ ﻡﺍ ﻢﻌﻨﯨ ﺐﺼﻴﻏﺓ ﺍﻼﺴﺘﻔﻳﺎﻣ ﻻ ﻼﻨﻔﻳ ﻭ ﻰﻳ ﺎﺣﺪﯨ ﻊﺒﻠﻣﺎﺗ ﻼﺗﺮﻘﻴﻣ ﻸﺼﺒﺣ ﻻ ﺍﻼﺴﺘﻔﻳﺎﻣ ﻭ ﻊﺒﻠﻣﺓ ﻼﻜﺗﺎﺑﺓ . ﻱﺓ ﻼﻌﻈﻴﻣﺓ ﻢﻧ ﻼﺠﻴﻟ ﺏﻼﻗﺭﺍﺀﺓ ﻭ ﺺﺨﻠﺷ ﻦﺴﺑ ﻺﯨ ﻯﺬﻫ ﺍ ﻊﺒﻠﻣﺎﺗ ﻼﺗﺮﻘﻴﻣ ﻰﻳ : ﻭ ﺖﺴﺘﻌﻤﻟ ﻒﻳ ﻼﻣﻭﺎﻀﻋ ﺍﻶﺘﻳﺓ : ﻭ » ، « ﻰﻛﺫﺍ ﺕﺮﺴﻣ ﻭ » ﻼﻓﺍﺭﺯﺓ « ﻼﻓﺎﺼﻣﺓ 1- ﻭﺎﻀﻋﻭ، ﻚﺒﻠﯩﻣﺍ ﻒﻳ ﻚﺑﺭ ﻼﺟﺎﯩﻟ ﻚﺗ « ﻥ ﻖﺼﻳﺮﺘﻴﻧ ﻢﺘﺼﻤﺘﻴﻧ ﺏﻼﻤﻌﻨﯨ ﻢﺜﻟ : ﻼﻓﺎﺼﻣﺓ ﺐﻴﻧ ﺞﻤﻤﺘﻳ - ﺃ » . ﻎﻳﺭ ﻡﻮﺿ ﻉﻭ ﺐﻋﺩ ﻼﻤﻧﺍﺪﯨ ﻢﺜﻟ : ﻱﺍ ﺶﻌﻴﺑ ﻼﻋﺭﺎﻗ، ﻚﻧ ﻱﺩﺍ ﻭﺎﺣﺩﺓ . - ﺏ 2 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺄﺻﺎﺒﺘﻧﺍ ﺲﻧﻮﻧ ﺚﺒﻠﺛ : ﺲﻧﺓ ﺃﺫﺎﺒﺗ ﻼﺸﺤﻣ، ﻮﺴﻧﺓ ﺄﻜﻤﺗ ﻼﻤﺤﻣ، ﻮﺴﻧﺓ « ﻱﺀ ﻢﺜﻟ : ﺐﻴﻧ ﺄﻘﺳﺎﻣ ﻼﺷ -ـﺟ ﺖﺴﺘﻌﻤﻟ ﺐﻴﻧ ﻼﺠﻤﻟ ﻼﻃﻮﻴﻣﺓ ﻼﺘﻳ ﺖﻛﻮﻧ ﺈﺣﺩﺎﯩﻣﺍ ﺱ ﻭ » ؛ « ﻮﺗﺮﺴﻣ ﻰﻛﺫﺍ ﺐﺑﺍ » . ﺪﻘﺗ ﻼﻌﻈﻣ ﻼﻤﻨﻗﻮﻃﺓ، ﻼﻓﺎﺼﻣﺓ 2- ﺯﺍﺯ؛ ﻸﻨﻳﺍ ﻞﻏﺓ ﻼﻗﺭﺂﻧ ﻼﻛﺮﻴﻣ؛ ﻮﻠﻏﺓ ﻼﻌﻣﻮﻣ ﻭﻼﻔﻧﻮﻧ ﻭ ﻦﻌﺗﺯ ﺐﻳﺍ ﻍﺎﻳﺓ ﺍﻼﻌﺗ ﻞﺒﻠﺧﺮﯨ ﻢﺜﻟ : `` ﻦﺤﺑ ﻞﻐﺘﻧﺍ ﻭ ﻡ ﻼﻤﻌﻨﯨ ﻢﺜﻟ : ﺇﺫﺍ ﺄﺻﺎﺒﻛ ﻼﺠﻤﻣﺓ ﻊﻧﺩ ﺖﻣﺍ ﻒﻳ ﻦﻳﺎﻳﺓ ﻼﻌﺑﺍﺭﺓ ﻭ ﺕﻮﻀﻋ ﻭ » . « ﻮﺗﺮﺴﻣ ﻰﻛﺫﺍ » . ﺍﻵﺩﺎﺑ ﻼﻨﻘﻃﺓ، 3- .ﻭ ﻑﺎﻜﻈﻣ ﻼﻐﻴﻇ ﺕﻮﻀﻋﺎﻧ ﻒﻳ ﻼﻣﻭﺎﻘﻋ ﺍﻶﺘﻳﺓ ﻒﻳ ﻼﻜﺒﻠﻣ : ﻼﻨﻘﻄﺗﺎﻧ ﻻﺭﺄﺴﻴﺗﺎﻧ، ﻮﺗﺮﺴﻣﺎﻧ ﻰﻛﺫﺍ ﻭ » : « 4- » . ﺈﻨﻛ ﻞﻌﻤﯨ ﺦﻤﻗ ﻊﻈﻴﻣ « ﺎﻬﻠﻟ ﺖﻋﻼﯨ : ﻢﻗﻮﻟﻭ ﻢﺜﻟ : ﻕﻻ ﺐﻋﺩ ﻼﻗﻮﻟ، ﺄﻳ ﺐﻴﻧ ﻼﻗﻮﻟ ﻭ - ﺃ ﺙﺓ ﺄﻘﺳﺎﻣ : ﺎﺴﻣ، ﻮﻔﻌﻟ، ﻼﻜﺒﻠﻣ ﻊﻤﯨ ﺚﺒﻟ ﻼﺘﻔﺴﻳﺭ ﻢﺜﻟ : ﻲﻘﺴﻣ ﺐﻴﻧ ﻼﺸﻳﺀ ﻭﺄﻘﺳﺎﻣﻭ، ﻞﻏﺮﺿ ﻼﺷﺮﺣ ﻭ - ﺏ . ﺡﺮﻓ ﻭ ﻡﺓ ﺍﻼﺴﺘﻔﻳﺎﻤﻳﺓ، ﻢﺜﻟ : ﻡﺍ ﻊﻤﻤﻛ ؟ ﺕﻮﻀﻋ ﺐﻋﺩ ﻼﺠﻣ ﻭ » ؟ « ﻊﺒﻠﻣﺓ ﺍﻼﺴﺘﻔﻳﺎﻣ، ﻮﺗﺮﺴﻣ ﻰﻛﺫﺍ 5- ﺭ ﻼﺠﻤﻣﺓ ﻼﺘﻳ ﺖﻌﺑﺭ ﻊﻧ ﺍﻺﻌﺟﺎﺑ ﻭ ﺕﻮﻀﻋ ﻒﻳ ﺂﺧ « ! » ﻊﺒﻠﻣﺓ ﻼﺘﻌﺠﺑ، ﻮﺗﺮﺴﻣ ﻰﻛﺫﺍ 6- ! ﺍﻼﺴﺘﻏﺭﺎﺑ ﻢﺜﻟ : ﻡﺍ ﺄﺠﻤﻟ ﻻﻮﻓﺍﺀ ﻭ ﺩﻮﻨﻣﺍ ﺖﻐﻴﻳﺭ ﻲﻨﻘﻟ ﺐﻨﺻﻭ ﻮﻳﻮﻀﻋ ﺐﻴﻨﻴﻣﺍ ﻚﻟ ﻚﺒﻠﻣ « » ﺖﻜﺘﺑ ﻰﻛﺫﺍ ﺓ ﻼﺘﻨﺼﻴﺻ ﻼﻣﺯﺩﻮﺟﺓ، ﻭ ﻊﺒﻠﻣ 7- » ﺲﻤﻣ : ﺺﻤﯨ ﺎﻬﻠﻟ ﻊﻤﻳﻭ ﻭﻵﻭ ﻭ ﻎﻳﺮﯩﻣﺍ ﻢﺜﻟ ﻕﻻ ﺮﺳﻮﻟ ﺎﻬﻠﻟ ﻢﻧ ﻼﻗﺭﺂﻧ ﻼﻛﺮﻴﻣ، ﻭﻼﺣﺪﻴﺛ ﻼﻨﺑﻮﻳ ﻼﺷﺮﻴﻓ، ﻭ « . ﺎﻄﻤﺑ ﻼﻌﻤﻣ ﻢﻧ ﻼﻤﻳﺩ ﻺﯨ ﻼﻤﺣﺩ ، ﻞﻴﺴﺗ ﻢﻧ ﺃﻭ ﺕﺮﻜﻴﺑ ﻲﺴﺘﻌﻤﺒﻠﻧ ﻞﺌﻠﺣﺎﻃﺓ ﺐﻜﻤﻣﺓ ﻼﻗﻮﺳﺎﻧ ﺃﻭ ﻼﻴﺒﻟﻼﻧ، ﻮﻳﺮﺴﻣﺎﻧ ﻰﻛﺫﺍ : ( ) ﻭ 8- ﻼﺘﻔﺴﻳﺭ ﻢﺜﻟ : ﺍﻺﻨﺳﺎﻧ ﻼﻋﺭﺎﻘﻳ ﻼﺟﺪﻳﺩ ( ﻒﻳ ﻼﻣﺮﺤﻣﺓ ﻼﺟﺪﻳﺩﺓ ) ﺝﻮﯨﺭ ﻼﻜﺒﻠﻣ ﻮﻠﻜﻨﻳﺍ ﺖﻌﻴﻧ ﻊﻤﯨ ﻼﺗﻮﻀﻴﺣ ﻭ ﺃﺩﺍﺓ ﻼﻨﻳﻮﺿ ﻼﺤﺿﺍﺮﻳ . ﺄﺼﺒﺣ 3 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺕﻮﻀﻋ ﻢﻛﺎﻧ ﻼﻤﺣﺫﻮﻓ ﻢﻧ ﻼﻜﺒﻠﻣ ﻞﻣﺩﻼﻟﺓ ﻊﻤﯨ ﻼﻤﺣﺫﻮﻓ ﺬﻓ، ﻭ ﺕﺮﺴﻣ ﻰﻛﺫﺍ : ( .... ) ﻭ ﻊﺒﻠﻣﺓ ﻼﺣ 9- ﺚﻟ : ﺃﻭ ﻞﺒﻳﺎﻧ ﺄﻧ ﻼﺣﺪﻴﺛ ﻝﻭ ﺖﺘﻣﺓ، ﻡ ﺇﺫﺍ ﻼﺸﻌﺑ ﻱﻮﻣﺍ ﺃﺭﺍﺩ ﻼﺤﻳﺍﺓ ﻒﺒﻟ ﺏﺩ ﺄﻧ .... ﺕﻮﻀﻋ ﻒﻳ ﻼﻣﻭﺎﻘﻋ ﺍﻶﺘﻳﺓ : ) ﻭ - ﻼﺷﺮﻃﺓ، ﻭ ﺕﺮﺴﻣ ﻰﻛﺫﺍ ( 10- ﺐﻋﺪﯨﺍ، ﻢﺜﻟ : ﻖﺒﻟ ﻼﺠﻤﻣﺓ ﻼﻤﻌﺗﺮﺿﺓ ﻭ - ﺃ ﺦﻤﻗ ﻦﺒﻴﻟ . - ﻮﻔﻘﻛ ﺎﻬﻠﻟ - ﻼﺤﻤﻣ ﻼﻤﺣﺍﺪﺛﺓ ﻢﺜﻟ : ﻒﻳ ﺄﺜﻧﺍﺀ ﻼﻤﺣﺍﻭﺭﺓ ﺐﻴﻧ ﺎﺜﻨﻴﻧ، ﻞﻣﺩﻼﻟﺓ ﻊﻤﯨ ﺖﻐﻳﺭ ﻼﻤﺘﻜﻤﻣ ﻒﻳ - ﺏ ؟ ﺄﻨﺗ ˚ﻦﻣ - . ﺄﻧﺍ ﻢﺤﻣﺩ - ﻡﺍ ﻊﻤﻤﻛ ؟ - ﻁﻼﺑ ﻒﻳ ﻼﺟﺎﻤﻋﺓ . - ﻼﻤﻋﺩﻭﺩ، ﻢﺜﻟ : ﻡﺭﺎﺤﻟ ﻼﺘﻌﻤﻴﻣ ﺍﻸﺳﺎﺴﻳﺓ ﻒﻳ ﻼﻋﺭﺎﻗ، ﺃﺮﺒﻋ : ﺕﻮﻀﻋ ﺐﻴﻧ ﻼﻋﺩﺩ ﻭ -ﺞـ ﻼﻣﺮﺤﻣﺓ ﺍﻼﺒﺗﺩﺎﺌﻳﺓ . 1- ﻼﻣﺮﺤﻣﺓ ﻼﻤﺗﻮﺴﻃﺓ . 2- ﻼﻣﺮﺤﻣﺓ ﻼﺛﺎﻧﻮﻳﺓ . 3- ﻼﻣﺮﺤﻣﺓ ﻼﺟﺎﻤﻌﻳﺓ ﺍﻷﻮﻠﻳﺓ . 4- ﻁﺭ ﻞﻨﺴﺘﻌﻴﺿ ﺐﻳﺍ ) ﺕﻮﻀﻋ ﻒﻳ ﺃﻮﻟ ﻼﺳ • ﻼﻨﺠﻣﺓ ﺃﻭ ﻻﺩﺎﺋﺭﺓ ﻼﺳﻭﺩﺍﺀ : ﻰﻳ ﻦﺠﻣﺓ ﺃﻭ ﺩﺎﺋﺭﺓ ﺱﻭﺩﺍﺀ ( 11- ﻒﻳ ﻼﻜﺗﺎﺑﺓ ﻼﺣﺪﻴﺛﺓ ﺖﺴﺘﻌﻤﻟ ﺄﻣﺍ ﻼﻌﻧﻭﺎﻧ ﻼﻓﺮﻌﻳ ﺃﻭ ﺡﻮﻟ ﻼﻌﻧﻭﺎﻧ ﻼﻣﺮﻛﺰﻳ . ﻊﻧ ﺮﻘﻣ ﻼﻔﻗﺭﺓ، ﻭ 4 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻚﺗﺎﺑﺓ ﻼﻬﻣﺯﺓ ﻲﺘﻀﻤﻧ ﻯﺫﺍ ﻼﻤﺒﺤﺛ ﺍﻶﺘﻳ : ﻞﻜﺒﻠﻣ : ﻼﻴﻣﺯﺓ ﻒﻳ ﺃﻮﻟ ﺍ 1- ﻰﻣﺯﺓ ﻼﻘﻄﻋ . - ﺃ ﻰﻣﺯﺓ ﻻﻮﺼﻟ . - ﺏ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ : 2- ﺮﺴﻣ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻤﯨ ﺍﻸﻠﻓ . - ﺃ ﺮﺴﻣ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻤﯨ ﻻﻭﺍﻭ . - ﺏ ﺮﺴﻣ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻤﯨ ﻼﻳﺍﺀ . -ﺞـ ﺮﺴﻣ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻢﻓﺭﺩﺓ ﻊﻤﯨ ﻼﺴﻃﺭ . -ﺩ ﻼﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ : 3- ﺇﺫﺍ ﻙﺎﻨﺗ ﻼﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ ﺐﻋﺩ ﻢﺘﺣﺮﻛ ﺃﻭ ﺱﺎﻜﻧ . - ﺃ ﻼﺣﺍﻼﺗ ﻼﺧﺎﺻﺓ ﻞﻤﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ . - ﺏ ﻼﻬﻣﺯﺓ ﻒﻳ ﺃﻮﻟ ﻼﻛﻼﻣ : ﻰﻣﺯﺓ ﻻﻮﺼﻟ ) . ( ﻰﻣﺯﺓ ﻼﻘﻄﻋ ﻭ ﺖﻤﺤﻗ ﻒﻳ ﺩﺮﺟﻭ، ﻭ ﺕ ﻒﻳ ﺏﺩﺀ ﻼﻜﺒﻠﻣ، ﺄﻣ ﻰﻣﺯﺓ ﻼﻘﻄﻋ : ﻰﻳ ﻼﻴﻣﺯﺓ ﻼﺘﻳ ﻲﻨﻄﻗ ﺐﻳﺍ ﺩﺎﺌﻣﺍ ﺱﻭﺍﺀ ﺃ ﻙﺎﻧ 1- ﺖﻘﻋ ﻰﻣﺯﺓ ﻼﻘﻄﻋ ﻒﻳ : ﻭ ﻸﻔﻳﺍ ﻒﻳ ﻼﻜﺗﺎﺑﺓ ﻼﻌﺒﻠﻣﺓ ( ﺀ ) ﻢﺣﺮﻛﺓ ﻑﻼﻴﻣﺯﺓ » ﻥ ﺎﻴﻣ -ﺎﻴﻣ - ﺎﺜﻨﺗﺎﻧ - ﺎﺜﻧﺎﻧ- ﺎﻣﺭﺃﺓ- ﺎﻣﺭﺅ-ﺎﺴﻣ-ﺎﺒﻧﻭ-ﺐﻧﺍ « ﺍ ﻒﻳ ﺃﻮﻟ ﺞﻤﻴﻋ ﺍﻸﺴﻣﺍﺀ، ﻉﺩ - ﺃ ﻒﻴﻳﺍ ﻞﻣﻮﺼﻟ . 5 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻒﻳ ﺃﻮﻟ ﺞﻤﻴﻋ ﺍﻸﺣﺮﻓ، ﻉﺩﺍ ( ﻻ ) ﻼﺘﻋﺮﻴﻓ ﻒﻴﻣﺰﺘﻳﺍ ﻞﻣﻮﺼﻟ . - ﺏ ﺄﻜﻟ ) . - ﺄﺘﯨ ) ، ( ﺈﺑﺍﺀ -ﺄﻜﻟ-ﺄﺒﯨ- ﻢﺻﺩﺮﻫ، ﻢﺜﻟ : ( ﺄﺧﺫ ﻒﻳ ﺃﻮﻟ ﻼﻔﻌﻟ ﻼﻣﺎﻀﻳ ﻼﺜﺒﻠﺜﻳ ﻭ -ﺞـ ﺈﺳﺭﺎﻋﺍ ) .- ﺄﺳﺮﻋ - ( ﺄﺳﺮﻋ ﻢﺻﺩﺮﻫ ﻢﺜﻟ : ﻞﻣﺎﻀﻳ ﻻﺮﺑﺎﻌﻳ ﻭﺄﻣﺮﻫ ﻭ ﻒﻳ ﺃﻮﻟ ﻼﻔﻌﻟ ﺍ -ﺩ ﺩﺮﺳ ) . ﺃ - ﺄﺴﻤﻣ - ﺏﻼﻴﻣﺯﺓ، ﻢﺜﻟ : ( ﺄﻜﺘﺑ ﻒﻳ ﻼﻔﻌﻟ ﻼﻤﺿﺍﺮﻋ ﻼﻤﺑﺩﻭﺀ -ﻰـ ﺡﺮﻛﺓ ﻢﺟﺭﺩﺓ ﻢﻧ ﻼﻌﺒﻠﻣﺓ ﺖﻜﺘﺑ ﻸﻔﻳﺍ ﻡ ﻼﺘﻳ ﻲﻨﻄﻗ ﺐﻳﺍ ﻒﻳ ﺏﺩﺀ ﻼﻜﺒﻠﻣ، ﻭ ﻰﻣﺯﺓ ﻻﻮﺼﻟ : ﻰﻳ ﻼﻴﻣﺯﺓ 2- ﺖﻘﻋ ﻰﻣﺯﺓ ﻎﻳﺭ ﻢﻗﺭﻮﻧﺓ ﺐﻳﺍ، ﻭ ) ﺃﻮﺼـ ﺍ ﻢﻗﺭﻮﻧﺓ ﺏﻼﻌﺒﻠﻣﺓ ( ﺖﻜﺘﺑ ﻸﻔﻳ ( ﺀ ) ، ﻭﻻ ﻲﻨﻄﻗ ﺐﻳﺍ ﻒﻳ ﺩﺮﺟ ﻼﻜﺒﻠﻣ، ﻭ ﺲﺘﻣﺎﻋﺍ ) . ﺍ - ﺍ - ﺲﺘﻤﻋ ﻒﻳ ﺃﻮﻟ ﻼﻔﻌﻟ ﻼﻣﺎﻀﻳ ﻼﺨﻣﺎﺴﻳ ﻭﺄﻣﺮﻫ ﻮﻤﺻﺩﺮﻫ، ﻢﺜﻟ : ( ﺍ ﺲﺘﻤﻋ ﻻﻮﺼﻟ : - ﺃ ﺲﺘﻌﻣﺍﻻ ) . ﺍ - ﺲﺘﻌﻤﻟ ﺍ - ﺲﺘﻌﻤﻟ ﻢﺻﺩﺮﻫ، ﻢﺜﻟ : ( ﺍ ﻒﻳ ﺃﻮﻟ ﻼﻔﻌﻟ ﻼﺳﺩﺎﺴﻳ ﻭﺄﻣﺮﻫ ﻭ - ﺏ ﺩﺮﺳ ) . ﺍ - ﻦﻴﺿ ﺍ -ﻚﺘﺑ ﺍ -ﻕﺭﺍ ﻒﻳ ﺃﻮﻟ ﻒﻌﻟ ﺍﻸﻣﺭ ﻼﺜﺒﻠﺜﻳ، ﻢﺜﻟ : ( ﺍ -ﺞـ ﻼﻘﻣﺭ ) . - ـ ( ﻻ ) ﻼﺘﻋﺮﻴﻓ، ﻢﺜﻟ : ( ﻼﺸﻤﺳ ﻒﻳ ﺃﻮﻟ ﺍﻸﺴﻣﺍﺀ ﻼﻤﺑﺩﻭﺀﺓ ﺏ -ﺩ ﺎﻴﻤﻧ ) . -ﺎﻴﻣ - ﺎﺜﻨﺗﺎﻧ - ﺎﺜﻧﺎﻧ- ﺎﻣﺭﺃﺓ- ﺎﻣﺭﺅ-ﺎﺴﻣ-ﺎﺒﻧﻭ- ﻒﻳ ﺃﻮﻟ ﺍﻸﺴﻣﺍﺀ ﺍﻶﺘﻳﺓ : ( ﺎﺒﻧ -ﻰـ ﻼﻬﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻖﺒﻟ ﻼﺑﺩﺀ ﻒﻳ ﺡﺍﻼﺗ ﺮﺴﻣ ﻼﻴﻣﺯﺓ، ﻲﺠﺑ ﻢﺒﻠﺤﻇﺓ ﻡﺍ ﻱﺄﺘﻳ : ﻲﻧﺎﺴﺒﻳﺍ ﻢﻧ ﺄﺣﺮﻓ ﻼﻣﺩ ( ﻼﻳﺍﺀ، ﹴ ﻭﻼﻔﺘﺣﺓ ) ﺡﺮﻓ ﻡﺩ ﻼﻀﻣﺓ ﺡﺮﻛﺓ ﻒﻳ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ( ﻼﻜﺳﺭﺓ ﻭ : ﻞﻜﻟ ﺃﻭﻻ ﻼﻔﺘﺣﺓ ﻲﻧﺎﺴﺒﻳﺍ ﺍﻸﻠﻓ . ﺍﻸﻠﻓ ) ﻑﻼﻜﺳﺭﺓ ﻲﻧﺎﺴﺒﻳﺍ ﻼﻳﺍﺀ، ﻭﻼﻀﻣﺓ ﻲﻧﺎﺴﺒﻳﺍ ﻻﻭﺍﻭ، ﻭ ﻻﻭﺍﻭ، ﺖﻳ ﺐﻋﺪﯨﺍ ﻼﻀﻣﺓ، ﺖﻤﻴﻳﺍ ﻼﻔﺘﺣﺓ، ﺩﺓ ﻢﻧ ﻼﻗﻭﺓ، ﻑﻼﻜﺳﺭﺓ ﺄﻗﻭﺎﯨﺍ، ﻭ ﺕﺃ ﺙﺎﻨﻳﺍ : ﻞﻴﺴﺗ ﻼﺣﺮﻛﺎﺗ ﻊﻤﯨ ﺩﺮﺟﺓ ﻭﺎﺣ ﻼﻀﺒﻃ . ﺡﺮﻛﺓ ﻙﺎﻧ ﺱﺎﻜﻧﺍ، ﻭﻼﺴﻛﻮﻧ ﺄﻀﻌﻓ ﺄﻧﻭﺎﻋ ﻼﺸﻜﻟ ﻭ ﺮﻓ ﺍ ﺫﺍ ﻞﻣ ﻱﻮﺟﺩ ﻊﻤﯨ ﻼﺣ ﻭ ﺖﻜﺘﺑ ﻼﻴﻣﺯﺓ ﻊﻤﯨ ﻡﺍ ﻲﻧﺎﺴﺑ ﺄﻗﻮﯨ ﻊﻧﺩ ﻚﺗﺎﺑﺓ ﻼﻴﻣﺯﺓ ﻦﺒﻠﺤﻇ ﺡﺮﻜﺘﻳﺍ ﻮﺣﺮﻛﺓ ﻼﺣﺮﻓ ﻻﺬﻳ ﻖﺒﻤﻳﺍ، ﻭ ﺙﻼﺛﺍ : ﻼﺣﺮﻜﺘﻴﻧ ﻢﻧ ﺄﺣﺮﻓ ﻼﻣﺩ ( ﻼﻳﺍﺀ، ﻻﻭﺍﻭ، ﺍﻸﻠﻓ ) . 6 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻮﺴﻃﺓ ﻊﻠﯨ ﺍﻸﻠﻓ ﺖﻣ ﺃﻭﻻ : ﺮﺴﻣ ﻼﻬﻣﺯﺓ ﻻ ﺍﻸﻠﻓ ﻒﻳ ﻼﻣﻭﺎﻀﻋ ﺍﻶﺘﻳﺓ : ﺖﻜﺘﺑ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻤﯨ ﻢﻛﺎﻓﺃﺓ ) .- ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻔﺗﻮﺣﺓ ﺐﻋﺩ ﺡﺮﻓ ﻢﻔﺗﻮﺣ، ﻢﺜﻟ : ( ﺱﻷ ﻰﻳﺃﺓ ) . -ﻡﺭﺃﺓ- ﻢﺳﻷﺓ- ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻔﺗﻮﺣﺓ ﺐﻋﺩ ﺡﺮﻓ ﺺﺤﻴﺣ ﺱﺎﻜﻧ، ﻢﺜﻟ : ( ﻒﺟ ﺃﺓ ﺏﺩﺄﺗ ) .- ﻡﺄﻣﻭﺭ- ﺇﺫﺍ ﻙﺎﻨﺗ ﺱﺎﻜﻧﺓ ﺲﺒﻘﻳﺍ ﺡﺮﻓ ﻢﻔﺗﻮﺣ، ﻢﺜﻟ : ( ﻱﺄﺧﺫ 1- 2- 3- ﺃﻭ ﺖﻤﺘﻳﺍ ﻸﻓ ﻼﻣﺩ ﺃﻭ ﻸﻓ ﻼﺘﺜﻨﻳﺓ ﻢﻔﺗﻮﺣﺓ ﺐﻋﺩ ﻒﺘﺣ ﺃﻭ ﺐﻋﺩ ﺱﺎﻜﻧ، ﻭ ﺓ ﺇﺫﺍ ﺝﺍﺀﺕ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃ 4- ﺂﺗ ) . ﻢﻨﺷ -ﺂﻨﻤﺑﺩ -ﺂﻨﻈﻣ -ﺂﺛﺭ ، ﻢﺜﻟ : ( ﻡ ﺩﺓ ﻑﻮﻗ ﻸﻓ ﺕ ﻼﻴﻣﺯﺓ ﻡ ﻊﺒﻠﻣﺓ ﺞﻤﻋ ﻼﻣﺆﻨﺛ ﻼﺳﻼﻣ، ﻚﺘﺑ ﺙﺎﻨﻳﺍ : ﺮﺴﻣ ﻼﻬﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻠﯨ ﻻﻭﺍﻭ ﺖﻜﺘﺑ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻤﯨ ﻻﻭﺍﻭ ﻒﻳ ﻼﺣﺍﻼﺗ ﺍﻶﺘﻳﺓ : ، ﻢﺜﻟ : ﺐﻋﺩ ﺾﻣ ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻀﻣﻮﻣﺓ 1- ﻮﺳ ) . ﻙﺅ - ﺵﺅﻮﻧ- ( ﻑﺅﻮﺳ ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻀﻣﻮﻣﺓ ﺐﻋﺩ ﻒﺘﺣ، ﻢﺜﻟ : 2- ﺩﺆﯨﺍ ) . ﻲﺑ - ﻱﺅﻮﺑ- ( ﻡﺅﻮﻧﺓ ﻦﺗ ﻢﻀﻣﻮﻣﺓ ﺐﻋﺩ ﺱﺎﻜﻧ، ﻢﺜﻟ : ﺇﺫﺍ ﻙﺍ 3- ﻊﻃﺍﺆﻛ ) . -ﻞﺘﻓﺍﺅ - ( ﻢﺳﺅﻮﻟ ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻔﺗﻮﺣﺓ ﺐﻋﺩ ﺾﻣ، ﻢﺜﻟ : 4- ﻱﺩ ) . ﻡﺅ -ﻦﺜﻣﺅ - ( ﻑﺅﺍﺩ ﺇﺫﺍ ﻙﺎﻨﺗ ﺱﺎﻜﻧﺓ ﺐﻋﺩ ﺾﻣ، ﻢﺜﻟ : 5- ﺭ ﺅ ﻱﺓ ) . -ﻦﻣﺅ ﻡ - ( ﺏﺆﺳ 7 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺙﻼﺛﺍ : ﺮﺴﻣ ﻼﻬﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻠﯨ ﻼﻳﺍﺀ ﺖﻜﺘﺑ ﻼﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻊﻤﯨ ﻡﺮﺴﻳ ﻼﻳﺍﺀ ﻒﻳ ﻼﺣﺍﻼﺗ ﺍﻶﺘﻳﺓ : ﻭﺭﺓ ﺐﻋﺩ ﻚﺳﺭ، ﻢﺜﻟ : ﻚﺳ ﺇﺫﺍ ﻙﺎﻨﺗ ﻡ 1- ﻢﻴﻨﺌﻴﻧ ) - ﻢﺘﻴﻴﺌﻴﻧ -ﺵ ﺊﻴﻧ ( ﺖﻧ ﻙﺎﻨﺗ ﻢﻜﺳﻭﺭﺓ ﺐﻋﺩ ﺾﻣ، ﻢﺜﻟ : ﺇﺫﺍ -2 ﻮﺋﺪﺗ ) .- ( ﺲﺌﻟ ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻜﺳﻭﺭﺓ ﺐﻋﺩ ﻒﺘﺣ، ﻢﺜﻟ : 3- ﻲﻄﻤﺌﻧ ) . -ﻞﺌﻴﻣ- ( ﺄﺌﻣﺓ ﺇﺫﺍ ﻙﺎﻨﺗ ﻢﻜﺳﻭﺭﺓ ﺐﻳﺩ ﺱﺎﻜﻧ، ﻢﺜﻟ : 4- ﺝﺯ ﺊﻳﺓ ) .- ( ﻢﺳﺎﺌﻟ ﺏﺩ ﺊﺗ ) . -ﺲﻴﺋﺓ- ﻦﺗ ﻢﻔﺗﻮﺣﺓ ﺐﻋﺩ ﻚﺳﺭ، ﻢﺜﻟ : ( ﺮﺋﺓ ﺇﺫﺍ ﻙﺍ 5- ﻢﺋﺯﺭ ) .- ﻒﺋﺭﺎﻧ- ( ﺍﻼﺴﺘﺋﺫﺎﻧ ﺇﺫﺍ ﻙﺎﻨﺗ ﺱﺎﻜﻧﺓ ﺐﻋﺩ ﻚﺳﺭ، ﻢﺜﻟ : 6- ﻲﺋﻮﻧ ) . ﺱ -ﻆﻤﺋﻭﺍ -ﻮﻧ ﻙﺎﻨﺗ ﻢﻀﻣﻮﻣﺓ ﺐﻋﺩ ﻚﺳﺭ، ﻢﺜﻟ : ( ﻕﺍﺮﺋ ﺇﺫﺍ -7 : ﺮﺴﻣ ﻼﻬﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻢﻓﺭﺩﺓ ﻊﻠﯨ ﻼﺴﻃﺭ ﺭﺎﺒﻋﺍ ﻢﻳﺓ، ﺇﺫﺍ ﻮﻘﻌﺗ ﺐﻋﺩ ﻼﻣﺩ ﺏﺍﻸﻠﻓ ﻞﻴﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻢﻓﺭﺩﺓ ﻊﻤﯨ ﻼﺴﻃﺭ، ﺦﺒﻠﻓﺍ ﻞﻤﻗﺎﻋﺩﺓ ﺍﻸﺻ ﺖﻜﺘﺑ ﺍ ﻭ ﺏﻭﺀﺓ ) . ﻡ - ﻢﺳﺍﺀﻝﺓ -ﺐﻟﺀﻡﺓ ﻡ - ( ﺖﺛﺍﺀﺏ ﻙﺎﻨﺗ ﻢﻔﺗﻮﺣﺓ، ﻢﺜﻟ : ﻭﻻﻭﺍﻭ ﻭ ﻢﻤﻣﻭﺀﺓ - ﻕﺭﺍﺀﺓ - ﻚﻓﺍﺀﺓ - 8 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻼﻬﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ ﺃﻭﻻ : ﺇﺫﺍ ﻙﺎﻨﺗ ﺐﻋﺩ ﻢﺘﺣﺮﻛﺓ ﺃﻭ ﺱﺎﻜﻧ، ﻮﻠﻳﺍ ﺡﻼﺗﺎﻧ : ، ﻒﺘﻜﺘﺑ ﻼﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ ﻊﻤﯨ ﺡﺮﻓ ﻲﻧﺎﺴﺑ ﺡﺮﻛﺓ ﻡﺍ ﻖﺒﻤﻳﺍ، ﻢﻴﻣﺍ ﺄﻧ ﺖﻛﻮﻧ ﺐﻋﺩ ﺡﺮﻓ ﻢﺘﺣﺮﻛ 1- ﻙﺎﻨﺗ ﺡﺮﻜﺘﻳﺍ : ﻑﺈﻧ ﻙﺎﻧ ﻡﺍ ﻖﺒﻤﻳﺍ ﻢﻜﺳﻭﺭﺍ ﻚﺘﺒﺗ ﻊﻤﯨ ﻼﻳﺍﺀ، ﻢﺜﻟ : - ﺩ ﺉ ) . ﺏ - ﺩﺎﻔﺋ- ﺵﺎﻃ ﺉ- ( ﻕﺍﺮﺋ ﺍ ﻥ ﻙﺎﻧ ﻡﺍ ﻖﺒﻤﻳﺍ ﻢﻔﺗﻮﺣﺍ ﻚﺘﺑ ﻊﻤﯨ ﺍﻸﻠﻓ، ﻢﺜﻟ : ﻭ - ﺃ ) .ﺩ ﺹ -ﺏﺩﺃ-ﺄﻳ ﻱ ﺕ -ﻲﻣﺆﻟ-ﺭﺄﻗ ( ﻱ ﺄﻧ ﺖﻛﻮﻧ ﺐﻋﺩ ﺡﺮﻓ ﺱﺎﻜﻧ، ﻒﺘﻜﺘﺑ ﻼﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ ﻢﻓﺭﺩﺓ ﻊﻤﯨ ﻼﺴﻃﺭ ﺇﺫﺍ ﻮﻘﻌﺗ ﺐﻋﺩ ﺡﺮﻓ ﺱﺎﻜﻧ، 2- ﺯﺀ ) .ﺝ -ﺏ ﺀﻉ -ﻑ ﺀﺩ -ﺾﻳﺀ ﻡ -ﺶﻳ ﺀ -ﺝﻭﺀﻝ -ﻭﺀﺽ -ﻡﺍﺀ- : ﻢﺜﻟ ( ﺺﺣﺭﺍﺀ ﺙﺎﻨﻳﺍ : ﻼﺣﺍﻼﺗ ﻼﺧﺎﺻﺓ ﻞﻤﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ ﺇﺫﺍ ﺎﺘﺼﻤﺗ ﻼﻴﻣﺯﺓ ﻼﻤﺘﻃﺮﻓﺓ ﻼﻤﻓﺭﺩﺓ ﺐﻋﺩ ﺱﺎﻜﻧ، ﺏﻸﻓ ﺖﻧﻮﻴﻧ ﻼﻨﺼﺑ ﺃﻭ ﻸﻓ ﻼﺘﺜﻨﻳﺓ، ﻚﺘﺒﺗ ﻊﻤﯨ ﺡﻼﺘﻴﻧ : -ﺐﺋﺍ ﻉ - ﺐﻣﺍ ﺐﻋﺪﻫ، ﻢﺜﻟ : ( ﺪﻔﺋﺍ ﻼﻛﺮﺴﻳ ) ﺇﺫﺍ ﻙﺎﻧ ﻼﺣﺮﻓ ﻻﺬﻳ ﻖﺒﻤﻳﺍ ﻲﻤﻜﻧ ﻮﺼﻣﻭ - ﻊﻤﯨ ﻼﻳﺍﺀ ( ﻼﻨﺑﺭﺓ 1- -ﺯﺀﺍ ﺝ -ﻭﺀﺍ ﻢﻓﺭﺩﺓ ﻊﻤﯨ ﻼﺴﻃﺭ ﺇﺫﺍ ﻙﺎﻧ ﻼﺣﺮﻓ ﻻﺬﻳ ﻖﺒﻤﻳﺍ ﻻ ﻲﻤﻜﻧ ﻮﺼﻣﻭ ﺐﻣﺍ ﺐﻋﺪﻫ، ﻢﺜﻟ : ( ﺽ 2- ﺶﻴﺋﺎﻧ ) . -ﺶﻴﺋﺍ ﺯﺀﺎﻧ ) . ﺝ 9 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺍﻸﻏﻼﻃ ﻼﻠﻏﻮﻳﺓ ﻦﺴﺑﺓ ﻺﯨ ﺍﻼﻣﺓ، ﻑﻼﻗﺎﻋﺩﺓ ﻼﺻﺮﻔﻳﺓ ﻒﻳ ﻼﻤﻏﺓ ﻼﻋﺮﺒﻳﺓ ﺖﻘﺘﻀﻳ ﺡﺬﻓ ﻼﺗﺍﺀ ﻼﻣﺮﺑﻮﻃﺓ ﻢﻧ ﺍﻼﻣ -1 : ﻱ ﺂﺧﺭ ﺍﻼﺴﻣ ﻙﻼﺒﺻﺮﻳ ﻢﻧ ﻼﺒﺻﺭﺓ ﻢﺷﺩﺩﺓ ﻒﻳ ﻼﻨﺴﺑ ﻺﻴﻳﺍ، ﻭﻼﻨﺴﺑ ﺰﻳﺍﺩﺓ ﻱﺍﺀ ﺍﻼﺴﻣ ﻼﻤﺨﺗﻮﻣ ﺐﻳﺍ ﻊﻧﺩ ﻞﻜﺗﺎﺑﺓ، ﻂﻤﻗ ﻊﻤﯨ ﻚﻟ ﻢﻧ ﻻ ﻲﻋﺮﻓ ﻼﻗﺭﺍﺀﺓ ﻭﺍ ﻼﻋﺮﺒﻳ ﻢﻧ ﻼﻋﺮﺒﻳﺓ، ﺄﻣﺍ ﻼﺨﻃﺃ ﻒﻳ ﻚﻤﻣﺓ ( ﺍﻸﻤﻳ ) ﻒﻳ ﺄﻨﻳﺍ ﺕ ﻭ  ) ﺪﻠﻴﻤﻴﻣ ﻒﻳ ﺬﻠﻛ ﺄﻧ ﻼﻨﺒﻳ ﻢﺤﻣﺩ ( ﻯﺫﺍ ﻲﻌﻨﻳ ﺄﻨﻳﺍ ﺄﺼﺒﺤﺗ ﻢﺒﻟﺰﻣﺓ ﻞﺸﺨﺼﻳﺓ ﻻﺮﺳﻮﻟ ﻼﻛﺮﻴﻣ ( ﻭ  ﻭ ) ﻊﻣﻭﺍ ( ﻡﺍ ) ﻥﺎﻔﻳﺓ ﻉﺎﻤﻣﺓ ﻸﻨﻴﻣ ﺝ » ﻡﺍ ﺄﻧﺍ ﺐﻗﺍﺮﺋ « ﻕﻻ ﻝﻭ ﺎﻗﺭﺃ ﻑﺄﺟﺎﺑ  ﻭ ) ﺄﻗﺭ ﺐﻨﻔﺳﻭ ﻊﻧﺪﻣﺍ ﻰﺒﻃ ﻻﻮﺤﻳ ( ( ﻡﺍ ) ﻰﻧﺍ ﻊﻤﻴﻟ ﺥﺎﻄﺋ ﻒـ ﻮﯨﺫﺍ ﺕ ! ﺡﺮﻓ ﻼﺑﺍﺀ ﺡﺮﻓ ﺝﺭ ﺯﺎﺋﺩ ﻞﻤﺗﻮﻜﻳﺩ ﺍ ﺐﻋﺪﯨﺍ ﺎﺴﻤﻳﺍ ﻮﺨﺑﺮﯨﺍ ﻭ ﻡ ﻊﻤﻟ ﻞﻴﺳ ﻭ ﻰﻟ ﺝﺯﺍﺀ ﺍﻺﺤﺳﺎﻧ ﺇﻻ « ﻖﻳﺎﺳﺍ ﻊﻤﯨ ﻕﻮﻟﻭ ﺖﻋﻼﯨ : ﻡﺍ ﻻﺬﻳ ﺎﻗﺭﺄﻫ « ﺎﺴﺘﻔﻳﺎﻤﻳﺓ ﻒﺘﺠﻌﻟ ﻢﻌﻨﯨ ﻼﺣﺪﻴﺛ » ﻦﯨ ﺄﻧ ، ﺄﻳ ﻡﺍ ﺝﺯﺍﺀ ﺍﻺﺤﺳﺎﻧ ﺇﻻ ﺍﻺﺤﺳﺎﻧ ... ﺄﻣﺍ ﺢﺠﺘﻴﻣ ﺍﻼﺧﺮﯨ ﻞﺘﺑﺮﻳﺭ ﻢﻋ 66 ﻻﺮﺤﻤﻧ/ » ﺍﻺﺤﺳﺎﻧ ﺭﺩ ﻥ ﻼﻛﺮﻴﻣ ) ﻞﻣﺍ ﻒﻳﻭ ﻢﻧ ﻼﻔﺻﺎﺣﺓ، ﻭ ( ﻼﻗﺭﺁ ﻼﻜﺗﺎﺑﺓ ﻒﺘﺘﻤﺜﻟ ﺏﻼﻤﻌﺟﺯﺓ ﻼﻜﺑﺮﯨ ( ﺍﻸﻤﻳ ) ﻻ ﻲﻋﺮﻓ ﻼﻗﺭﺍﺀﺓ ﻭ ﻪﻠﻟ ﺖﻋﻼﯨ ﻉﻼﻣ ﺄﻴﻧ ﻲﻀﻋ ﺮﺳﻼﺗﻭ ، ﻑﺍ6 ﻱﻮﺴﻓ/ » ﻡ ﻲﻛ ﺈﻧ ﺮﺒﻛ ﻊﻤﻴﻣ ﺡ « ﻼﺤﺟﺓ ﺖﺘﻤﺜﻟ ﺐﻗﻮﻟﻭ ﺖﻋﻼﯨ ﻯﺬﻫ ﺢﻜﻴﻣ ﻸﻧﻭ ﺲﺒﺣﺎﻧﻭ ﻞﻣ ﻲﺒﻌﺛ ﻦﺒﻳﺍ ﺃﻭ ﻱﺮﺴﻟ ﺮﺳﻭﻻ ﺇﻻ ﺐﻣﺍ ﻲﺒﻠﺌﻣ ﻼﻌﺻﺭ ﻻﺬﻳ ﻲﺒﻌﺛ ﻒﻳﻭ، ﻒﻗﺩ ﺐﻌﺛ ﻮﻠﻤﻧ، ﻭ ﻎﻤﺒﺗ ) ﺐﻤﻌﺟﺯﺓ (  ﺐﻌﺛ ﻊﻴﺴﯨ ﻙﺎﻧ ﻢﺸﻳﻭﺭﺍ ﻢﻧ ﻼﺴﺣﺭ ﻭﻼﺸﻋﻭﺫﺓ، ﻭ ) ﺐﻤﻌﺟﺯﺓ ﻑﺎﻘﺗ ﻡﺍ (  ﻡﻮﺴﯨ ) ﻒﻛﺎﻨﺗ ﻢﻌﺟﺰﺗﻭ ﻼﻗﺭﺂﻧ ﻼﻛﺮﻴﻣ ﻞﻣﺍ ﻙﺎﻧ  ﺐﻌﺛ ﺲﻳﺪﻧﺍ ﻢﺤﻣﺩ ( ﻡﺍ ﻙﺎﻧ ﻢﺸﻳﻭﺭﺍ ﻒﻳ ﻢﺟﻻ ﻼﻄﺑ، ﻭ ﻊﻤﯨ ﺝﺰﯩﻣ ﺎﻬﻠﻟ ﺐﻳﺫﺍ ﻦﻈﻣ ﻼﺸﻋﺭ ﻼﺴﻴﻣﺍ ﻼﻤﻌﻤﻗﺎﺗ، ﻑﺄﻋ ﻼﺒﺒﻠﻏﺓ ﻭ ﻊﻤﻳﻭ ﺬﻠﻛ ﻼﻌﺻﺭ ﻢﻧ ﺏﺭﺎﻋﺓ ﻒﻳ ﻼﻔﺻﺎﺣﺓ، ﻭ ! . ﻯﻭ ﺏﻼﻤﻏﺓ ﻦﻔﺴﻳﺍ ﻼﺘﻳ ﻲﺘﺣﺪﺛﻮﻧ ﺐﻳﺍ ﻎﺗﻭ ﻭ ﻼﻜﺗﺎﺑ ﻞﻔﺻﺎﺤﺗﻭ ﻮﺒﺒﻟ ﻒﻳ ﻼﻗﺭﺂﻧ ﻼﻛﺮﻴﻣ ﻒﻳ ﻞﻣﺆﻨﺛ ﻉﺎﻘﻟ ﺃﻭ ﺺﻓﺓ ﻚﻣﺍ ﻭﺭﺩ ﻒﺘﺣ ﻼﺴﻴﻧ ﻯﻭ ﺎﺴﻣ ﺲﻜﻴﻧﺓ ﺏ ﺲﻜﻴﻧﺓ : - ﺲﻜﻴﻧﺓ 2- ﻢﻧ ﺲﻜﻴﻧﺓ ﺄﻧ ﻱﺄﺘﻴﻜﻣ ﻼﺗﺎﺑﻮﺗ ﻒﻳﻭ ﻭ ﻕﻻ ﻞﻴﻣ ﻦﺒﻴﻴﻣ ﺈﻧ ﺂﻳﺓ ﻢﻤﻛﻭ « ﻡﻮﻀﻌﻴﻧ، ﺍﻷﻮﻟ ﻒﻳ ﻕﻮﻟﻭ ﺖﻋﻼﯨ ﻼﺗﻮﺑﺓ/ » ﻊﻤﯨ ﺮﺳﻮﻟﻭ ﻮﻌﻤﯨ ﻼﻣﺆﻤﻨﻴﻧ ﺎﻬﻠﻟ ﺲﻜﻴﻨﺗﻭ ﺚﻣ ﺄﻧﺰﻟ « ﻼﺛﺎﻨﻳ ﻒﻳ ﻕﻮﻟﻭ ﺖﻋﻼﯨ ﻭ 248 ﻼﺒﻗﺭﺓ/ » ﺮﺒﻜﻣ '' ﺲﻜﻴﻧﺓ '' ﺐﻀﻣ ﻼﺴﻴﻧ ﻒﻴﻳ ﺄﻨﺜﯨ ﻼﺤﻣﺍﺭ ﻚﻣﺍ ﻭﺭﺩ ﻒﻳ ﻢﻋﺎﺠﻣ ﻼﻤﻏﺓ . ﻮﺘﻌﻨﻳ ﻼﻄﻣﺄﻨﻴﻧﺓ ﻭﺍﻸﻣﺎﻧ، ﺄﻣﺍ 26 10 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻝﺓ ﻊﻤﯨ ﺈﻧ ﻼﻋﺮﺒﻳﺓ ﻼﻔﺼﻴﺣﺓ ﻞﻣ ﺖﻌﻳﺩ ﻮﻀﻋ ﻚﻤﻣﺓ `` ﻒﺗﺭﺓ '' ﻡﻮﻀﻋ ﻚﻤﻣﺓ `` ﻡﺩﺓ '' ﻞﻣﺩﻻ ﻼﻣﺩﺓ : - ﻼﻔﺗﺭﺓ 3- ﺩ ﻼﻀﻌﻓ ﻝﺫﺍ ﺄﻄﻤﻗ ﻊﻤﯨ ﻼﻌﺻﺭ ﻻﺬﻳ ﺲﻘﻄﺗ ﻒﻳﻭ ﺐﻏﺩﺍﺩ ﻊﻤﯨ ﻱ ﻝﻮﻘﺗ ﻸﻧ ﻢﻌﻨﯨ ﻒﺗﺭﺓ، ﺍﻼﻨﻜﺳﺍﺭ ﻭ ﺍ ـ `` ﻒﺗﺭﺓ ﻼﻌﺻﻭﺭ ﻼﻤﺗﺄﺧﺭﺓ '' . ﻼﻤﻏﻮﻟ ﻮﻄﻤﺳ ﻼﻳﻮﻳﺓ ﻼﻋﺮﺒﻳﺓ ﻮﺣﺮﻗ ﻼﻜﺘﺑ ﺏ ﺡ ﻺﯨ ﻕﺩ ﺪﺨﻟ ﻯﺫﺍ ﻼﻤﺼﻄﻣ ﻢﻋﺎﺠﻣ ﻼﻤﻏﺓ ﺱﺮﺑ ﻼﻜﺒﻠﺑ ﻮﺳﺮﺑ ﻼﺤﻤﻳﺭ، ﻭ ﺖﻌﻨﻳ ﻒﻳ ﻭ ﻼﻛﻭﺍﺩﺭ : -ﻙﺍﺩﺭ 4- '' ﻢﺒﻠﻛ ﺃﻭ ﻼﻴﻳﺄﺗ '' . ﺍﻸﺻﻮﺑ ﻒﻳ ﻼﺘﻌﺒﻳﺭ ﻲﻗ ﻼﺗﺮﺠﻣﺓ ﻭ ﻼﻋﺮﺒﻳﺓ ﻊﻧ ﻁﺭ ﻼﺼﺤﻴﺣ ﻒﻳ ﻢﻌﻧﺎﯨﺍ ﻞﻏﺓ `` ﻼﺘﻗﻮﯨ '' ﻢﻗ ﺦﻃﺃ ﻊﻤﯨ ﻼﺸﺑﺎﺑ ﺃﻭ ﻼﻐﻤﻣﺎﻧ ﻭ ﻼﺘﻳ ﺖﻃ ﻱﺍ `` ﻼﻔﺘﻳﺓ '' ﺞﻤﻋﻭ ﻼﻔﺘﯨ : 5- ﺇﺫ ﺁﻮﯨ « ﻑﻼﻔﺘﯨ ﻢﻧ ﺎﺘﻘﯨ ﻻ ﻢﻧ ﻙﺎﻧ ﺵﺎﺑﺍ ﺏﺪﻠﻴﻟ ﻡﺍ ﺬﻛﺮﻫ ﺎﻬﻠﻟ ﺲﺒﺣﺎﻧﻭ ﻒﻳ ﻮﺼﻓ ﺄﺼﺣﺎﺑ ﻼﻜﻴﻓ ﺐﻗﻮﻟﻭ ﺈﻨﻴﻣ « ﻮﻟﻭ ﻱﺆﻛﺩ ﺎﻬﻠﻟ ﺖﻋﻼﯨ ﻯﺫﺍ ﻼﻤﻌﻨﯨ ﺐﻗ ﻢﻋ ﺄﻨﻴﻣ ﻙﺎﻧﻭﺍ ﺶﻳﻮﺧﺍ ﻢﺴﻨﻴﻧ، ﻭ 16 ﻼﻜﻴﻓ/ » ﻺﯨ ﻼﻜﻴﻓ ﻼﻔﺘﻳﺓ 13 . ﻼﻜﻴﻓ/ » ﺯﺪﻧﺎﯩﻣ ﻯﺪﯨ ﻒﺘﻳﺓ ﺂﻤﻧﻭﺍ ﺏﺮﺒﻴﻣ ﻭ ﻭﺎﺴﻃﺓ ﺓ '' ﻼﺘﻳ ﺖﺗﻮﺴﻃ ﻼﻌﻗﺩ ﺃﻭ ﻼﻘﺒﻟﺩﺓ، ﻒﻴﻗﻻ ﻯﺬﻫ ﻻﻭﺎﺴﻃﺓ ﻞﻏﺓ ﺖﻌﻨﻳ `` ﻼﺧ ﺭﺯ ﻮﺳﺎﻃﺓ : - ﻭﺎﺴﻃﺓ 6- ﻼﺼﺤﻴﺣﺓ ﻒﻳ ﺍﻼﺴﺘﻌﻣﻻ . ﻰﻳ ﺄﻣﺍ `` ﻻﻮﺳﺎﻃﺓ '' ﻒﺘﻌﻨﻳ `` ﻻﻮﺴﻴﻣﺓ '' ﻭ ﻼﻌﻗﺩ، ﻚﻤﻣﺓ `` ﺹﺎﻐﻳﺓ '' ﺏﺩﻻ ﻢﻧ ﻮﺟﻭ ﻼﺨﻃﺃ ﻒﻳ ﻯﺫﺍ ﻼﺘﻌﺒﻳﺭ ﺎﺴﺘﻌﻣﻻ ﺁﺫﺎﻧ ﺹﺎﻐﻳﺓ : ﺃﺬﻧ ﺹﺎﻐﻳﺓ ﻭ 7- ﻲﻗﻻ ﻭ ﻒﻳ ﻚﺘﺑ ﺎﻬﻠﻟ `` ﺹﺎﻐﻳﺓ '' ﺖﻌﻨﻳ `` ﻡﺎﺌﻣﺓ '' ، ﻲﻗﻻ ( ﺺﻐﺗ ﻼﻨﺟﻮﻣ ) ﻡﻼﺗ ﻺﯨ ﻼﻏﺭﻮﺑ، '' ﻢﺼﻐﻳﺓ '' ﻭ ، ﺄﻳ ﻡﻼﺗ 14 ﻼﺘﺣﺮﻴﻣ/ » ﻡﻮﺒﻜﻣﺍ ﻕ ﺕ ﻍ ﻒﻗﺩ ﺹ « ﻕﻻ ﺖﻋﻼﯨ ﻝﺮﺠﻟ ) ﻕﻮﻣﻭ ﻻﺬﻴﻧ ﻲﻤﻴﻣﻮﻧ ﻺﻳﻭ، ﻭ ( ﺹﺎﻐﻳﺓ ﺍ ، ﻭﺄﻣﺍ `` ﺄﺼﻐﯨ ﻺﻳﻭ '' ﻒﻤﻌﻧﺎﻫ 113 ﺍﻸﻨﻋﺎﻣ/ » ﺆﻤﻧﻮﻧ ﺏﺍﻶﺧﺭﺓ ﻞﺘﺼﻐﻳ ﻺﻳﻭ ﺄﻔﺋﺩﺓ ﻻﺬﻴﻧ ﻻ ﻱ ﻭ « ﻮﻗﻮﻟﻭ ﺖﻋﻼﯨ '' ﺃﺫﺎﻧ ﻢﺼﻐﻳﺓ '' ﺄﻳ ﺱﺎﻤﻋﺓ . `` ﺲﻤﻋﻭ '' ﻭ ﺍﻸﺼﺣ ﻲﻗﻻ `` ﺎﻌﺘﺑﺮﺗ ﻒﺒﻠﻧﺍ ﺹﺪﻴﻗﺍ '' ﻭ '' ﺇﺫ ﻢﻧ ﺍﻸﻔﻋﻻ ﻼﺷﺎﺌﻋﺓ ﻒﻳ ﻼﻋﺮﺒﻳﺓ ﻼﻔﻌﻟ `` ﺎﻌﺘﺑﺭ ﻉﺩ : - 8- ﺎﻌﺘﺑﺭ ﻑﺎﻌﺘﺑﺭﻭﺍ « ﻼﻌﻇﺓ '' ﻕﻻ ﺖﻋﻼﯨ ﺖﺑﺭ ﺐﻳﺫﺍ ﻼﻤﻌﻨﯨ ﻸﻧﻭ `` ﻼﻌﺑﺭﺓ ﻭ ﺎﻋ ﺐﻠﻧﺍ ﺹﺪﻴﻗﺍ '' ﻑﻼﻋﺮﺒﻳﺓ ﻻ ﺖﺴﺘﻌﻤﻟ '' ﻉﺩﺪﺗ ﻑ 2 . ﻼﺤﺷﺭ/ » ﻱﺍ ﺃﻮﻠﻳ ﺍﻸﺒﺻﺍﺭ 11 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺀ '' ﻮﻔﻳﻭ ﻮﻌﻤﻳﻭ `` ﺞﻌﻟ ﻒﻳﻭ ﻼﺨﻳﺭ ﻭﻼﺑﺮﻛﺓ '' ﺝﺍﺀ ﻒﻳ ﻼﻤﻌﺠﻣ ﻻﻮﺴﻴﻃ `` ﺏﺍﺮﻛ ﺎﻬﻠﻟ ﻼﺸﻳ ﺏﺍﺮﻛ : ﻢﺑﺭﻮﻛ 9- ﻡ - ﺏﺮﻛ ﻊﻤﯨ ﺍﻸﻣﺭ ﻭﺎﻈﺑ ﻊﻤﻳﻭ ﻑﺍﻸﻣﺭ ﻒﻳ ﻡﻮﻀﻋ ﻒﻣﺰﻣﻭ ﻭ ﻼﺒﻌﻳﺭ ﺝﺍﺀ ﻒﻳ ﻻﻮﺴﻴﻃ ﺄﻴﺿﺍ `` ﺏﺮﻛ ﻒﻳﻭ ﻢﺑﺍﺮﻛ ﻭ ﻻ ﺖﻗﻮﻟ ﻢﺑﺭﻮﻛ '' . ﺎﻈﺑ ﻊﻤﻳﻭ . ﺇﺬﻧ ﻖﻟ `` ﻦﺟﺎﺤﻛ ﻢﺑﺍﺮﻛ ﻭ ﻢﺑﺭﻮﻛ ﻊﻤﻳﻭ ﺃﻭ ﻡﻭ ﻞﻤﺒﺗﺩﺃﺓ ﺖﻜﺘﺑ ﻊﻤﯨ ﺍﻸﻠﻓ ﻰﻳ ﺄﻧ ﻼﻴﻣﺯﺓ ﺍ ﻝﺮﺴﻣ ﻼﻴﻣﺯﺓ ﻕﺎﻋﺩﺓ ﻲﺴﻳﺭﺓ ﻭ ﻢﺋﺓ : -ﻡﺎﺋﺓ ﻼﻬﻳﺃﺓ، ﻭ - ﻼﻬﻴﺋﺓ 11- ﻼﻤﺘﻃﺮﻓﺓ ﻒﻴﺘﺒﻋ ﺮﺴﻤﻳﺍ ﺡﺮﻛﺓ ﻲﻣﺯﺓ ﻼﻤﺗﻮﺴﻃﺓ ﻭ ﺖﺟﺎﻫ '' ﺄﻣﺍ ﻻ ، ﺍ ﺏﺄﻳ ﺡﺮﻛﺓ ﺖﺣﺮﻜﺗ ﻢﺜﻟ `` ﺄﺧﺫ، ﺄﻣ ﻢﻄﻤﻗﺍ ﻭ ﺓ ﻞﻴﺴﺗ ﺐﻤﺴﺗﻮﯨ ﻭﺎﺣﺩ ﻢﻧ ﻼﻗﻭﺓ ﻭﻼﻀﻌﻓ ﻑﺄﻗﻮﯨ ﻼﺣﺮﻓ ﻼﺳﺎﺒﻗ ﻞﻳﺍ ﻢﻋ ﻡﺭﺎﻋﺍﺓ ﺄﻧ ﻼﺣﺮﻛﺎﺗ ﻼﻋﺮﺒﻳ ﻊﻤﯨ ﻡﺍ ﻢﻧ ﺚﻣ ﻼﻀﻣﺓ ﻑﻼﻔﺘﺣﺓ ﻑﻼﺴﻛﻮﻧ، ﻑﺇﺫﺍ ﻙﺎﻨﺗ ﻼﺣﺮﻛﺓ ﺍﻸﻗﻮﯨ ﻼﻜﺳﺭﺓ ﺕﺮﺴﻣ ﻼﺣﺮﻛﺎﺗ، ﻼﻜﺳﺭﺓ ﻭ ﺍ ﻥ ﻡﺓ ﺕﺮﺴﻣ ﻊﻤﯨ ﻻﻭﺍﻭ ﻢﺜﻟ `` ﻢﺳﺅﻮﻟ '' ﻭ ﺍ ﻥ ﻙﺎﻨﺗ ﻼﺿ ﻲﺒﻠﺌﻤﻳﺍ ﻢﻧ ﺄﺣﺮﻓ ﻼﻌﻣﺓ ﻮﯨﻭ ﻼﻳﺍﺀ ﻢﺜﻟ `` ﺮﺳﺎﺌﻟ '' ﻭ ﻢﯨ ﻰﻳﺃﺓ ﻼﻳﺍﺀ ﻭﺍ ﻡﺍ ﺕﺮﺴﻣ ﺍﻸﻠﻓ ﻒﻳ ﺍﻼﺴﻣ ﻼﻤﻘﺻﻭﺭ ﺈﻣﺍ ﺏﻸﻓ ﻢﻘﺻﻭﺭﺓ ﻼﺘﻳ ﻉ ﺍﻼﺴﻣ ﻼﻤﻘﺻﻭﺭ : 11- ﻙﺎﻨﺗ ﻼﻔﺘﺣﺓ ﺕﺮﺴﻣ ﻊﻤﯨ ﺍﻸﻠﻓ ﻢﺜﻟ `` ﻼﻴﻳﺃﺓ '' . ﻼﺼﺤﻴﺣ ﺢﻤﯨ ... '' ﻭ -ﻂﯨ ﻸﺨﻃﺍﺀ ﻒﻳ ﻼﻋﺮﺒﻳﺓ ﺐﻳﺬﻫ ﻼﺣﺭﻮﻓ ﻢﺜﻟ `` ﻼﺧ ﻰﻧﺎﻛ ﻼﻜﺜﻳﺭ ﻢﻧ ﺍ ﺏﻸﻓ ﻢﻣﺩﻭﺩﺓ ﻭ ﻞﯨ ﻒﻳ ﺮﺴﻤﻳﺍ `` ﻼﺨﻃﺍ ﻭ ﺢﺒﻟ '' ﺄﻣﺍ ﻚﻴﻔﻳﺓ ﻢﻋﺮﻓﺓ ﺮﺴﻤﻳﺍ ﺏﺍﻸﻠﻓ ﻼﻤﻣﺩﻭﺩﺓ ﺄﻣ ﺏﺍﻸﻠﻓ ﻼﻤﻘﺻﻭﺭﺓ ﻒﻨﻋﻭﺩ ﺇ ﺍ ﻥ ﻙﺎﻨﺗ ﻒﻳ ﻭﺍ ﻚﺘﺒﺗ ﻸﻓﺍ ﻢﻣﺩﻭﺩﺓ ﻭ ﻙﺎﻧ ﺄﺼﻟ ﺍﻸﻠﻓ ﻭﺍ ﻼﻤﺿﺍﺮﻋ ﻑﺈﻧ ﺄﺼﻟ ﻼﻜﻤﻣﺓ ﻢﻧ ﻼﻔﻌﻟ ﻼﻣﺎﻀﻳ ﻭ . » ﺪﯩﯨ - ﻲﻳﺪﻳ-ﻯﺪﯨ « » ﺐﻠﺣ - ﻲﺤﻣﻭ-ﺐﻠﺣ « » ﻁﺎﺧ - ﻲﺨﻃﻭ -ﻁﺎﺧ « ﻞﻓﺍ ﻢﻘﺻﻭﺭﺓ ﻢﺜﻟ ﺍﻸﺼﻟ ﻱﺍﺀ ﻚﺘﺒﺗ ﺃ ﻯﻭ ﻡﺍ ﻙﺎﻧ ﺂﺧﺮﻫ ﻱﺍﺀ ﻢﺜﻟ ﺥﻼﻳ، ﻉﻼﻳ، ﻢﻤﺗﻮﻳ ﻒﻗﺎﻋﺪﺗﻭ ﺄﻧ ﺕﺮﺴﻣ ﻱﺍﺆﻫ ﺇﺫﺍ ﻙﺎﻧ ﻭ ﺍﻼﺴﻣ ﻼﻤﻨﻗﻮﺻ : 12- ﻲﻋﻮﺿ ﻊﻨﻳﺍ ﻦﻛﺭﺓ ﻒﺘﺣﺬﻓ ﻱﺍﺆﻫ ﻒﻳ ﺡﻻﺓ ﻻﺮﻔﻋ ﻭﻼﺟﺭ ﻭ ﻢﻋﺮﻓﺍ ﺏﻻ ﻼﺘﻋﺮﻴﻓ ﺃﻭ ﻢﺿﺎﻓﺍ ﻺﻳﻭ، ﺄﻣﺍ ﺇﺫﺍ ﻙﺎﻧ ﻲﻧ ﻼﻋﻮﺿ ﻢﺜﻟ ﻢﻤﺗﻭ ، ﺡﻻ ، ﻉﻻ ﺈﻣﺍ ﺇﺫﺍ ﻙﺎﻧ ﻦﻛﺭﺓ ﻢﻨﺻﻮﺑﺓ ﻒﺘﺜﺒﺗ ﻱﺍﺆﻫ ﻢﺜﻟ ﺥﻼﻳﺍ، ﻢﻤﺗﻮﻳﺍ، ﻉﻼﻳﺍ . ﺐﺘﻧﻭ ﻢﻄﻤﻗ ﻞﻔﻌﻟ ﻢﺣﺫﻮﻓ، ﻕﻻ ﺍﻼﺴﺘﻌﻣﻻ ﻼﺼﺤﻴﺣ ﻞﻳﺍ ﺄﻧ ﺖﻛﻮﻧ ﺂﺧﺭ ﻼﻌﺑﺍﺭﺓ ﻸﻨﻳﺍ ﻢﻔﻋﻮﻟ ﺥﺎﺻﺓ : 13- ، ﺄﻣﺍ ﺇﺫﺍ ﺝﺍﺀﺕ ﻒﻳ ﻮﺴﻃ ﻼﻌﺑﺍﺭﺓ 25 ﺍﻸﻨﻓﻻ/ » ﻆﻤﻣﻭﺍ ﻢﻨﻜﻣ ﺥﺎﺻﺓ ﺎﺘﻗﻭﺍ ﻒﺘﻧﺓ ﻻ ﺖﺼﻴﺒﻧ ﻻﺬﻴﻧ ﻭ « ﺖﻋﻼﯨ ﻑﺈﻣﺍ ﺄﻧ ﺖﺤﻟ ﻢﺤﻤﻳﺍ ﻚﻤﻣﺓ `` ﻼﺴﻴﻣﺍ '' ﺃﻭ ﺖﻛﻮﻧ ﻢﺟﺭﻭﺭﺓ ﺐﺣﺮﻓ ﻼﺟﺭ ﻼﻳﺍﺀ ﺄﻳ `` ﺐﺧﺎﺻﺓ '' . 12 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺵﺎﺌﻋﺓ ﻕﻮﻠﻛ `` ﺭﺄﻴﺗ ﻙﺎﻓﺓ ﻼﻄﺒﻠﺑ '' ﻭﻼﺻﻭﺎﺑ `` ﺭﺄﻴﺗ ﻼﻄﺒﻠﺑ ﻙﺎﻓﺓ '' ، ﻮﻗﻻ ﻢﻧ ﺍﻸﺨﻃﺍﺀ ﻻ ﻙﺎﻓﺓ : 14- 36 . ﻼﺗﻮﺑﺓ/ » ﻕﺎﺘﻣﻭﺍ ﻼﻤﺷﺮﻜﻴﻧ ﻙﺎﻓﺓ ﻚﻣﺍ ﻲﻗﺎﺘﻣﻮﻨﻜﻣ ﻙﺎﻓﺓ ﻭ « ﺖﻋﻼﯨ ﻦﻔﺳﻭ '' ﻸﻧ ﺍﻸﺻﻮﺑ `` ﻕﺭﺄﺗ ﻼﻜﺗﺎﺑ ﺐﻳﺭ ﺄﻧ ﺖﻗﻮﻟ `` ﻕﺭﺄﺗ ﻦﻔﺳ ﻼﻜﺗﺎﺑ '' ﻭ ﻢﻧ ﺍﻸﺨﻃﺍﺀ ﻒﻳ ﻼﺘﻋ ﻦﻔﺴﻫ : 15- ﺍ ﻡﺍ ﺄﻧ ﺖﺘﻋﺪﯨ ﺓ ﺈﻣﺍ ﺄﻧ ﺖﺘﻋﺪﯨ ﺐﻨﻔﺴﻳﺍ ﻭ ﻼﻨﻔﺳ ﺈﻧ ﺖﻗﺪﻤﺗ ﻞﻣ ﺕﺪﻟ ﻊﻤﯨ ﻼﺗﺄﻜﻳﺩ ﺐﻟ ﺖﺧﺮﺟ ﻺﯨ ﻢﻌﻨﯨ ﺂﺧﺭ.16- ﺍﻸﻔﻋﻻ ﻒﻳ ﻼﻋﺮﺒﻳﺓ ﻻﺰﻣﺓ ﻮﻤﺘﻋﺪﻳﺓ، ﻭ ﺡﺭﻮﻓ ﻼﺟﺭ : ﻼﻤﺘﻋﺪﻳ ﻊﺿﺍ ﻲﺣﺍ، ﺍﻸﺨﻃﺍﺀ ﻚﺜﻳﺭﺓ ﻰﻧﺎﻛ ﺬﻛﺮﺗ ﺏ ﻮﻓ ﻼﺟﺭ ﺵﺮﻃ ﺄﻧ ﻲﻋﺮﻓ ﻢﻌﻨﯨ ﻼﺣﺮﻓ ﻞﻴﻛﻮﻧ ﻼﻜﺒﻠﻣ ﺺﺣ ﺐﺣﺭ ﺡ ﺄﻧ ﻲﻗﻻ `` '' ﺍﻺﺟﺎﺑﺓ ﻊﻧ ﻼﺳﺅﻻ ﻼﺼﺤﻳ ﻭ ) ﺄﺠﺑ ﻊﻤﯨ ﺍﻸﺴﺌﻣﺓ ﺍﻺﺟﺎﺑﺓ ﻊﻤﯨ ﻼﺳﺅﻻ ﻭ ﻢﻨﻳﺍ : ( ﻝ ﺩﺎﺌﻣﺍ ﺖﺴﺘﻌﻣ -ﺃ ﻼﺳﺅﻻ ﺃﺯﺎﺣ ﺝﺎﺑ ﻊﻧ ﻢﻌﻨﯨ ﺃ ﻝ `` ﺄﺟﺎﺑ '' ﺐﻤﻌﻨﯨ `` ﺃﺯﺎﺣ ﻭ ﻚﺸﻓ '' ﻭ ﺄﺠﺑ ﻊﻧ ﺍﻸﺴﺌﻣﺓ '' ﻭ ﻼﺴﺒﺑ ﺄﻧ ﻼﻔﻋ ﻭ ﻚﺸﻓ ﻊﻧﻭ ﺍﻺﺒﻳﺎﻣ، ﺄﻣﺍ ﺡﺮﻓ ﻼﺟﺭ `` ﻊﻤﯨ '' ﻒﻳﻭ ﻞﺒﻠﺴﺘﻌﺒﻟﺀ . ﻊﻧﻭ ﻼﻐﻣﻮﺿ ﻭ ﺐﻌﻀﻴﻣ ﻲﺣ ﻸﻧﻭ ﻲﻌﻨﻳ `` ﻒﺼﻟ ﻢﻧ ﻼﻜﻤﻳﺓ '' ﻭ ﻯﺫﺍ ﻼﺘﻌﺒﻳﺭ ﻎﻳﺭ ﺺﺣ ﻭ ) ﺖﺧﺮﺟ ﻼﻃﻼﺑ ﻢﻧ ﻼﻜﻤﻳﺓ ( ﻲﻗﻻ -ﺏ ﻱﺓ '' . ﻒﻳ ﻼﻜﻣ ﻲﻗﻮﻟ ﺄﻧﻭ ﻲﻌﻨﻳ ﻼﺧﺭﻮﺟ ﺍﻼﻌﺘﻳﺍﺪﻳ ﻚﻟ ﻱﻮﻣ ﻢﻧ ﻼﻜﻤﻳﺓ، ﺄﻣﺍ ﻼﺘﻌﺒﻳﺭ ﻼﺼﺤﻴﺣ ﻑﺄﻧ ﻲﻗﻻ `` ﺖﺧﺮﺟ ﻼﺗﺄﺜﻳﺭ ﻒﻳﻭ، ﻸﻧ ﺍﻼﺛﺭ ﻲﻛﻮﻧ ﻒﻳ ﺩﺎﺨﻟ ﻼﺸﻳﺀ ﻻ ﻭﺍﻸﺻﻮﺑ ﺄﺛﺭ ﻒﻳﻭ ﻭ ﻼﺗﺄﺜﻳﺭ ﻊﻤﻴﻫ ﺄﺛﺭ ﻊﻤﻴﻫ ﻭ -ﺕ ﻊﻤﻳﻭ . ﻼﺻﻭﺎﺑ `` ﺏﻻﺮﻐﻣ '' . ﺥﺎﻄﺋ ﻭ ﺎﺴﺘﻌﻣﻻﻭ ﻊﻤﯨ ﻻﺮﻐﻣ -ﺙ ﻲﻗﻻ `` ﺐﺼﻔﺘﻳ ﻢﺴﻤﻣ، ﻭﺄﻧﺍ ﻼﺼﺤﻴﺣ ﺄﻧ ﻲﻗﻻ `` ﺄﻧﺍ ﻚﻤﺴﻤﻣ ﺃﻭ ﺄﻧﺍ ﻚﻣﺩﺮﺳ '' ﻭ ﻑ ﻼﺘﺸﺒﻴﻫ ﺐﺣﺮﻓ ﻼﻛﺎﻓ -ﺝ ﺶﺒﻳﻭ ﻒﻜﻴﻓ ﺖﺸﺑﻭ ﺐﻨﻔﺴﻛ . ﻥ ﻼﻛﺎﻓ ﻞﻤﺗ ﺐﺼﻔﺘﻳ ﻡﺩﺮﺳ '' ﻷ ﻻﻮﺟ ﺩ : ﻯﻭ ﻼﺤﺑ ﻱ : ﺖﻇﺎﯨﺭ ﺃﻭ ﺃﻮﯩﻤﻛ ﺏﻻﻮﺟﺩ ) . ﻭ : ﺃﺮﯨ ﻢﻧ ﻦﻔﺳﻭ ﻻﻮﺟ ﺩ ( ﺃ : ﺕﻭﺎﺟﺩ ﻒﺒﻠﻧ ﺕﻭﺎﺟﺩ 17- ﻼﺷﺪﻳﺩ ﺃﻭ ﻼﺣﺰﻧ ( ﻊﻤﯨ ﻮﻔﻗ ﻼﺴﻳﺎﻗ ) . ﺩﺮﺟ ﺍﻷﻮﻟ ﻒﻳ ﻼﺳﺎﻋﺓ ﻙﺫﺍ . ﻖﻟ ﺇﺬﻧ : ﻊﻤﯨ ﻼﻄﺒﻠﺑ ﻼﺤﺿﻭﺭ ﻺﯨ ﻼﻣ 13 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻻ ﺖﻘﻟ : ( ﻊﻤﯨ ﻼﻄﺒﻠﺑ ﻼﺗﻭﺎﺟﺩ ) . ﻭ ﻞﺣﺪﻳﺩ ﻒﻳ ﻼﻄﺒﻴﻋﺓ ﺐﻜﺛﺭﺓ . ﻖﻟ : ﻱﻮﺟﺩ ﺍ ﻭ ﻻ ﺖﻘﻟ : ( ﻲﺗﻭﺎﺟﺩ ﻼﺣﺪﻳﺩ ﻒﻳ ﻼﻄﺒﻴﻋﺓ ) . ﻭ ﺲﺘﺧﺮﺟ ﻼﺣﺪﻳﺩ ﻼﻣﻮﺟﻭﺩ . ﻖﻟ : ﻱ ﻭ ﻻ ﺖﻘﻟ : ( ﻲﺴﺘﺧﺮﺟ ﻼﺣﺪﻳﺩ ﻼﻤﺗﻭﺎﺟﺩ ) . ﻭ ﻢﻧ ﺄﺨﻃﺍﺀ ﻼﻤﺗﺮﺠﻤﻴﻧ ﺎﺴﺘﻌﻣﻼﻴﻣ ( ﻚﻤﻣﺍ ) ﻡﺮﺘﻴﻧ ﻒﻳ ﺞﻤﻣﺓ ﻚﻤﻣﺍ ( ﻻ ﺖﻛﺭﺭ ﻒﻳ ﺞﻤﻣﺓ ﻭﺎﺣﺩﺓ ) : 18- ﻚﻤﻣﺍ ﺍﻼﻄﺒﻠﻋ، ﻒﻳ ﻼﻗﺭﺍﺀﺓ ﻭ ﻦﺣﻭ ﻕﻮﻠﻴﻣ : `` ﻚﻤﻣﺍ ﺖﻌﻤﻘﺗ ﻭﺎﺣﺩﺓ، ﻊﻤﯨ ﻍﺭﺍﺭ ﻼﺗﺮﻜﻴﺑ ﻼﻓﺮﻨﺴﻳ ﺃﻭ ﺍﻼﻨﻜﻤﻳﺰﻳ، ﻚﻤﻣﺍ ﺪﺨﻟ ﻊﻤﻴﻳﺍ « ﺰﻴﻟ ﻼﻋﺰﻳﺯ : ﻒﻳ ﻼﺘﻧ ﻑ ( ﻚﻤﻣﺍ ) ﻼﺛﺎﻨﻳﺓ . ﻭ ﻼﺻﻭﺎﺑ ﺡﺫ ﺯﺍﺪﺗ ﺢﺼﻴﻤﺘﻛ ﻢﻧ ﻼﻤﻋﺮﻓﺓ '' ﻭ 37 . ﻵ ﻊﻣﺮﻧ/ » ﺰﻗﺍ ﻊﻧﺪﯨﺍ ﺭ ﺩ ﺝ ﺰﻛﺮﻳﺍ ﻼﻤﺣﺭﺎﺑ ﻭ ﻲﻗﻻ : ﻚﻤﻣﺍ ﺯﺍﺩ ﺎﻄﺒﻠﻌﻛ، ﺎﺘﺴﻌﺗ ﺂﻓﺎﻘﻛ . ﻕﺩ ﺖﺒﻴﻧ ﺎﺴﺘﻌﻣﻼﻳﺍ ﻚﻴﻛﺓ ﺝﺩﺍ ﺵﺎﻌﺗ ﺶﻳﻮﻋﺍ ﻭﺎﺴﻋﺍ . ﻭ ﺏﻼﺗﻼﻳ ﺶﺑﻭ ﺞﻤﻣﺓ ﺭ ، ﻝﺫﺍ ) : ﻡ ﻮﻤﻧ ﺙ ! . ﻩ ﻝﻶﺧﺮﻴﻧ ﻖﻟ ﺎﻨﺘﻗﺍﺩ ﻲﻗﻻ : ﻚﻤﻣﺍ ﺯﺍﺩ ﻉ ﻢﻣ ﻼﻣﺭﺀ، ﻭ 19- ( ﺏﻼﺗﻼﻳ - ﻡ؛ ﻝﺫﺍ؛ ﻮﻌﻤﯨ ﻊﻧﺩ ﻚﺜﻳﺭ ﻢﻧ ﻼﻤﻗﺍﻼﺗ ﻼﻌﻤﻤﻳﺓ ﺄﻧ ﻼﺻﻭﺎﺑ ﺄﻧ ﻲﺤﻟ ﻢﺤﻤﻳﺍ ﻡﺍ ﻲﻧﺎﺴﺑ ﻼﻤﻗﺎﻣ، ﻢﺜﻟ : ﻢﻧ ﺙ ... ﻺﺧ ﻢﻧ ﺚﻣ ﻲﺘﻀﺣ/ ﻦﺟﺩ/ ﻥﺮﯨ ﺄﻧ؛ ﻯﺫﺍ؛ ﻮﺑﺬﻠﻛ؛ ﺇﺬﻧ؛ ﺄﻳ ؛ ﻭ ﻺﯨ ﻼﻤﻛﺎﻧ ﻼﺒﻌﻳﺩ ﺐﻤﻌﻨﯨ ﻰﻧﺎﻛ، ﻮﯨﻭ ﻅﺮﻓ ﻻ ﻲﺘﺻﺮﻓ، ﻮﻗﺩ ﺖﻤﺤﻗﻭ ) ﺎﺴﻣ ﻲﺷﺍﺭ ﺏﻭ ﻡ ﻮﻠﻤﻓﺎﺋﺩﺓ ﻦﻗﻮﻟ : ( ﺙ ﻱﻮﻘﻓ ﻊﻤﻴﻳﺍ ﺏﻼﻳﺍﺀ . ﻼﺗﺍﺀ ﻒﻴﻗﻻ ( ﺚﻣﺓ ) ﻭ ﻞﺗﺍﺀ ﻼﻤﻔﺗﻮﺣﺓ ﻒﻴﻗﻻ : ﺖﻤﺤﻗﻭ ﺍ ﺭﺎﺨﻳ ﻒﻳ ﻻﺰﻤﻧ، ﻭ ﺄﻣﺍ ( ﺚﻣ ) ﻒﻳﻭ ﺡﺮﻓ ﻊﻄﻓ ﻱﺪﻟ ﻊﻤﯨ ﻼﺗﺮﺘﻴﺑ ﻢﻋ ﻼﺗ ﻞﺻﻭﺎﺑ : ﻻﻭﺍﺮﺛ؛ ﺇﺫ ﻞﻣ ﺖﺴﻤﻋ `` ﻭﺮﻴﺛ '' ﻲﻗﻻ ﻒﺒﻠﻧ ﻯﻭ ﻻﻭﺮﻴﺛ ﻻﻮﺤﻳﺩ، ﻭﺄﻌﻃ ﻻﻭﺮﻴﺛ ﺢﻗﻭ، ﻭﺍ ﻭﺮﻴﺛ : 21- ﻱﻮﻘﻓ ﻊﻤﻴﻳﺍ ﺏﻼﺗﺍﺀ . ﺚﻤﺗ ، ﻭ ﻒﻳ ﻚﺒﻠﻣ ﻼﻋﺮﺑ، ﻭ ﻞﻣ ﺕﺭﺩ ﻒﻳ ﻢﻋﺎﺠﻣ ﻼﻤﻏﺓ . 14 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻒﻳ ﻼﻗﺭﺂﻧ : ﻭ ﺲﻴﻣ، ﻸﻧ ﺱﺎﯩﻣ ﻢﻌﻧﺎﯨﺍ ﺎﻘﺗﺮﻋ، ﻲﻗﻻ ﺱﺎﯩﻣ ﻒﻳ ﻼﻌﻤﻟ، ﻭ ﻼﺻﻭﺎﺑ : ﺃ ﺄﺴﻬﻣ ) : - ( ﺱﺎﻬﻣ 21- ﻊﻤﯨ ﻼﻗﺭﺍﺀﺓ، ﻭ ﻼﺻﻭﺎﺑ : ﺖﻋﻭﺪﺗ ﻼﻗﺭﺍﺀﺓ، ﻸﻧ ﻼﻔﻌﻟ ( ﺖﻋﻭﺩ ) ﻲﺘﻋﺪﯨ ﺐﻨﻔﺳﻭ . `` .ﻥ ﻱ ﺽ ﺡ ﺩ ﻼﻣ ﻥ ﻡ ﺎﻧ ﻙ ﻑ ﻡ ﺎﯨ ﺱ `` ﻑ 22- ﻲﻗﻻ ﺖﻋﻭ ﺖﻋﻭﺩ : ﺕ ﺩ ( ﺐﺴﻴﻃ ) ﻭﻼﺻﻭﺎﺑ : ﺲﻴﻟ ﺃﻭ ﻲﺴﻳﺭ، ﻭ ﻲﻗﻻ : ﻼﺳﺅﻻ ﺐﺴﻴﻃ ﺖﻘﺻﺩ ﺄﻧﻭ ﻞﻴﺳ ﺺﻌﺑﺍ، ﺲﻬﻟ ) : - ( ﺐﺴﻴﻃ 23- ﺐﺴﻴﻃ . ﻢﻛﺎﻧ ﻢﺘﺴﻋ، ﺖﻗﻮﻟ ﺃﺮﺿ ﺐﺴﻴﻃﺓ، ﻭ ﻢﻌﻧﺎﯨﺍ/ ﻢﻤﺗﺩ ﻭ ﻁﺍﺀ ﻼﻤﻏﻮﻳﺓ ﻼﺷﺎﺌﻋﺓ ﺖﻋﺮﻴﻓ `` ﻚﻟ ﻮﺒﻌﺿ ﻮﻐﻳﺭ '' ﺐـ ﻻ ﻼﺘﻋﺮﻴﻓ، ﻭﺍﻸﺻﻮﺑ ﺄﻨﻳﺍ ﻻ ﺖﻋﺮﻓ ﻢﻧ ﺍﻸﺧ 24- ﻼﺻﻭﺎﺑ ﻢﻧ ﻼﺒﻠﻔﺗ ﻞﻤﻨﻇﺭ، ﻸﻧ ﺎﺴﻣ ﺎﺌﻋﺓ ﻕﻮﻠﻛ : `` ﻢﻧ ﻼﻤﻤﻔﺗ ﻞﻤﻨﻇﺭ '' ، ﻭ ﻢﻧ ﺍﻸﺨﻃﺍﺀ ﻼﻤﻏﻮﻳﺓ ﻼﺷ 25- ﻻ ﺖﻘﻟ : ﻻﺩﻭﺍﺀ ﻼﻐﻳﺭ ﻥﺎﻔﻋ . ﺐـ ﻻ، ﻖﻟ : ﻻﺩﻭﺍﺀ ﻎﻳﺭ ﻼﻧﺎﻔﻋ، ﻭ ﻼﺻﻭﺎﺑ ﻱﺆﻛﺩ ﺍﻸﻣﺭ، ﻸﻧ ﻼﻔﻌﻟ ﺄﻛﺩ `` ﺵﺎﺌﻋﺓ ﻕﻮﻠﻛ : `` ﻱﺆﻛﺩ ﻊﻤﯨ ﺍﻸﻣﺭ '' ، ﻭ ﻢﻧ ﺍﻸﺨﻃﺍﺀ ﻼﻤﻏﻮﻳﺓ ﻻ 26- '' ﻞﻔﺗ '' ﻲﺠﻳﺀ ﻊﻤﯨ `` ﻑﺎﻌﻟ '' . ﻼﻓﺎﻌﻟ ﻢﻧ ﻼﻔﻌﻟ ﻲﺘﻋﺪﯨ ﺐﻨﻔﺳﻭ . ﻼﺻﻭﺎﺑ : `` ﺎﺤﺘﺠﺗ ﻺﯨ ﺐﻌﺿ ﻼﻜﺘﺑ '' ، ﻸﻧ ﻲﻗﻻ : `` ﺎﺤﺘﺠﺗ ﺐﻌﺿ ﻼﻜﺘﺑ '' ، ﻭ ( ﺎﺤﺗﺎﺟ، ﻲﺤﺗﺎﺟ ﻺﯨ ) : 27- ﻡ '' . ـ `` ﻺﯨ '' ﺃﻭ `` ﻼﺒﻟ ﺎﺤﺗﺎﺟ ﻲﺠﺑ ﺄﻧ ﻲﺘﻋﺪﯨ ﺏ ﻼﻔﻌﻟ `` ﺭﺎﺘﺑ '' ، ﻸﻧ ﺍﻼﺴﺘﺒﻠﻣ ﻯﻭ ﻼﺻﻭﺎﺑ : `` ﺖﺴﻤﻤﺗ ﻻ ﻞﻤﻏﻮﻳﺓ ﻕﻮﻠﻛ : `` ﺎﺴﺘﻤﻤﺗ ﻻﺭﺎﺘﺑ '' ، ﻭ ﻢﻧ ﺍﻸﺨﻃﺍﺀ ﺍ 28- ﻼﺘﺴﻤﻣ ﻯﻭ ﺍﻸﺧﺫ، ﻒﻴﻟ ﺄﻨﺗ ﺖﻤﻤﺳ ﺭﺎﺘﺒﻛ ﺄﻣ ﺕﺄﺧﺬﻫ ؟ . ﻼﻤﻤﺳ، ﻭ ﺇﺫﺍ ﻙﺎﻧ ﻼﻤﻘﺻﻭﺩ ﻼﻃﺮﻴﻗ ﻻﺬﻳ ﻦﺴﻳﺭ ﺏﻭ ﻒﺠﻤﻋﻭ ﻁﺮﻗ، ﺄﻣﺍ ﺇﺫﺍ ﻙﺎﻧ ﻼﻤﻘﺻﻭﺩ ﻼﻃﺮﻴﻗﺓ ﺃﻭ ﻁﺮﻗ : 29- ﻁﺭﺎﺌﻗ ﻼﻌﻤﻟ ) . ﺎﺌﻗ ﻊﻤﯨ ﺲﺒﻴﻟ ﻼﻤﺛﻻ : ( ﻼﻣﻭﺍﺩ ﻭ ﻒﺠﻤﻌﻳﺍ ﻁﺭ ﻻﻮﺳﺎﻃﺓ ﻸﻳ ﺶﻳﺀ ﻙﺎﻧ ﻼﺼﺤﻴﺣ ﺖﺼﺤﻴﺣ ﺃﻭﺭﺎﻗ ﺍﻼﻤﺘﺣﺎﻧ . ﻭ ﺖﺼﻤﻴﺣ ﺃﻭﺭﺎﻗ ﺍﻼﻤﺘﺣﺎﻧ : 31- ﻼﻤﻘﺻﻭﺩ ﺐﻳﺍ ( ﺚﺒﺗ ) ، ﻭﺭﺩ ﻒﻳ ﻢﻌﺠﻣ ﻞﺳﺎﻧ ﻼﻋﺮﺑ ﻭﻼﺘﻳﺬﻴﺑ ﻡﺍﺩﺓ ( ﺮﯩﻧ ) ﻭ ﺍﻷﻮﺿﺎﻋ ﻻﺭﺎﻬﻧﺓ : 31- ﻑﻼﺼﺤﻴﺣ ﺄﻧ ﺖﻗﻮﻟ ﺍﻷﻮﺿﺎﻋ ﻼﺣﻼﻳﺓ ﺃﻭ ﻼﺣﺎﺿﺭﺓ ﺃﻭ ﻼﻃﺍﺮﺋﺓ . 15 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻼﺼﺤﻴﺣ ﻒﻴﻳﺍ ﻒﻀﺒﻟ ﻊﻧ . ﻭ ﺏﺍﻺﺿﺎﻓﺓ ﻺﯨ : 32- ﺲﺒﻴﻟ ﻼﻤﺛﻻ : `` ﺄﺷﺍﺭﺍ ﻼﺑﺎﺤﺛﺎﻧ ﻭﺄﺷﺍﺭﻭﺍ ﻢﻣﺓ ﻊﻤﯨ ﻢﻋ ﻼﻔﻌﻟ ﺇﺫﺍ ﻙﺎﻧ ﻒﻳ ﺃﻮﻟ ﻼﺟ ﺝ ﻢﻧ ﻼﺨﻃﺃ ﺖﺜﻨﻳﺓ ﻭ 33- ﻼﺑﺎﺤﺛﺎﻧ، ﺄﺷﺍﺭ ﻼﺣﺍﻼﺗ ﻒﺘﻗﻮﻟ : `` ﺄﺷﺍﺭ ﻼﺑﺎﺤﺛ، ﻭ ﻼﺼﺤﻴﺣ ﺄﻧ ﻱﺄﺘﻳ ﻼﻔﻌﻟ ﻢﻓﺭﺩﺍ ﻒﻳ ﺞﻤﻴﻋ ﻼﺑﺎﺤﺛﻮﻧ '' ، ﻭ ﻼﻓﺎﻌﻟ ﻡﺆﻨﺛﺍ ﻒﻨﻗﻮﻟ : `` ﺄﺷﺍﺮﺗ ﻼﺑﺎﺤﺛﺓ '' . ﺄﺷﺍﺭ ﻼﺑﺎﺤﺛﻮﻧ '' ، ﺎﻣﺍ ﻊﻧﺪﻣﺍ ﻲﻛﻮﻧ ﻭ ﻥ ﻱﺯﺍﻮﻟ ﺬﻠﻛ ﻞﺘﻃﻭﺭ ﺩﻼﻟﺓ ﻯﺬﻫ ﻼﻜﻤﻣﺓ ﻑﺄﺼﺒﺤﺗ ﺖﻄﻤﻗ ﻊﻤﯨ ﻡ ﻭﻼﺼﺤﻴﺣ ( ﺎﺴﺘﻌﻣﻻ ) ﻭ ﺎﺴﺘﺧﺩﺎﻣ : 34- ﻢﺴﺘﺧﺪﻣﻮﻧ، ﻝﺫﺍ ﻑﻼﺼﺤﻴﺣ ﺄﻧ ﻦﻄﻤﻗ ﻞﻐﻳﺭ ﻯﺫﺍ ﻢﻴﻧﺓ ﻉﺎﻤﻟ ﻼﻨﻇﺎﻓﺓ ﻮﻣﺍ ﺵﺎﺒﻴﻳﺍ ﻒﻴﻄﻤﻗ ﻊﻤﻴﻳﺍ ﻢﺴﺘﺧﺪﻣ ﻭ ﺺﺤﻴﺣ ﺄﻧ ﻦﻗﻮﻟ : ﻻ ﻚﻤﻳﺍ ﻢﺼﻄﻤﺣﺎﺗ ﺥﺎﻄﺋﺓ ﻭ ﻼﺳﺎﺒﻗﺓ ﻻﺬﻛﺭ : ﺭ ﻭ ﺂﻨﻓﺓ ﻻﺬﻛﺭ ﻭﻼﺳﻼﻓﺓ ﻻﺬﻛ 35- ﻼﺸﻳﺀ ( ﺎﺴﺘﻌﻤﻟ ) . ﻼﻣﺬﻛﻭﺭﺓ ﺱﺎﺒﻗﺍ '' . `` ﻼﻣﺬﻛﻭﺭﺓ ﺂﻨﻓﺍ ﻭﻼﻣﺬﻛﻭﺭﺓ ﺲﻤﻓﺍ ﻭ ﺍﻶﺘﻳﺓ . ﻦﺴﺘﻌﻤﻟ ﺏﺩﻻ ﻊﻨﻳﺍ ﻚﻤﻣﺓ ﻱﺄﺘﻳ ﻭ ←ﻼﺗﻼﻳ-ﻲﻤﻳ ﻼﻳﺍ ﺥﺎﻄﺋﺍ ﻒﻳ ﻢﺜﻟ ﻯﺬﻫ ﻼﺣﻻﺓ ﻚﻤﻣﺓ ﺐﻘﻳﺓ ﺖﻌﻨﻳ ﻦﻳﺎﻳﺓ ﻼﺸﻳﺀ ﻝﺫﺍ ﻲﻛﻮﻧ ﺎﺴﺘﻌﻣ ﺐﻘﻳﺓ ﻼﺣﺍﻼﺗ : 36- ﻦﻗﻮﻟ : ﻼﺣﺍﻼﺗ ﺍﻼﺧﺮﯨ ﺃﻭ ﺍﻸﻧﻭﺎﻋ ﺍﻼﺧﺮﯨ ﻖﻳﺩ ﻻﺩﺭﺎﺳﺓ . ﻼﺼﺤﻴﺣ ﺄﻧ ﻭ ﻚﻤﻣﺓ ( ﻭﻼﺴﻴﻣﺍ ) ﻲﺠﺑ ﺄﻧ ﺕﺮﻔﻋ ﻖﺒﻟ ﻚﻤﻣﺓ ( ﻚﻤﻣﺍ ) ﻭ ﻻﺬﻳ ﻭﻼﺘﻳ ) ﻭ ﻢﺜﻟ ( ﻭ ﻻﻭﺍﻭ ﻖﺒﻟ ﺍﻼﺴﻣ ﻼﻣﻮﺻﻮﻟ : 37- ﺡﺎﺟﺓ ﻞﻣﺮﺒﻃ ﺐﻳﺍ . ﻻ ﻢﺘﻌﻤﻴﻟ ﻒﻴﻛﻮﻧ ﺎﺴﺘﻌﻣﻼﻳﺍ ﺖﻛﻮﻧ ﺺﺤﻴﺣﺓ ﺍﻼﺴﺘﻌﻣﻻ ﺇﺫﺍ ﺪﻠﺗ ﻊﻤﯨ ﻼﻇﺮﻓ، ﺄﻣﺍ ﺇﺫﺍ ﻙﺎﻨﺗ ﻝ ﺢﻴﺛ : 38- ﻲﻤﺘﺒﺳ ﺕﺍﺀ ﺢﺘﯨ ﻻ ﻲﺨﺘﻤﻃ ﻢﻋ ﺡﺮﻓ ﻼﻳﺍﺀ ﻭ ﺬﻠﻛ ﺏﻮﻀﻋ ﻼﻨﻗﺎﻃ ﻊﻤﯨ ﻻ ﻭ ﻼﺗﺍﺀ : ﻼﺘﻓﺮﻴﻗ ﺐﻴﻧ ﻼﻫﺍﺀ ﻭ 39- ﻼﺼﺤﻴﺣ ﺎﺴﺘﻌﻣﻻ ﻚﻤﻣﺓ ( ﺇﺫ ) . ﻭ ﺥﺎﻄﺋﺍ ﻼﻤﻌﻨﯨ . 16 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺄﻧ ﻼﻤﺼﻄﻤﺣﺎﺗ ﺍﻸﺠﻨﺒﻳﺓ ﻢﻧ ﺄﻳ ﻞﻏﺓ ﻙﺎﻨﺗ ﻲﺠﺑ ﻚﺗﺎﺒﺘﻳﺍ ﺏﻼﻤﻏﺓ ﻦﻔﺴﻳﺍ، ﺃﻭ ﺖﺗﺮﺠﻣ ﻺﯨ ﻼﻋﺮﺒﻳﺓ ﻻ 41- ﻼﺘﺜﻨﻳﺓ ﻭﻼﺠﻤﻋ ﻮﻐﻳﺮﯨﺍ ﻸﻧ ﻞﻜﻟ ﻞﻏﺓ ﺄﺴﻣﻮﺒﻳﺍ ﺖﻜﺘﺑ ﻚﻣﺍ ﺖﻤﻔﻇ ﻒﻳ ﺖﻤﻛ ﻼﻤﻏﺓ ﻭﺍ ﻻ ﺖﺨﻀﻋ ﻺﯨ ﺖﺼﻨﻓ ﻊﻤﯨ . ﻭﻼﺼﺤﻴﺣ ﻒﻴﻳﺍ ﺖﻘﺴﻣ ﻊﻤﯨ ﻭ ﺖﻨﻘﺴﻣ ﻺﯨ، ﺖﺼﻨﻓ ﻺﯨ : 41- ﻢﺼﻄﻤﺣﺎﺘﻳﺍ . ﻭ ﻡﺍ ﺐﻋﺪﯨﺍ ﻢﻨﺻﻮﺑ ﻚﻗﻮﻟﻭ ﺖﻋﻼﯨ : ﺖﻛﻮﻧ ﺄﻣﺍ ﻰﻧﺍ ﺖﻔﺼﻴﻤﻳﺓ ﻭ ﺄﻣﺍ ﺏﻼﻨﺴﺑﺓ، ﺄﻣﺍ ﺐﺨﺻﻮﺻ، ﺄﻣﺍ ﺐﺷﺄﻧ : 42- ﻼﻤﺼﻄﻤﺣﺎﺗ . ﻩ ، ﻒﺒﻟ ﺩﺎﻌﻳ ﻞﻤﻤﺠﻳﺀ ﺐﻳﺫ 9 ﻼﻀﺤﯨ/ » ﺄﻣﺍ ﻼﻴﺘﻴﻣ ﻒﺒﻟ ﺖﻘﻳﺭ « ﺃﻻ ﺄﻳ ﺕﺪﻐﻣ ﺇﺫﺍ ﻙﺎﻧ ﺐﻋﺪﯨﺍ ﻒﻌﺒﻟ ﻢﺿﺍﺮﻋﺍ . ﺄﻧ+ﻻ : 43- ﻻ ﺕﺪﻐﻣ ﺇﺫﺍ ﻙﺎﻧ ﺐﻋﺪﯨﺍ ﺎﺴﻣﺍ . ﻢﺜﻟ : `` ﺄﺸﻳﺩ ﺄﻧ ﻻ ﻹﻭ ﺇﻻ ﺎﻬﻠﻟ . ﺄﻧ+ﻻ : ﻼﺼﺤﻴﺣ ﻒﻴﻳﺍ ( ﺏﻻﺮﻐﻣ ) . ﻊﻤﯨ ﻻﺮﻐﻣ : ﺄﺳﺎﺳ . ﺍ ﻒﺘﻗﻮﻟ : ﺮﺌﻴﺳ ﻭ ﺖﺣﺬﻓ ﻼﻳﺍﺀ ﻰﻧ ﺮﺌﻴﺴﻳ، ﺄﺳﺎﺴﻳ : 44- 45- ﻼﻤﺧﻼﻓﺓ ﻢﻋ ﻚﺗﺎﺑﺓ ﺍﻸﻋﺩﺍﺩ ﻢﻧ ﺢﻴﺛ ﻼﻤﻃﺎﺒﻗﺓ ﻭ ﻲﺠﺑ ﺖﻄﺒﻴﻗ ﻕﺎﻋﺩﺓ ﺍﻸﻋﺩﺍﺩ : ﻻﻮﺣﺩﺎﺗ ﻼﻘﻳﺎﺴﻳﺓ ﻭ 46- ) ﻑﺈﻧﻭ 16 ) ﺖﺧﻼﻓ ﻼﻤﻋﺩﻭﺩ، ﺄﻣﺍ ﻼﻋﺩﺩ ( 9 ،3 ) ﺖﻃﺎﺒﻗ ﻼﻋﺩﺩ، ﻭ ﺍﻸﻋﺩﺍﺩ ( 2 ،1 ﻼﻤﻋﺩﻭﺩ، ﻑﺍﻸﻋﺩﺍﺩ ( ﻲﻃﺎﺒﻗ ﺇﺫﺍ ﻙﺎﻧ ﻡﺮﻜﺑﺍ . ﻲﺧﻼﻓ ﺇﺫﺍ ﻙﺎﻧ ﻢﻓﺭﺩﺍ ﻭ ( ﻙﻮﻧﻭ ) . ﻼﺼﺤﻴﺣ ﺏﻼﺤﺴﺑﺎﻧ، ﺄﻣﺍ ﻚﻤﻣﺓ ﺏﺎﻌﺘﺑﺍﺮﻫ ﻒﺘﺼﺤﺣ ﻺﯨ ﺐﻨﻇﺭ ﺍﻼﻌﺘﺑﺍﺭ : 47- ﻁﺍﺮﻴﺣ ﻼﺳﺎﺒﻗﺓ ﻢﻋ ﻦﻔﺳﻭ ﻻ ﺍﻼﻌﺘﻣﺍﺩ ﻊﻤﯨ ﻻﺮﺳﺎﺌﻟ ﻭﺍﻻ ﻲﺠﺑ ﻦﻘﻟ ﺍﻶﻳﺓ ﻢﻧ ﻼﻗﺭﺂﻨﻳﺓ ﻢﻧ ﻼﻗﺭﺂﻧ 48- ﻡﺭﺎﻋﺍﺓ ﺢﺻﺭ ﻚﺒﻠﻣ ﺎﻬﻠﻟ ﺖﻋﻼﯨ ﺐﻴﻧ ﺍﻸﻗﻭﺎﺳ . ﻁﺍﺮﻴﺣ ﻼﺟﺎﻤﻌﻳﺓ ﻲﻛﻮﻧ ﺥﺎﺻﺍ ﺏﻼﺟﺩﺍﻮﻟ ﻭﻼﺻﻭﺭ ﻻ ﻎﻳﺭ . ﻼﺘﻣﻮﻴﻧ ﻒﻳ ﻻﺮﺳﺎﺌﻟ ﻭﺍﻻ 49- ﻲﻛﻮﻧ ﻚﻟ ﺶﻳﺀ ﺏﺪﻗﺓ ﻢﺘﻧﺎﯩﻳﺓ ﻊﻤﯨ ﺲﺒﻴﻟ ﻼﻤﺛﻻ ﻻ ﻦﻗﻮﻟ ﻁﺍﺮﻴﺣ ﻼﻌﻤﻤﻳﺓ ﻲﺠﺑ ﺄﻧ ﻒﻳ ﻻﺮﺳﺎﺌﻟ ﻭﺍﻻ 51- ﻉﺩﺓ ﺄﻳﺎﻣ ﺃﻭ ﻉﺩﺓ ﺄﺸﻳﺭ ﺃﻭ ﺐﻀﻋ ﺙﻭﺎﻧ ﺃﻭ ﺎﺴﺘﻌﻣﻻ ﻼﻣﺍﺀ ﺩﻮﻧ ﺖﺣﺪﻳﺩ ﻥﻮﻌﻴﺗﻭ . ﻞﻴﺳ ( ﺃﻭ ) . ﺕﺄﺘﻳ ﺐﻋﺪﯨﺍ ﻚﻤﻣﺓ ( ﺄﻣ ) ﻭ ﺱﻭﺍﺀ ﺃ ﻙﺎﻧ : 51- 17 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻭﻼﺣﺩ ﻥ `` ﺕﻮﻓﺮﺗ '' ﺐﻤﻐﺗ ﻼﻋﺩﺩ ﻼﻤﻄﻣﻮﺑ ﺬﻠﻛ ﻷ ﻑﺮﺗ ﻭﻼﻤﺗﻭﺎﻓﺭﺓ ﻭ ﻼﺨﻃﺃ ﻕﻮﻟ ﺕﻭﺍ ﻭ ﺕﻮﻓﺮﺗ، ﻼﻤﺗﻮﻓﺭﺓ : 52- ﻯﺫﺍ ﺦﻃﺃ ﻸﻧ ﻚﻤﻣﺓ ( ﻻﺫﺎﺗ ) ﻞﻴﺴﺗ ﻢﻧ ﻸﻓﺎﻇ ﺎﺴﺘﻌﻣﻻ ﻚﻤﻣﺓ ( ﺏﻻﺫﺎﺗ ﻭﺫﺎﺗﻭ ) ﺏﺩﻻ ﻢﻧ ( ﻦﻔﺳﻭ ) ﻭ 53- ﻼﻤﺗﻭﺎﻓﺭﺓ ﻒﺒﻤﻌﻨﯨ ﺖﻛﺎﺛﺮﺗ . ﻼﻤﻌﻴﻧ، ﺄﻣﺍ ﺕﻭﺎﻓﺮﺗ ﻭ ﻼﺗﻮﻜﻳﺩ . ﻮﻠﻴﺳ ﺺﺤﻴﺣﺍ ﻕﻮﻠﻛ ﻼﺤﻣﺭﺍﺀ ﻭﻼﺒﻴﺿﺍﺀ ﺍﻷﻭﺭﺎﻗ ﻼﺨﺿﺭ : ﻙﺮﻳﺎﺗ ﻻﺪﻣ ﻼﺤﻣﺭ ﻮﻛﺮﻳﺎﺗ ﻻﺪﻣ ﻼﺒﻴﺿ ﻭ 54- ﺓ ﻼﻋﺮﺒﻳﺓ ﻼﺴﻴﻣﺍ ﻒﻳ ﺺﻴﻏﺓ ﺄﻔﻌﻟ ﻼﻣﻮﺻﻮﻓ ﻭﺎﺠﺑﺓ ﻒﻳ ﻼﻤﻏ ﻞﻤﻃﺎﺒﻗﺓ ﺐﻴﻧ ﻼﺼﻓﺓ ﻭ ﻭﻼﺨﺿﺭﺍﺀ ﻭﺬﻠﻛ ﻸﻧ ﺍ ﻮﻤﻧ ﻼﺠﺑﻻ ﺝﺩﺩ ﺐﻴﺿ ﻮﺤﻣﺭ ﻢﺨﺘﻤﻓ ﻷﻭﺎﻨﻳﺍ ﻮﻏﺭﺎﺒﻴﺑ « ﻮﻣﺆﺜﻧﻭ ﻒﻌﺒﻟﺀ، ﻝﺆﻠﻃﻭﻻ ﻭﺍﻸﻟﻭﺎﻧ، ﻕﻻ ﺖﻋﻼﯨ : ﺲﺒﻋ ﻭ « ، ﻮﻗﻻ ﺖﻋﻼﯨ : 21 ﺍﻺﻨﺳﺎﻧ/ » ﺎﺑ ﺲﻧﺪﺳ ﺦﺿﺭ ﻊﻤﻴﻴﻣ ﺚﻳ « ﻼﯨ : ﻕﻻ ﺖﻋ ، ﻭ 27 ﻑﺎﻃﺭ/ » ﺱﻭﺩ 46 . ﻱﻮﺴﻓ/ » ﺽﺭ ﺲﻨﺒﺒﻠﺗ ﺥ ﺎﺣﺪﯨ ﺎﺴﺘﻧﺍﺩﺍ ﻺﯨ ﻸﻧ ﺍﻺﺴﻧﺍﺩ ﻲﻘﻋ ﻊﻤﯨ ﻼﺸﻳﺀ ﻼﺛﺎﺒﺗ ﻢﻧ ﻢﻧ ﻼﺨﻃﺃ ﻕﻮﻟ ﺎﺴﺘﻧﺩ ﻊﻤﯨ ﻭﻼﺼﺤﻴﺣ 55- ﺐﻟﺀ ﺄﻳ ﻻﻮﻗﻮﻋ ﻊﻤﯨ ﻼﺸﻳﺀ ﻢﻧ ﺄﻌﻤﯨ ﻻ ﻢﻧ ﻼﺠﻳﺎﺗ ﻻ ﻢﻧ ﺞﻳﺓ ﻼﻌﻣﻮﻣ ﻮﺣﺮﻓ ﻼﺟﺭ ( ﻊﻤﯨ ) ﻲﻔﻳﺩ ﺍﻼﺴﺘﻋ ﻼﺘﻘﺼﻳﺭ ﺃﻭ ﻻﺬﻨﺑ . ﻢﻧ ﻼﺨﻃﺃ ﻕﻮﻟ ﺎﻌﺗﺫﺭ ﻊﻧ ﻖﻟ ﺎﻌﺗﺫﺭ ﻢﻧ ﻼﺘﻘﺼﻳﺭ ﺃﻭ ﻻﺬﻨﺑ ﻭ 56- ﻢﻧ ﻼﺨﻃﺃ ﻕﻮﻟ ﻒﺒﻠﻧ ﺫﻭ ﻚﻓﺍﺀﺓ ﻭﻼﺼﺤﻴﺣ ﺄﻧ ﺖﻗﻮﻟ ﻒﺒﻠﻧ ﺫﻭ ﻚﻓﺎﻳﺓ ﻭﺬﻠﻛ ﻸﻧ ﻢﻌﻨﯨ ﻼﻜﻓﺍﺀﺓ 57- ﻯ ﻚﻓﺎﻳﺓ ﺄﻳ ﻁﺎﻗﺓ ﻼﻌﻤﻟ ﻒﻳ ﻻﻮﻈﻴﻓﺓ ﻻ ﻲﺤﺗﺎﺟ ﻺﯨ ﻚﻓﺍﺀﺓ ﺄﻳ ﻢﺳﺍﻭﺍﺓ ﺐﻟ ﻲﺤﺗﺎﺟ ﻹ ﻼﻤﺳﺍﻭﺍﺓ ﻭﻼﻤﻣﺎﺜﻣﺓ، ﻭ ﻼﺟﺎﻨﺑ . ﻕﺩﺭﺓ . ﻭ ﻼﻇﺍﺀ ﻼﺿﺍﺩ ﻭ 18 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺚﺒﻠﺛﺍ « ﺓ ﻍﺓ ﻼﻋﺮﺒﻳﺓ ﻚﻣﺍ ﺢﺻﺮﯨﺍ ﻊﻤﻣﺍﺀ ﻼﻤﻏ ﻉﺩﺩ ﻼﻜﻤﻣﺎﺗ ﻼﺘﻳ ﻒﻴﻳﺍ ﺡﺮﻓ ﻼﻇﺍﺀ ﻒﻳ ﻼﻣ » ﻼﺠﻤﻟ « ﺐﻤﻌﻨﯨ » ﻼﺸﻴﻈﻣ « ﻚﻤﻣﺓ؛ ﻞﻜﻧ ﻼﻜﺜﻳﺭ ﻢﻨﻳﺍ ﻎﻳﺭ ﻢﺴﺘﻌﻤﻟ ﻒﻳ ﻊﺻﺮﻧﺍ ﻢﺜﻟ ﻚﻤﻣﺓ » ﺖﺴﻌﻴﻧ ﻭ ﻯﺬﻫ ﻼﻜﻤﻣﺎﺗ ﻼﺘﻳ ﻒﻴﻳﺍ ﺡﺮﻓ ﻼﻇﺍﺀ؛ ﻭ ﻼﻇﺍﺀ ﺏﺩﻻ ﻢﻧ ﺢﻔﻇ ﻕﺎﻋﺩﺓ ﺐﺴﻴﻃﺓ ﻞﻤﺘﻓﺮﻴﻗ ﺐﻴﻧ ﻼﺿﺍﺩ ﻭ ﻰﻧﺎﻛ ﻻ ﻱﻮﺟﺩ ﻒﻴﻳﺍ ﺡﺮﻓ » ﺱ-ﺽ-ﺹ-ﻁ-ﺯ-ﺫ-ﺙ-ﺕ-ﻑ ﺃ ﺍﻸﺣﺭ ﺄﻳ ﻚﻤﻣﺓ ﺖﺑﺩﺃ ﺏﺄﺣﺩ ﻯﺬﻫ « ﻼﻗﺎﻋﺩﺓ ﻰﻳ : ﻰﻳ : » ﻼﻇﺍﺀ « ﻼﻜﻤﻣﺎﺗ ﻼﺘﻳ ﻒﻴﻳﺍ ﺡﺮﻓ ﻅﺍﺀ ﺐﺗﺎﺗﺍ ﻭ ﺐﻤﻌﻨﯨ ﻼﻨﺼﻴﺑ . : ﻼﺣ ﻅ 1- ﺽﺩ ﻼﻨﺴﻳﺎﻧ . : ﻒﻇﻼﺣ -2 ﺐﻤﻌﻨﯨ ﻼﻤﻨﻋ ﺃﻭ ﻼﻤﺤﻇﻭﺭ . : ﻼﺣ ﻅﺭ 3- ﺐﻤﻌﻨﯨ ﻻﺮﻔﻋﺓ . : ﻼﺣ ﻅﻭﺓ 4- ﺭ.ﻭ ﻼﻈﻤﻣ : ﻼﺟ 5- ﻯﻭ ﺬﻛﺭ ﻼﻨﻋﺎﻣ . ﻭ : ﻼﻈﻤﻴﻣ 6- ﻼﻏﺯﻻ . ﻼﻈﺒﻳ : 7- ﻰﻳ ﻁﺮﻓ ﻼﺴﻴﻓ . ﻭ : ﻼﻈﺑﺓ 8- ﻼﻈﻌﻧ : ﻻﺮﺤﻴﻟ . 9- ﻼﻇﺮﻓ : ﺞﻴﺑ ﺃﻭ ﻎﺷﺍﺀ ﺥﺍﺮﺠﻳ ﻦﺤﻔﻇ ﺩﺎﺨﻣﻭ ﺶﻳﺀ . 10- ﻼﻇﺮﻴﻓ : ﻼﺠﻤﻴﻟ . 11- ﻼﻈﻧ : ﻼﺸﻛ . 12- ﻼﻈﻟ : ﺽﺩ ﻼﺸﻤﺳ . 13- ﺽﺩ ﻼﺨﻴﺑﺓ . : ﻼﻈﻓﺭ 14- ﻼﻈﻳﺭ : ﺦﺒﻠﻓ ﻼﺒﻄﻧ . 15- 19 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺄﻳ ﻼﻌﻄﺷ . : ﻼﻈﻣﺃ 16- ﻢﻧﻭ ( ﻼﻛﺎﻈﻣ ) . ﻮﯨﻭ ﻚﺘﻣ ﻼﺣﺰﻧ ﻭ : ﻼﻜﻈﻣ 17- ﺄﻳ ﻼﻨﻇﺭ . : ﻼﻤﺤﻇ-18 ﻼﻜﺒﻠﻣ . ﻼﻤﻔﻇ : ﻼﻨﻄﻗ ﻭ 19- ﻼﺗﻸﻴﻓ . ﻼﻨﻈﻣ : ﻼﺠﻤﻋ ﻭ 20- ﻼﻨﻇﺎﻓﺓ : ﻼﻨﻗﺍﻭﺓ . 21- ﻼﻨﻇﺭ : ﻼﺒﺻﺭ . 22- ﻼﻌﻈﻣ : ﻭﺎﺣﺩ ﻼﻌﻇﺎﻣ : ﻖﻄﻋﺓ ﻢﻧ ﻊﻈﻣ ﺄﻳ ﻙﺎﺌﻧ ﺢﻳ . 23- ﻼﻌﻈﻴﻣ : ﻼﻜﺒﻳﺭ . 24- ﺄﻳ ﺵﺪﻳﺩ . » ﻢﻌﻈﻟ ﺄﻣﺭ « ﻢﻧﻭ ﻮﯨﻭ ﻼﺷﺩﺓ ﻭ : ﻼﻌﻈﻟ 25- ﻼﻐﻴﻇ : ﻼﻐﻀﺑ . 26- ﺐﻤﻌﻨﯨ ﻼﻗﻭﺓ . : ﻼﻔﻇﺎﻇﺓ 27- ﻯﻭ ﻼﺸﻨﻴﻋ . ﻢﻧ ﺍﻸﻣﺭ ﻼﻔﻈﻴﻋ ﻭ : ﻼﻔﻇﺎﻋﺓ 28- ﺐﻤﻌﻨﯨ ﻡﺪﺣ ﻼﺤﻳ ﺏﻼﺸﻋﺭ . : ﻼﺘﻗﺮﻴﻇ 29- ﻼﻣﻭﺎﻈﺑﺓ : ﻼﻣﺩﺍﻮﻣﺓ ﻊﻤﯨ ﻼﺸﻳﺀ . 30- ﻼﺧﺪﻣﺓ . ﻻﻮﻈﻴﻓﺓ : ﻼﻤﻨﺼﺑ ﻭ 31- ﺽﺩ ﻼﻧﻮﻣ . : ﻼﻴﻘﻇﺓ 32- ﺄﻳ ﻦﻳﺎﻳﺓ ﺍﻼﺼﺒﻋ . : ﻼﻇ ﻑﺭ 33- ﺩ . ﺐﻤﻌﻨﯨ ﻼﻧ : ﻼﻨﻈﻳﺭ 34- : ﻢﻣﺓ ﻼﻇ ﻼﻈﺒﻠﻣ ﻭ 35- ﻊﻜﺳ ﻼﻧﻭﺭ . 20 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﺐﻤﻌﻨﯨ ﺄﺘﻌﺑ . : ﺐﻴﻇ-36 ﺞﺣ ﻅ : ﻼﺠﺣﻮﻇ : ﺏﺭﻭﺯ ﺡﺪﻗﺓ ﻼﻌﻴﻧ . 37- ﻼﺤﻈﻳﺭﺓ : ﻡﺃﻮﯨ ﻼﻣﻭﺎﺸﻳ . 38- ﻼﻐﻀﺑ . ﻼﺤﻔﻴﻇﺓ : ﻼﺤﻤﻳﺓ ﻭ 39- ﻼﺤﻨﻈﻟ : ﻦﺑﺎﺗ ﻡﺭ ﻼﻣﺫﺎﻗ . 40- ﻼﺸﻈﻳﺓ : ﻼﻔﻤﻗﺓ ﻖﻄﻋﺓ ﻢﻧ ﻼﺨﺸﺑ . 41- ﺐﻤﻌﻨﯨ ﺦﺷﻮﻧﺓ ﻼﻌﻴﺷ . ﺶﻇ ﻑ-42 : ﻼﺷﻭﺎﻇ : ﻞﻴﻴﺑ ﻼﻧﺍﺭ ﻢﻧ ﻎﻳﺭ ﺪﺧﺎﻧ ﺃﻭ ﺡﺭ ﻼﺸﻤﺳ . 43- . » ﺕﺎﻫ « ﺩﺎﻣ . ﺄﻣﺍ ﺾﻟ ﺏﻼﺿﺍﺩ ﺄﻳ ﻆﻟ : 44- » . ﻉ ﻢﻧ ﻊﻇﺎﻣ ﻼﺻﺩﺭ ﻼﺿ ﻡ « ﻞﻜﻧ ﻼﻈﻤﻋ : ﻼﻋﺮﺟ ﻭ 45- ﻱﺭ : ﻢﻨﺘﺼﻓ ﻼﻨﻳﺍﺭ . ﻼﻇ -46 ﻙﺎﻇ : ﻢﻧ ﺄﺳﻭﺎﻗ ﻼﻋﺮﺑ ﻖﺒﻟ ﺍﻺﺴﺒﻠﻣ . ﻉ -47 ﻼﺨﺷﻮﻧﺓ . ﻼﻐﻤﻇﺓ : ﻼﺷﺩﺓ ﻭ 48- ﻼﻐﻤﻴﻇ : ﺽﺩ ﻻﺮﻘﻴﻗ . 49- ﻼﻐﻴﻇ : ﻼﻣﻮﺗ، ﻑﺎﻈﺗ ﺭﻮﺣﻭ : ﺄﻳ ﻡﺎﺗ . 50- ﻼﻘﻴﻇ : ﺵﺩﺓ ﻼﺣﺭ . 51- ﺄﻣﺍ ﻼﻘﻴﺿ ﻑﻼﻘﺷﺭﺓ ﻼﻌﻤﻳﺍ ﻼﻳﺎﺒﺳﺓ ﻢﻧ ﻼﺒﻴﺿﺓ . ﻼﻤﻈﯨ : ﻢﻧ ﺄﺴﻣﺍﺀ ﻼﻧﺍﺭ . 52- ﻼﻤﻤﻇ : ﻢﺴﺣ ﻼﺸﻔﺘﻴﻧ ﺏﻼﻤﺳﺎﻧ . 53- ﻼﻣﺮﻇ : ﻼﺟﻮﻋ ﻼﺷﺪﻳﺩ، ﺄﻣﺍ ﻼﻣﺮﺿ : ﻑﻻﺩﺍﺀ . 54- 21 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻼﻈﻧﺓ : ﻼﺘﻴﻣﺓ . 55- ﻼﺘﻨﻈﻴﻣ : ﻼﺗﺮﺘﻴﺑ . 56- ﻻﻮﻌﻇ : ﻼﻨﺼﺣ . 57- ﺖﻴﻘﻇ : ﺎﺴﺘﻴﻘﻇ . 58- .ﺞﺒﻟ ﺫﺍ ﺢﻇ . ﺄﻣﺍ ﻼﺤﻀﻴﺿ ﻒﻳﻭ ﻢﻨﺨﻔﺿ ﻢﻧ ﻻ ﻙﺎﻧ ﻥ ﻞﻤﺤﻇﻮﻇ : ﻡ ﻭﺍ ﻼﺤﻈﻴﻇ 59- ﻼﺸﻴﻈﻣ : ﻼﺠﻤﻟ . 60- ﻼﻈﻤﻓ : ﻼﺣﺎﻓﺭ ﻒﻳ ﻼﻣﻭﺎﺸﻳ . 61- ﻼﻈﻤﻳ : ﻡﺍ ﺖﺴﻘﻳ ﻼﻣﺍﺀ ﻢﻧ ﻻﺯﺮﻋ . 62- ﻼﻇﺎﯨﺭ : ﻼﺑﺍﺭﺯ . 63- ﻥ : ﺯﺎﺌﻟ ﺃﻭ ﻉﺎﺑﺭ . ﺎﻋ ﻅ -64 ﺭ : ﺎﺴﻣ ﻊﻤﻣ ﺐﻤﻌﻨﯨ ﻑﺎﺋﺯ ﺃﻭ ﺭﺎﺒﺣ . ﺎﻓ ﻅ -65 ﻮﺴﻴﻣ . ﻅﺮﻴﻓ : ﺞﻤﻴﻟ ﻭ 66- ﺢﻳﻭﺎﻧ ﻒﻳ ﺢﺠﻣ ﻼﻘﻃ ﺫﻭ ﺭﺎﺌﺣﺓ ﻙﺮﻴﻳﺓ ﻢﻧ ﺄﻜﻟ ﻼﻤﺣﻮﻣ . ﻅﺮﺑﺎﻧ : 67- ﻲﻧﺓ : ﺯﻮﺟﺓ ﺃﻭ ﺎﻣﺭﺃﺓ ﻡﺍﺩﺎﻤﺗ ﻒﻳ ﻼﻳﻭﺪﺟ . ﻉ ﻼﻇ -68 ﺎﻨﺘﻇﺍﺭ : ﺕﻮﻘﻋ، ﺕﺮﻘﺑ، ﺄﻤﻟ ﻒﻳ ﻼﺤﺻﻮﻟ ﻊﻤﯨ ﺶﻳﺀ ﺃﻭ ﺡﺩﻮﺛ ﺄﻣﺭ ﻢﺗﺮﺠﯨ . 69- ﻼﺤﻔﻴﻇ : ﻲﻘﻇ ﻢﻨﺘﺑﻭ . 70- ﻢﺒﻠﺤﻇﺓ، ﻢﻤﺣﻮﻇﺓ : ﺖﻨﺒﻳﻭ ﺃﻭ ﺈﺷﺍﺭﺓ ﻺﯨ ﺄﻣﺭ . 71- ﺕﻮﻈﻴﻓ، ﻡﻮﻈﻓ . 72- ﻢﻈﻓﺭ : ﻢﻨﺘﺻﺭ . 73- ﻢﻨﻈﻣﺓ : ﻰﻳﺃﺓ ﻡﺆﻠﻓﺓ ﻢﻧ ﺄﻌﺿﺍﺀ . 74- 22 ﻡ . ﻥﺎﻫﺩﺓ ﻍﺍﺰﻳ ﻊﻟﻭﺎﻧ ﺓ ﺢﻣﺎﺿﺭﺎﺗ ﻲﻓ ﻼﻠﻏﺓ ﻼﻋﺮﺒﻳ ﻦﻋﺎﻇ : ﺍﻼﻨﺘﺻﺎﺑ . ﺍﻹ -75 ﻅﺅﺍﺭ : ﺺﻓﺓ ﻞﻤﺒﻗﺭ . 76- ﻅ ﺉﺭ : ﻡﺮﻀﻋﺓ ﻝﻮﻟﺩ ﻎﻳﺮﯨﺍ . 77- ﻼﻇﺄﺑ : ﻻﺰﺠﻟ . 78- ﻼﻈﺒﻇﺎﺑ : ﻼﺑ ﺭﺓ ﻒﻳ ﺞﻔﻧ ﻼﻌﻴﻧ ﻱﺩﺍﻮﯨ ﺏﻻﺰﻌﻓﺭﺎﻧ . ﺙ 79- ﻼﻇﺭﺎﺑ : ﻻﺭﻭﺎﺒﻳ ﻼﺼﻐﻳﺭﺓ . 80- ﻼﻇﺭﺎﺑ : ﺎﺴﻣ ﺮﺠﻟ . 81- ﺺﻳﺎﺣ ﻼﻤﺴﺘﻐﻴﺛ . ﻆﺟ : ﺇﺫﺍ ﺹﺎﺣ ﻒﻳ ﻼﺣﺮﺑ 82- ﺥ : ﺶﺟﺭ ﻼﺴﻣﺎﻗ . ﻡ ﹴﻼﻇ -83 ﻼﻇﺭ : ﻼﺤﺟﺭ ﻼﻣﺩﻭﺭ . 84- ﻼﻈﻴﻳﺭ : ﻼﻤﻌﻴﻧ . 85- ﻆﻤﻳﺍﺀ : ﺍﻼﻨﺜﯨ ﻼﺴﻣﺭﺍﺀ . 86- ﺎﻧ : ﺶﻳﺀ ﻢﻧ ﻼﻌﺴﻟ . ﻼﻈﺑ -87 ﻻﺰﯨﻭ . ﻼﻌﻈﻣﺓ : ﻼﻜﺑﺮﻳﺍﺀ ﻭ 88- ﻼﻈﻣﺃ : ﻼﻌﻄﺷ . 89- ﺭﺓ : ﻼﺠﻤﻴﻣﺓ . ﺽ ﻼﻨﻇﺭﺓ : ﻼﻤﻤﺣﺓ، ﺄﻣﺍ ﻼﻧ 90- ﻼﻤﺤﻇﺓ : ﻮﻤﺿﺓ ﻼﻌﻴﻧ . 91- ﻼﺤﻇ : ﺭﺎﻘﺑ . 92- ﻼﻤﻈﻣﺓ : ﻼﺒﻴﺗ ﻼﻜﺒﻳﺭ ﻢﻧ ﻼﺸﻋﺭ . 93- 23"
}